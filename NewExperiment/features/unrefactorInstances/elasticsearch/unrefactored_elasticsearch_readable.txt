[<(startLine=42 endLine=59 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgTests.java)
    public void testEmptyAggregation() throws Exception {

        SearchResponse searchResponse = client().prepareSearch("empty_bucket_idx")
                .setQuery(matchAllQuery())
                .addAggregation(histogram("histo").field("value").interval(1l).minDocCount(0).subAggregation(avg("avg")))
                .execute().actionGet();

        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2l));
        Histogram histo = searchResponse.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        Histogram.Bucket bucket = histo.getBuckets().get(1);
        assertThat(bucket, notNullValue());

        Avg avg = bucket.getAggregations().get("avg");
        assertThat(avg, notNullValue());
        assertThat(avg.getName(), equalTo("avg"));
        assertThat(Double.isNaN(avg.getValue()), is(true));
    }
,
(startLine=41 endLine=58 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/metrics/SumTests.java)
    public void testEmptyAggregation() throws Exception {

        SearchResponse searchResponse = client().prepareSearch("empty_bucket_idx")
                .setQuery(matchAllQuery())
                .addAggregation(histogram("histo").field("value").interval(1l).minDocCount(0).subAggregation(sum("sum")))
                .execute().actionGet();

        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2l));
        Histogram histo = searchResponse.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        Histogram.Bucket bucket = histo.getBuckets().get(1);
        assertThat(bucket, notNullValue());

        Sum sum = bucket.getAggregations().get("sum");
        assertThat(sum, notNullValue());
        assertThat(sum.getName(), equalTo("sum"));
        assertThat(sum.getValue(), equalTo(0.0));
    }
,
(startLine=41 endLine=58 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinTests.java)
    public void testEmptyAggregation() throws Exception {

        SearchResponse searchResponse = client().prepareSearch("empty_bucket_idx")
                .setQuery(matchAllQuery())
                .addAggregation(histogram("histo").field("value").interval(1l).minDocCount(0).subAggregation(min("min")))
                .execute().actionGet();

        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2l));
        Histogram histo = searchResponse.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        Histogram.Bucket bucket = histo.getBuckets().get(1);
        assertThat(bucket, notNullValue());

        Min min = bucket.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(Double.POSITIVE_INFINITY));
    }
,
(startLine=41 endLine=58 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MaxTests.java)
    public void testEmptyAggregation() throws Exception {

        SearchResponse searchResponse = client().prepareSearch("empty_bucket_idx")
                .setQuery(matchAllQuery())
                .addAggregation(histogram("histo").field("value").interval(1l).minDocCount(0).subAggregation(max("max")))
                .execute().actionGet();

        assertThat(searchResponse.getHits().getTotalHits(), equalTo(2l));
        Histogram histo = searchResponse.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        Histogram.Bucket bucket = histo.getBuckets().get(1);
        assertThat(bucket, notNullValue());

        Max max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getName(), equalTo("max"));
        assertThat(max.getValue(), equalTo(Double.NEGATIVE_INFINITY));
    }
,
>
, <(startLine=93 endLine=114 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/main/java/org/elasticsearch/action/search/SearchQueryThenFetchAsyncAction.java)
                      final ShardFetchSearchRequest fetchSearchRequest, DiscoveryNode node) {
        searchTransportService.sendExecuteFetch(node, fetchSearchRequest, new ActionListener<FetchSearchResult>() {
            @Override
            public void onResponse(FetchSearchResult result) {
                result.shardTarget(shardTarget);
                fetchResults.set(shardIndex, result);
                if (counter.decrementAndGet() == 0) {
                    finishHim();
                }
            }

            @Override
            public void onFailure(Throwable t) {
                // the search context might not be cleared on the node where the fetch was executed for example
                // because the action was rejected by the thread pool. in this case we need to send a dedicated
                // request to clear the search context. by setting docIdsToLoad to null, the context will be cleared
                // in TransportSearchTypeAction.releaseIrrelevantSearchContexts() after the search request is done.
                docIdsToLoad.set(shardIndex, null);
                onFetchFailure(t, fetchSearchRequest, shardIndex, shardTarget, counter);
            }
        });
    }
,
(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/main/java/org/elasticsearch/action/search/SearchDfsQueryThenFetchAsyncAction.java)
                      final ShardFetchSearchRequest fetchSearchRequest, DiscoveryNode node) {
        searchTransportService.sendExecuteFetch(node, fetchSearchRequest, new ActionListener<FetchSearchResult>() {
            @Override
            public void onResponse(FetchSearchResult result) {
                result.shardTarget(shardTarget);
                fetchResults.set(shardIndex, result);
                if (counter.decrementAndGet() == 0) {
                    finishHim();
                }
            }

            @Override
            public void onFailure(Throwable t) {
                // the search context might not be cleared on the node where the fetch was executed for example
                // because the action was rejected by the thread pool. in this case we need to send a dedicated
                // request to clear the search context. by setting docIdsToLoad to null, the context will be cleared
                // in TransportSearchTypeAction.releaseIrrelevantSearchContexts() after the search request is done.
                docIdsToLoad.set(shardIndex, null);
                onFetchFailure(t, fetchSearchRequest, shardIndex, shardTarget, counter);
            }
        });
    }
,
>
, <(startLine=71 endLine=87 srcPath=/root/NewExperiment/elasticsearchFilter/00855/src/main/java/org/elasticsearch/common/inject/Injectors.java)
    public static <T> Set<T> getInstancesOf(Injector injector, Class<T> baseClass) {
        Set<T> answer = Sets.newHashSet();
        Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
        for (Entry<Key<?>, Binding<?>> entry : entries) {
            Key<?> key = entry.getKey();
            Class<?> keyType = getKeyType(key);
            if (keyType != null && baseClass.isAssignableFrom(keyType)) {
                Binding<?> binding = entry.getValue();
                Object value = binding.getProvider().get();
                if (value != null) {
                    T castValue = baseClass.cast(value);
                    answer.add(castValue);
                }
            }
        }
        return answer;
    }
,
(startLine=95 endLine=108 srcPath=/root/NewExperiment/elasticsearchFilter/00855/src/main/java/org/elasticsearch/common/inject/Injectors.java)
    public static <T> Set<T> getInstancesOf(Injector injector, Matcher<Class> matcher) {
        Set<T> answer = Sets.newHashSet();
        Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
        for (Entry<Key<?>, Binding<?>> entry : entries) {
            Key<?> key = entry.getKey();
            Class<?> keyType = getKeyType(key);
            if (keyType != null && matcher.matches(keyType)) {
                Binding<?> binding = entry.getValue();
                Object value = binding.getProvider().get();
                answer.add((T) value);
            }
        }
        return answer;
    }
,
(startLine=116 endLine=128 srcPath=/root/NewExperiment/elasticsearchFilter/00855/src/main/java/org/elasticsearch/common/inject/Injectors.java)
    public static <T> Set<Provider<T>> getProvidersOf(Injector injector, Matcher<Class> matcher) {
        Set<Provider<T>> answer = Sets.newHashSet();
        Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
        for (Entry<Key<?>, Binding<?>> entry : entries) {
            Key<?> key = entry.getKey();
            Class<?> keyType = getKeyType(key);
            if (keyType != null && matcher.matches(keyType)) {
                Binding<?> binding = entry.getValue();
                answer.add((Provider<T>) binding.getProvider());
            }
        }
        return answer;
    }
,
(startLine=137 endLine=149 srcPath=/root/NewExperiment/elasticsearchFilter/00855/src/main/java/org/elasticsearch/common/inject/Injectors.java)
    public static <T> Set<Provider<T>> getProvidersOf(Injector injector, Class<T> baseClass) {
        Set<Provider<T>> answer = Sets.newHashSet();
        Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
        for (Entry<Key<?>, Binding<?>> entry : entries) {
            Key<?> key = entry.getKey();
            Class<?> keyType = getKeyType(key);
            if (keyType != null && baseClass.isAssignableFrom(keyType)) {
                Binding<?> binding = entry.getValue();
                answer.add((Provider<T>) binding.getProvider());
            }
        }
        return answer;
    }
,
(startLine=188 endLine=199 srcPath=/root/NewExperiment/elasticsearchFilter/00855/src/main/java/org/elasticsearch/common/inject/Injectors.java)
    public static Set<Binding<?>> getBindingsOf(Injector injector, Matcher<Class> matcher) {
        Set<Binding<?>> answer = Sets.newHashSet();
        Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
        for (Entry<Key<?>, Binding<?>> entry : entries) {
            Key<?> key = entry.getKey();
            Class<?> keyType = getKeyType(key);
            if (keyType != null && matcher.matches(keyType)) {
                answer.add(entry.getValue());
            }
        }
        return answer;
    }
,
(startLine=207 endLine=218 srcPath=/root/NewExperiment/elasticsearchFilter/00855/src/main/java/org/elasticsearch/common/inject/Injectors.java)
    public static Set<Binding<?>> getBindingsOf(Injector injector, Class<?> baseClass) {
        Set<Binding<?>> answer = Sets.newHashSet();
        Set<Entry<Key<?>, Binding<?>>> entries = injector.getBindings().entrySet();
        for (Entry<Key<?>, Binding<?>> entry : entries) {
            Key<?> key = entry.getKey();
            Class<?> keyType = getKeyType(key);
            if (keyType != null && baseClass.isAssignableFrom(keyType)) {
                answer.add(entry.getValue());
            }
        }
        return answer;
    }
,
>
, <(startLine=46 endLine=60 srcPath=/root/NewExperiment/elasticsearchFilter/02062/core/src/main/java/org/elasticsearch/search/aggregations/bucket/filters/FiltersAggregatorFactory.java)
            Map<String, Object> metaData) throws IOException {
        super(name, context, parent, subFactories, metaData);
        this.keyed = keyed;
        this.otherBucket = otherBucket;
        this.otherBucketKey = otherBucketKey;
        IndexSearcher contextSearcher = context.searcher();
        weights = new Weight[filters.size()];
        keys = new String[filters.size()];
        for (int i = 0; i < filters.size(); ++i) {
            KeyedFilter keyedFilter = filters.get(i);
            this.keys[i] = keyedFilter.key();
            Query filter = keyedFilter.filter().toFilter(context.getQueryShardContext());
            this.weights[i] = contextSearcher.createNormalizedWeight(filter, false);
        }
    }
,
(startLine=44 endLine=56 srcPath=/root/NewExperiment/elasticsearchFilter/02062/core/src/main/java/org/elasticsearch/search/aggregations/bucket/adjacency/AdjacencyMatrixAggregatorFactory.java)
            Map<String, Object> metaData) throws IOException {
        super(name, context, parent, subFactories, metaData);
        IndexSearcher contextSearcher = context.searcher();
        this.separator = separator;
        weights = new Weight[filters.size()];
        keys = new String[filters.size()];
        for (int i = 0; i < filters.size(); ++i) {
            KeyedFilter keyedFilter = filters.get(i);
            this.keys[i] = keyedFilter.key();
            Query filter = keyedFilter.filter().toFilter(context.getQueryShardContext());
            this.weights[i] = contextSearcher.createNormalizedWeight(filter, false);
        }
    }
,
>
, <(startLine=43 endLine=83 srcPath=/root/NewExperiment/elasticsearchFilter/01723/core/src/main/java/org/elasticsearch/index/query/SpanContainingQueryParser.java)
    public SpanContainingQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
        XContentParser parser = parseContext.parser();
        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
        String queryName = null;
        SpanQueryBuilder<?> big = null;
        SpanQueryBuilder<?> little = null;

        String currentFieldName = null;
        XContentParser.Token token;
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                if ("big".equals(currentFieldName)) {
                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
                    if (!(query instanceof SpanQueryBuilder<?>)) {
                        throw new QueryParsingException(parseContext, "span_containing [big] must be of type span query");
                    }
                    big = (SpanQueryBuilder<?>) query;
                } else if ("little".equals(currentFieldName)) {
                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
                    if (!(query instanceof SpanQueryBuilder<?>)) {
                        throw new QueryParsingException(parseContext, "span_containing [little] must be of type span query");
                    }
                    little = (SpanQueryBuilder<?>) query;
                } else {
                    throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
                }
            } else if ("boost".equals(currentFieldName)) {
                boost = parser.floatValue();
            } else if ("_name".equals(currentFieldName)) {
                queryName = parser.text();
            } else {
                throw new QueryParsingException(parseContext, "[span_containing] query does not support [" + currentFieldName + "]");
            }
        }

        SpanContainingQueryBuilder query = new SpanContainingQueryBuilder(big, little);
        query.boost(boost).queryName(queryName);
        return query;
    }
,
(startLine=43 endLine=91 srcPath=/root/NewExperiment/elasticsearchFilter/01723/core/src/main/java/org/elasticsearch/index/query/SpanWithinQueryParser.java)
    public SpanWithinQueryBuilder fromXContent(QueryParseContext parseContext) throws IOException, QueryParsingException {
        XContentParser parser = parseContext.parser();

        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
        String queryName = null;
        SpanQueryBuilder big = null;
        SpanQueryBuilder little = null;

        String currentFieldName = null;
        XContentParser.Token token;
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                if ("big".equals(currentFieldName)) {
                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
                    if (query instanceof SpanQueryBuilder == false) {
                        throw new QueryParsingException(parseContext, "span_within [big] must be of type span query");
                    }
                    big = (SpanQueryBuilder) query;
                } else if ("little".equals(currentFieldName)) {
                    QueryBuilder query = parseContext.parseInnerQueryBuilder();
                    if (query instanceof SpanQueryBuilder == false) {
                        throw new QueryParsingException(parseContext, "span_within [little] must be of type span query");
                    }
                    little = (SpanQueryBuilder) query;
                } else {
                    throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
                }
            } else if ("boost".equals(currentFieldName)) {
                boost = parser.floatValue();
            } else if ("_name".equals(currentFieldName)) {
                queryName = parser.text();
            } else {
                throw new QueryParsingException(parseContext, "[span_within] query does not support [" + currentFieldName + "]");
            }
        }

        if (big == null) {
            throw new QueryParsingException(parseContext, "span_within must include [big]");
        }
        if (little == null) {
            throw new QueryParsingException(parseContext, "span_within must include [little]");
        }

        SpanWithinQueryBuilder query = new SpanWithinQueryBuilder(big, little);
        query.boost(boost).queryName(queryName);
        return query;
    }
,
>
, <(startLine=47 endLine=55 srcPath=/root/NewExperiment/elasticsearchFilter/01739/core/src/main/java/org/elasticsearch/rest/action/count/RestCountAction.java)
    public RestCountAction(Settings settings, RestController controller, Client client) {
        super(settings, controller, client);
        controller.registerHandler(POST, "/_count", this);
        controller.registerHandler(GET, "/_count", this);
        controller.registerHandler(POST, "/{index}/_count", this);
        controller.registerHandler(GET, "/{index}/_count", this);
        controller.registerHandler(POST, "/{index}/{type}/_count", this);
        controller.registerHandler(GET, "/{index}/{type}/_count", this);
    }
,
(startLine=39 endLine=47 srcPath=/root/NewExperiment/elasticsearchFilter/01739/core/src/main/java/org/elasticsearch/rest/action/termvectors/RestMultiTermVectorsAction.java)
    public RestMultiTermVectorsAction(Settings settings, RestController controller, Client client) {
        super(settings, controller, client);
        controller.registerHandler(GET, "/_mtermvectors", this);
        controller.registerHandler(POST, "/_mtermvectors", this);
        controller.registerHandler(GET, "/{index}/_mtermvectors", this);
        controller.registerHandler(POST, "/{index}/_mtermvectors", this);
        controller.registerHandler(GET, "/{index}/{type}/_mtermvectors", this);
        controller.registerHandler(POST, "/{index}/{type}/_mtermvectors", this);
    }
,
(startLine=41 endLine=49 srcPath=/root/NewExperiment/elasticsearchFilter/01739/core/src/main/java/org/elasticsearch/rest/action/admin/cluster/shards/RestClusterSearchShardsAction.java)
    public RestClusterSearchShardsAction(Settings settings, RestController controller, Client client) {
        super(settings, controller, client);
        controller.registerHandler(GET, "/_search_shards", this);
        controller.registerHandler(POST, "/_search_shards", this);
        controller.registerHandler(GET, "/{index}/_search_shards", this);
        controller.registerHandler(POST, "/{index}/_search_shards", this);
        controller.registerHandler(GET, "/{index}/{type}/_search_shards", this);
        controller.registerHandler(POST, "/{index}/{type}/_search_shards", this);
    }
,
>
, <(startLine=41 endLine=100 srcPath=/root/NewExperiment/elasticsearchFilter/00946/src/test/java/org/elasticsearch/test/integration/search/matchedfilters/MatchedQueriesTests.java)
    public void simpleMatchedQueryFromFilteredQuery() throws Exception {

        client().admin().indices().prepareCreate("test").execute().actionGet();
        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("name", "test1")
                .field("number", 1)
                .endObject()).execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("name", "test2")
                .field("number", 2)
                .endObject()).execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("name", "test3")
                .field("number", 3)
                .endObject()).execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client().prepareSearch()
                .setQuery(filteredQuery(matchAllQuery(), orFilter(rangeFilter("number").lte(2).filterName("test1"), rangeFilter("number").gt(2).filterName("test2"))))
                .execute().actionGet();


        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));
        for (SearchHit hit : searchResponse.getHits()) {
            if (hit.id().equals("1") || hit.id().equals("2")) {
                assertThat(hit.matchedQueries().length, equalTo(1));
                assertThat(hit.matchedQueries(), hasItemInArray("test1"));
            } else if (hit.id().equals("3")) {
                assertThat(hit.matchedQueries().length, equalTo(1));
                assertThat(hit.matchedQueries(), hasItemInArray("test2"));
            } else {
                fail("Unexpected document returned with id " + hit.id());
            }
        }

        searchResponse = client().prepareSearch()
                .setQuery(boolQuery().should(rangeQuery("number").lte(2).queryName("test1")).should(rangeQuery("number").gt(2).queryName("test2")))
                .execute().actionGet();


        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));
        for (SearchHit hit : searchResponse.getHits()) {
            if (hit.id().equals("1") || hit.id().equals("2")) {
                assertThat(hit.matchedQueries().length, equalTo(1));
                assertThat(hit.matchedQueries(), hasItemInArray("test1"));
            } else if (hit.id().equals("3")) {
                assertThat(hit.matchedQueries().length, equalTo(1));
                assertThat(hit.matchedQueries(), hasItemInArray("test2"));
            } else {
                fail("Unexpected document returned with id " + hit.id());
            }
        }
    }
,
(startLine=103 endLine=168 srcPath=/root/NewExperiment/elasticsearchFilter/00946/src/test/java/org/elasticsearch/test/integration/search/matchedfilters/MatchedQueriesTests.java)
    public void simpleMatchedQueryFromTopLevelFilter() throws Exception {

        client().admin().indices().prepareCreate("test").execute().actionGet();
        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("name", "test")
                .field("title", "title1")
                .endObject()).execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("name", "test")
                .endObject()).execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("name", "test")
                .endObject()).execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client().prepareSearch()
                .setQuery(matchAllQuery())
                .setFilter(orFilter(
                        termFilter("name", "test").filterName("name"),
                        termFilter("title", "title1").filterName("title")))
                .execute().actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));

        for (SearchHit hit : searchResponse.getHits()) {
            if (hit.id().equals("1")) {
                assertThat(hit.matchedQueries().length, equalTo(2));
                assertThat(hit.matchedQueries(), hasItemInArray("name"));
                assertThat(hit.matchedQueries(), hasItemInArray("title"));
            } else if (hit.id().equals("2") || hit.id().equals("3")) {
                assertThat(hit.matchedQueries().length, equalTo(1));
                assertThat(hit.matchedQueries(), hasItemInArray("name"));
            } else {
                fail("Unexpected document returned with id " + hit.id());
            }
        }

        searchResponse = client().prepareSearch()
                .setQuery(matchAllQuery())
                .setFilter(queryFilter(boolQuery()
                        .should(termQuery("name", "test").queryName("name"))
                        .should(termQuery("title", "title1").queryName("title"))))
                .execute().actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));

        for (SearchHit hit : searchResponse.getHits()) {
            if (hit.id().equals("1")) {
                assertThat(hit.matchedQueries().length, equalTo(2));
                assertThat(hit.matchedQueries(), hasItemInArray("name"));
                assertThat(hit.matchedQueries(), hasItemInArray("title"));
            } else if (hit.id().equals("2") || hit.id().equals("3")) {
                assertThat(hit.matchedQueries().length, equalTo(1));
                assertThat(hit.matchedQueries(), hasItemInArray("name"));
            } else {
                fail("Unexpected document returned with id " + hit.id());
            }
        }
    }
,
(startLine=171 endLine=228 srcPath=/root/NewExperiment/elasticsearchFilter/00946/src/test/java/org/elasticsearch/test/integration/search/matchedfilters/MatchedQueriesTests.java)
    public void simpleMatchedQueryFromTopLevelFilterAndFilteredQuery() throws Exception {

        client().admin().indices().prepareCreate("test").execute().actionGet();
        client().admin().cluster().prepareHealth().setWaitForEvents(Priority.LANGUID).setWaitForGreenStatus().execute().actionGet();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("name", "test")
                .field("title", "title1")
                .endObject()).execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("name", "test")
                .field("title", "title2")
                .endObject()).execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("name", "test")
                .field("title", "title3")
                .endObject()).execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client().prepareSearch()
                .setQuery(filteredQuery(matchAllQuery(), termsFilter("title", "title1", "title2", "title3").filterName("title")))
                        .setFilter(termFilter("name", "test").filterName("name"))
                        .execute().actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));

        for (SearchHit hit : searchResponse.getHits()) {
            if (hit.id().equals("1") || hit.id().equals("2") || hit.id().equals("3")) {
                assertThat(hit.matchedQueries().length, equalTo(2));
                assertThat(hit.matchedQueries(), hasItemInArray("name"));
                assertThat(hit.matchedQueries(), hasItemInArray("title"));
            } else {
                fail("Unexpected document returned with id " + hit.id());
            }
        }

        searchResponse = client().prepareSearch()
                .setQuery(termsQuery("title", "title1", "title2", "title3").queryName("title"))
                .setFilter(queryFilter(matchQuery("name", "test").queryName("name")))
                .execute().actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(3l));

        for (SearchHit hit : searchResponse.getHits()) {
            if (hit.id().equals("1") || hit.id().equals("2") || hit.id().equals("3")) {
                assertThat(hit.matchedQueries().length, equalTo(2));
                assertThat(hit.matchedQueries(), hasItemInArray("name"));
                assertThat(hit.matchedQueries(), hasItemInArray("title"));
            } else {
                fail("Unexpected document returned with id " + hit.id());
            }
        }
    }
,
>
, <(startLine=1067 endLine=1122 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsIT.java)
    public void singleValuedField_OrderedBySubAggregationAsc_MultiHierarchyLevels() throws Exception {
        boolean asc = randomBoolean();
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("tags")
                                .executionHint(randomExecutionHint())
                                .field("tag")
                                .collectMode(randomFrom(SubAggCollectionMode.values()))
                                .order(Terms.Order.aggregation("filter1>filter2>stats.max", asc))
                                .subAggregation(
                                        filter("filter1").filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                filter("filter2").filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                        stats("stats").field("i"))))).execute().actionGet();

        assertSearchResponse(response);

        Terms tags = response.getAggregations().get("tags");
        assertThat(tags, notNullValue());
        assertThat(tags.getName(), equalTo("tags"));
        assertThat(tags.getBuckets().size(), equalTo(2));

        Iterator<Terms.Bucket> iters = tags.getBuckets().iterator();

        // the max for "more" is 2
        // the max for "less" is 4

        Terms.Bucket tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "more" : "less"));
        assertThat(tag.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter2 = filter1.getAggregations().get("filter2");
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 3l : 2l));
        Stats stats = filter2.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getMax(), equalTo(asc ? 2.0 : 4.0));

        tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "less" : "more"));
        assertThat(tag.getDocCount(), equalTo(asc ? 2l : 3l));
        filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 2l : 3l));
        filter2 = filter1.getAggregations().get("filter2");
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 2l : 3l));
        stats = filter2.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getMax(), equalTo(asc ? 4.0 : 2.0));
    }
,
(startLine=1125 endLine=1186 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsIT.java)
    public void singleValuedField_OrderedBySubAggregationAsc_MultiHierarchyLevels_specialChars() throws Exception {
        StringBuilder filter2NameBuilder = new StringBuilder("filt.er2");
        filter2NameBuilder.append(randomAsciiOfLengthBetween(3, 10).replace("[", "").replace("]", "").replace(">", ""));
        String filter2Name = filter2NameBuilder.toString();
        StringBuilder statsNameBuilder = new StringBuilder("st.ats");
        statsNameBuilder.append(randomAsciiOfLengthBetween(3, 10).replace("[", "").replace("]", "").replace(">", ""));
        String statsName = statsNameBuilder.toString();
        boolean asc = randomBoolean();
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("tags")
                                .executionHint(randomExecutionHint())
                                .field("tag")
                                .collectMode(randomFrom(SubAggCollectionMode.values()))
                                .order(Terms.Order.aggregation("filter1>" + filter2Name + ">" + statsName + ".max", asc))
                                .subAggregation(
                                        filter("filter1").filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                filter(filter2Name).filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                        stats(statsName).field("i"))))).execute().actionGet();

        assertSearchResponse(response);

        Terms tags = response.getAggregations().get("tags");
        assertThat(tags, notNullValue());
        assertThat(tags.getName(), equalTo("tags"));
        assertThat(tags.getBuckets().size(), equalTo(2));

        Iterator<Terms.Bucket> iters = tags.getBuckets().iterator();

        // the max for "more" is 2
        // the max for "less" is 4

        Terms.Bucket tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "more" : "less"));
        assertThat(tag.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter2 = filter1.getAggregations().get(filter2Name);
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 3l : 2l));
        Stats stats = filter2.getAggregations().get(statsName);
        assertThat(stats, notNullValue());
        assertThat(stats.getMax(), equalTo(asc ? 2.0 : 4.0));

        tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "less" : "more"));
        assertThat(tag.getDocCount(), equalTo(asc ? 2l : 3l));
        filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 2l : 3l));
        filter2 = filter1.getAggregations().get(filter2Name);
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 2l : 3l));
        stats = filter2.getAggregations().get(statsName);
        assertThat(stats, notNullValue());
        assertThat(stats.getMax(), equalTo(asc ? 4.0 : 2.0));
    }
,
(startLine=1189 endLine=1250 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsIT.java)
    public void singleValuedField_OrderedBySubAggregationAsc_MultiHierarchyLevels_specialCharsNoDotNotation() throws Exception {
        StringBuilder filter2NameBuilder = new StringBuilder("filt.er2");
        filter2NameBuilder.append(randomAsciiOfLengthBetween(3, 10).replace("[", "").replace("]", "").replace(">", ""));
        String filter2Name = filter2NameBuilder.toString();
        StringBuilder statsNameBuilder = new StringBuilder("st.ats");
        statsNameBuilder.append(randomAsciiOfLengthBetween(3, 10).replace("[", "").replace("]", "").replace(">", ""));
        String statsName = statsNameBuilder.toString();
        boolean asc = randomBoolean();
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("tags")
                                .executionHint(randomExecutionHint())
                                .field("tag")
                                .collectMode(randomFrom(SubAggCollectionMode.values()))
                                .order(Terms.Order.aggregation("filter1>" + filter2Name + ">" + statsName + "[max]", asc))
                                .subAggregation(
                                        filter("filter1").filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                filter(filter2Name).filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                        stats(statsName).field("i"))))).execute().actionGet();

        assertSearchResponse(response);

        Terms tags = response.getAggregations().get("tags");
        assertThat(tags, notNullValue());
        assertThat(tags.getName(), equalTo("tags"));
        assertThat(tags.getBuckets().size(), equalTo(2));

        Iterator<Terms.Bucket> iters = tags.getBuckets().iterator();

        // the max for "more" is 2
        // the max for "less" is 4

        Terms.Bucket tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "more" : "less"));
        assertThat(tag.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter2 = filter1.getAggregations().get(filter2Name);
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 3l : 2l));
        Stats stats = filter2.getAggregations().get(statsName);
        assertThat(stats, notNullValue());
        assertThat(stats.getMax(), equalTo(asc ? 2.0 : 4.0));

        tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "less" : "more"));
        assertThat(tag.getDocCount(), equalTo(asc ? 2l : 3l));
        filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 2l : 3l));
        filter2 = filter1.getAggregations().get(filter2Name);
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 2l : 3l));
        stats = filter2.getAggregations().get(statsName);
        assertThat(stats, notNullValue());
        assertThat(stats.getMax(), equalTo(asc ? 4.0 : 2.0));
    }
,
(startLine=934 endLine=989 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
    public void singleValuedField_OrderedBySubAggregationAsc_MultiHierarchyLevels() throws Exception {
        boolean asc = randomBoolean();
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("tags")
                                .field("num_tag")
                                .collectMode(randomFrom(SubAggCollectionMode.values()))
                                .order(Terms.Order.aggregation("filter1>filter2>max", asc))
                                .subAggregation(
                                        filter("filter1").filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                filter("filter2").filter(QueryBuilders.matchAllQuery()).subAggregation(
                                                        max("max").field(SINGLE_VALUED_FIELD_NAME))))).execute().actionGet();


        assertSearchResponse(response);

        Terms tags = response.getAggregations().get("tags");
        assertThat(tags, notNullValue());
        assertThat(tags.getName(), equalTo("tags"));
        assertThat(tags.getBuckets().size(), equalTo(2));

        Iterator<Terms.Bucket> iters = tags.getBuckets().iterator();

        // the max for "1" is 2
        // the max for "0" is 4

        Terms.Bucket tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "1" : "0"));
        assertThat(tag.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter2 = filter1.getAggregations().get("filter2");
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 3l : 2l));
        Max max = filter2.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo(asc ? 2.0 : 4.0));

        tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "0" : "1"));
        assertThat(tag.getDocCount(), equalTo(asc ? 2l : 3l));
        filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 2l : 3l));
        filter2 = filter1.getAggregations().get("filter2");
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 2l : 3l));
        max = filter2.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo(asc ? 4.0 : 2.0));
    }
,
(startLine=930 endLine=982 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/LongTermsIT.java)
    public void singleValuedField_OrderedBySubAggregationAsc_MultiHierarchyLevels() throws Exception {
        boolean asc = randomBoolean();
        SearchResponse response = client().prepareSearch("idx").setTypes("type")
                .addAggregation(terms("tags")
                        .field("num_tag")
                        .collectMode(randomFrom(SubAggCollectionMode.values()))
                        .order(Terms.Order.aggregation("filter1>filter2>max", asc))
                        .subAggregation(filter("filter1").filter(QueryBuilders.matchAllQuery())
                                .subAggregation(filter("filter2").filter(QueryBuilders.matchAllQuery())
                                        .subAggregation(max("max").field(SINGLE_VALUED_FIELD_NAME))))
                ).execute().actionGet();


        assertSearchResponse(response);

        Terms tags = response.getAggregations().get("tags");
        assertThat(tags, notNullValue());
        assertThat(tags.getName(), equalTo("tags"));
        assertThat(tags.getBuckets().size(), equalTo(2));

        Iterator<Terms.Bucket> iters = tags.getBuckets().iterator();

        // the max for "1" is 2
        // the max for "0" is 4

        Terms.Bucket tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "1" : "0"));
        assertThat(tag.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 3l : 2l));
        Filter filter2 = filter1.getAggregations().get("filter2");
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 3l : 2l));
        Max max = filter2.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo(asc ? 2.0 : 4.0));

        tag = iters.next();
        assertThat(tag, notNullValue());
        assertThat(key(tag), equalTo(asc ? "0" : "1"));
        assertThat(tag.getDocCount(), equalTo(asc ? 2l : 3l));
        filter1 = tag.getAggregations().get("filter1");
        assertThat(filter1, notNullValue());
        assertThat(filter1.getDocCount(), equalTo(asc ? 2l : 3l));
        filter2 = filter1.getAggregations().get("filter2");
        assertThat(filter2, notNullValue());
        assertThat(filter2.getDocCount(), equalTo(asc ? 2l : 3l));
        max = filter2.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo(asc ? 4.0 : 2.0));
    }
,
>
, <(startLine=168 endLine=197 srcPath=/root/NewExperiment/elasticsearchFilter/02271/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/SumBucketIT.java)
    public void testMetricTopLevel() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(terms("terms").field("tag").subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                .addAggregation(sumBucket("sum_bucket", "terms>sum")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<? extends Terms.Bucket> buckets = terms.getBuckets();
        assertThat(buckets.size(), equalTo(interval));

        double bucketSum = 0;
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat((String) bucket.getKey(), equalTo("tag" + (i % interval)));
            assertThat(bucket.getDocCount(), greaterThan(0L));
            Sum sum = bucket.getAggregations().get("sum");
            assertThat(sum, notNullValue());
            bucketSum += sum.value();
        }

        InternalSimpleValue sumBucketValue = response.getAggregations().get("sum_bucket");
        assertThat(sumBucketValue, notNullValue());
        assertThat(sumBucketValue.getName(), equalTo("sum_bucket"));
        assertThat(sumBucketValue.value(), equalTo(bucketSum));
    }
,
(startLine=174 endLine=206 srcPath=/root/NewExperiment/elasticsearchFilter/02271/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/AvgBucketIT.java)
    public void testMetricTopLevel() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(terms("terms").field("tag").subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                .addAggregation(avgBucket("avg_bucket", "terms>sum")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<? extends Terms.Bucket> buckets = terms.getBuckets();
        assertThat(buckets.size(), equalTo(interval));

        double bucketSum = 0;
        int count = 0;
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat((String) bucket.getKey(), equalTo("tag" + (i % interval)));
            assertThat(bucket.getDocCount(), greaterThan(0L));
            Sum sum = bucket.getAggregations().get("sum");
            assertThat(sum, notNullValue());
            count++;
            bucketSum += sum.value();
        }

        double avgValue = count == 0 ? Double.NaN : (bucketSum / count);
        InternalSimpleValue avgBucketValue = response.getAggregations().get("avg_bucket");
        assertThat(avgBucketValue, notNullValue());
        assertThat(avgBucketValue.getName(), equalTo("avg_bucket"));
        assertThat(avgBucketValue.value(), equalTo(avgValue));
    }
,
>
, <(startLine=203 endLine=218 srcPath=/root/NewExperiment/elasticsearchFilter/01823/core/src/test/java/org/elasticsearch/search/suggest/completion/CategoryContextMappingTests.java)
    public void testQueryContextParsingArray() throws Exception {
        XContentBuilder builder = jsonBuilder().startArray()
                .value("context1")
                .value("context2")
                .endArray();
        XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(builder.bytes());
        CategoryContextMapping mapping = ContextBuilder.category("cat").build();
        List<ContextMapping.InternalQueryContext> internalQueryContexts = mapping.parseQueryContext(createParseContext(parser));
        assertThat(internalQueryContexts.size(), equalTo(2));
        assertThat(internalQueryContexts.get(0).context, equalTo("context1"));
        assertThat(internalQueryContexts.get(0).boost, equalTo(1));
        assertThat(internalQueryContexts.get(0).isPrefix, equalTo(false));
        assertThat(internalQueryContexts.get(1).context, equalTo("context2"));
        assertThat(internalQueryContexts.get(1).boost, equalTo(1));
        assertThat(internalQueryContexts.get(1).isPrefix, equalTo(false));
    }
,
(startLine=236 endLine=259 srcPath=/root/NewExperiment/elasticsearchFilter/01823/core/src/test/java/org/elasticsearch/search/suggest/completion/CategoryContextMappingTests.java)
    public void testQueryContextParsingObjectArray() throws Exception {
        XContentBuilder builder = jsonBuilder().startArray()
                .startObject()
                .field("context", "context1")
                .field("boost", 2)
                .field("prefix", true)
                .endObject()
                .startObject()
                .field("context", "context2")
                .field("boost", 3)
                .field("prefix", false)
                .endObject()
                .endArray();
        XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(builder.bytes());
        CategoryContextMapping mapping = ContextBuilder.category("cat").build();
        List<ContextMapping.InternalQueryContext> internalQueryContexts = mapping.parseQueryContext(createParseContext(parser));
        assertThat(internalQueryContexts.size(), equalTo(2));
        assertThat(internalQueryContexts.get(0).context, equalTo("context1"));
        assertThat(internalQueryContexts.get(0).boost, equalTo(2));
        assertThat(internalQueryContexts.get(0).isPrefix, equalTo(true));
        assertThat(internalQueryContexts.get(1).context, equalTo("context2"));
        assertThat(internalQueryContexts.get(1).boost, equalTo(3));
        assertThat(internalQueryContexts.get(1).isPrefix, equalTo(false));
    }
,
(startLine=265 endLine=284 srcPath=/root/NewExperiment/elasticsearchFilter/01823/core/src/test/java/org/elasticsearch/search/suggest/completion/CategoryContextMappingTests.java)
    public void testQueryContextParsingMixed() throws Exception {
        XContentBuilder builder = jsonBuilder().startArray()
                .startObject()
                .field("context", "context1")
                .field("boost", 2)
                .field("prefix", true)
                .endObject()
                .value("context2")
                .endArray();
        XContentParser parser = XContentFactory.xContent(XContentType.JSON).createParser(builder.bytes());
        CategoryContextMapping mapping = ContextBuilder.category("cat").build();
        List<ContextMapping.InternalQueryContext> internalQueryContexts = mapping.parseQueryContext(createParseContext(parser));
        assertThat(internalQueryContexts.size(), equalTo(2));
        assertThat(internalQueryContexts.get(0).context, equalTo("context1"));
        assertThat(internalQueryContexts.get(0).boost, equalTo(2));
        assertThat(internalQueryContexts.get(0).isPrefix, equalTo(true));
        assertThat(internalQueryContexts.get(1).context, equalTo("context2"));
        assertThat(internalQueryContexts.get(1).boost, equalTo(1));
        assertThat(internalQueryContexts.get(1).isPrefix, equalTo(false));
    }
,
>
, <(startLine=125 endLine=141 srcPath=/root/NewExperiment/elasticsearchFilter/00989/src/test/java/org/elasticsearch/index/analysis/commongrams/CommonGramsTokenFilterFactoryTests.java)
    public void testCommonGramsAnalysis() throws IOException {
        Settings settings = ImmutableSettings.settingsBuilder().loadFromClasspath("org/elasticsearch/index/analysis/commongrams/commongrams.json").build();
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick", "quick_brown", "brown", "brown_is", "is", "a", "a_fox", "fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer_file").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick", "quick_brown", "brown", "brown_is", "is", "a", "a_fox", "fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
    }
,
(startLine=198 endLine=214 srcPath=/root/NewExperiment/elasticsearchFilter/00989/src/test/java/org/elasticsearch/index/analysis/commongrams/CommonGramsTokenFilterFactoryTests.java)
    public void testQueryModeCommonGramsAnalysis() throws IOException {
        Settings settings = ImmutableSettings.settingsBuilder().loadFromClasspath("org/elasticsearch/index/analysis/commongrams/commongrams_query_mode.json").build();
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick_brown", "brown_is", "is", "a_fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer_file").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick_brown", "brown_is", "is", "a_fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
    }
,
>
, <(startLine=232 endLine=240 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/main/java/org/elasticsearch/action/count/CountRequest.java)
    public String toString() {
        String sSource = "_na_";
        try {
            sSource = XContentHelper.convertToJson(source, false);
        } catch (Exception e) {
            // ignore
        }
        return "[" + Arrays.toString(indices) + "]" + Arrays.toString(types) + ", source[" + sSource + "]";
    }
,
(startLine=226 endLine=234 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/main/java/org/elasticsearch/action/exists/ExistsRequest.java)
    public String toString() {
        String sSource = "_na_";
        try {
            sSource = XContentHelper.convertToJson(source, false);
        } catch (Exception e) {
            // ignore
        }
        return "[" + Arrays.toString(indices) + "]" + Arrays.toString(types) + ", source[" + sSource + "]";
    }
,
(startLine=105 endLine=113 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/main/java/org/elasticsearch/action/termvectors/dfs/DfsOnlyRequest.java)
    public String toString() {
        String sSource = "_na_";
        try {
            sSource = XContentHelper.convertToJson(searchRequest.source(), false);
        } catch (IOException e) {
            // ignore
        }
        return "[" + Arrays.toString(indices) + "]" + Arrays.toString(types()) + ", source[" + sSource + "]";
    }
,
(startLine=215 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/main/java/org/elasticsearch/action/admin/indices/validate/query/ValidateQueryRequest.java)
    public String toString() {
        String sSource = "_na_";
        try {
            sSource = XContentHelper.convertToJson(source, false);
        } catch (Exception e) {
            // ignore
        }
        return "[" + Arrays.toString(indices) + "]" + Arrays.toString(types) + ", source[" + sSource + "], explain:" + explain + 
                ", rewrite:" + rewrite;
    }
,
(startLine=277 endLine=285 srcPath=/root/NewExperiment/elasticsearchFilter/01715/plugins/delete-by-query/src/main/java/org/elasticsearch/action/deletebyquery/DeleteByQueryRequest.java)
    public String toString() {
        String sSource = "_na_";
        try {
            sSource = XContentHelper.convertToJson(source, false);
        } catch (Exception e) {
            // ignore
        }
        return "delete-by-query [" + Arrays.toString(indices) + "][" + Arrays.toString(types) + "], source[" + sSource + "]";
    }
,
>
, <(startLine=249 endLine=259 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/bootstrap/JarHellTests.java)
    public void testEmptyClassPathUnix() throws Exception {
        assumeTrue("test is designed for unix-like systems only", ":".equals(System.getProperty("path.separator")));
        assumeTrue("test is designed for unix-like systems only", "/".equals(System.getProperty("file.separator")));

        try {
            JarHell.parseClassPath(":/element1:/element2");
            fail("should have hit exception");
        } catch (IllegalStateException expected) {
            assertTrue(expected.getMessage().contains("should not contain empty elements"));
        }
    }
,
(startLine=278 endLine=288 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/bootstrap/JarHellTests.java)
    public void testEmptyClassPathWindows() throws Exception {
        assumeTrue("test is designed for windows-like systems only", ";".equals(System.getProperty("path.separator")));
        assumeTrue("test is designed for windows-like systems only", "\\".equals(System.getProperty("file.separator")));

        try {
            JarHell.parseClassPath(";c:\\element1;c:\\element2");
            fail("should have hit exception");
        } catch (IllegalStateException expected) {
            assertTrue(expected.getMessage().contains("should not contain empty elements"));
        }
    }
,
>
, <(startLine=124 endLine=152 srcPath=/root/NewExperiment/elasticsearchFilter/01834/core/src/main/java/org/elasticsearch/search/aggregations/bucket/children/ChildrenAggregationBuilder.java)
    public static ChildrenAggregationBuilder parse(String aggregationName, QueryParseContext context) throws IOException {
        String childType = null;

        XContentParser.Token token;
        String currentFieldName = null;
        XContentParser parser = context.parser();
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.VALUE_STRING) {
                if ("type".equals(currentFieldName)) {
                    childType = parser.text();
                } else {
                    throw new ParsingException(parser.getTokenLocation(),
                            "Unknown key for a " + token + " in [" + aggregationName + "]: [" + currentFieldName + "].");
                }
            } else {
                throw new ParsingException(parser.getTokenLocation(), "Unexpected token " + token + " in [" + aggregationName + "].");
            }
        }

        if (childType == null) {
            throw new ParsingException(parser.getTokenLocation(),
                    "Missing [child_type] field for children aggregation [" + aggregationName + "]");
        }


        return new ChildrenAggregationBuilder(aggregationName, childType);
    }
,
(startLine=133 endLine=160 srcPath=/root/NewExperiment/elasticsearchFilter/01834/core/src/main/java/org/elasticsearch/search/aggregations/bucket/nested/ReverseNestedAggregationBuilder.java)
    public static ReverseNestedAggregationBuilder parse(String aggregationName, QueryParseContext context) throws IOException {
        String path = null;

        XContentParser.Token token;
        String currentFieldName = null;
        XContentParser parser = context.parser();
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.VALUE_STRING) {
                if ("path".equals(currentFieldName)) {
                    path = parser.text();
                } else {
                    throw new ParsingException(parser.getTokenLocation(),
                            "Unknown key for a " + token + " in [" + aggregationName + "]: [" + currentFieldName + "].");
                }
            } else {
                throw new ParsingException(parser.getTokenLocation(), "Unexpected token " + token + " in [" + aggregationName + "].");
            }
        }

        ReverseNestedAggregationBuilder factory = new ReverseNestedAggregationBuilder(
                aggregationName);
        if (path != null) {
            factory.path(path);
        }
        return factory;
    }
,
(startLine=109 endLine=136 srcPath=/root/NewExperiment/elasticsearchFilter/01834/core/src/main/java/org/elasticsearch/search/aggregations/bucket/nested/NestedAggregationBuilder.java)
    public static NestedAggregationBuilder parse(String aggregationName, QueryParseContext context) throws IOException {
        String path = null;

        XContentParser.Token token;
        String currentFieldName = null;
        XContentParser parser = context.parser();
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.VALUE_STRING) {
                if (context.getParseFieldMatcher().match(currentFieldName, NestedAggregator.PATH_FIELD)) {
                    path = parser.text();
                } else {
                    throw new ParsingException(parser.getTokenLocation(),
                            "Unknown key for a " + token + " in [" + aggregationName + "]: [" + currentFieldName + "].");
                }
            } else {
                throw new ParsingException(parser.getTokenLocation(), "Unexpected token " + token + " in [" + aggregationName + "].");
            }
        }

        if (path == null) {
            // "field" doesn't exist, so we fall back to the context of the ancestors
            throw new ParsingException(parser.getTokenLocation(), "Missing [path] field for nested aggregation [" + aggregationName + "]");
        }

        return new NestedAggregationBuilder(aggregationName, path);
    }
,
>
, <(startLine=87 endLine=107 srcPath=/root/NewExperiment/elasticsearchFilter/00719/src/test/java/org/elasticsearch/benchmark/search/facet/HistogramFacetSearchBenchmark.java)
            for (; i <= ITERS; i++) {
                BulkRequestBuilder request = client.prepareBulk();
                for (int j = 0; j < BATCH; j++) {
                    counter++;
                    XContentBuilder source = jsonBuilder().startObject()
                            .field("id", Integer.valueOf(counter))
                            .field("l_value", lValues[counter % lValues.length])
                            .field("date", new Date())
                            .endObject();
                    request.add(Requests.indexRequest("test").type("type1").id(Integer.toString(counter))
                            .source(source));
                }
                BulkResponse response = request.execute().actionGet();
                if (response.hasFailures()) {
                    System.err.println("--> failures...");
                }
                if (((i * BATCH) % 10000) == 0) {
                    System.out.println("--> Indexed " + (i * BATCH) + " took " + stopWatch.stop().lastTaskTime());
                    stopWatch.start();
                }
            }
,
(startLine=85 endLine=107 srcPath=/root/NewExperiment/elasticsearchFilter/00719/src/test/java/org/elasticsearch/benchmark/search/facet/QueryFilterFacetSearchBenchmark.java)
            for (; i <= ITERS; i++) {
                BulkRequestBuilder request = client.prepareBulk();
                for (int j = 0; j < BATCH; j++) {
                    counter++;

                    XContentBuilder builder = jsonBuilder().startObject();
                    builder.field("id", Integer.toString(counter));
                    builder.field("l_value", lValues[counter % lValues.length]);

                    builder.endObject();

                    request.add(Requests.indexRequest("test").type("type1").id(Integer.toString(counter))
                            .source(builder));
                }
                BulkResponse response = request.execute().actionGet();
                if (response.hasFailures()) {
                    System.err.println("--> failures...");
                }
                if (((i * BATCH) % 10000) == 0) {
                    System.out.println("--> Indexed " + (i * BATCH) + " took " + stopWatch.stop().lastTaskTime());
                    stopWatch.start();
                }
            }
,
>
, <(startLine=2375 endLine=2409 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  public final LinkvarContext linkvar() throws RecognitionException {
    LinkvarContext _localctx = new LinkvarContext(_ctx, getState());
    enterRule(_localctx, 40, RULE_linkvar);
    try {
      enterOuterAlt(_localctx, 1);
      {
      setState(315);
      identifier();
      setState(318);
      switch ( getInterpreter().adaptivePredict(_input,29,_ctx) ) {
      case 1:
        {
        setState(316);
        linkdot();
        }
        break;
      case 2:
        {
        setState(317);
        linkbrace();
        }
        break;
      }
      }
    }
    catch (RecognitionException re) {
      _localctx.exception = re;
      _errHandler.reportError(this, re);
      _errHandler.recover(this, re);
    }
    finally {
      exitRule();
    }
    return _localctx;
  }
,
(startLine=2613 endLine=2647 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  public final LinkstringContext linkstring() throws RecognitionException {
    LinkstringContext _localctx = new LinkstringContext(_ctx, getState());
    enterRule(_localctx, 46, RULE_linkstring);
    try {
      enterOuterAlt(_localctx, 1);
      {
      setState(344);
      match(STRING);
      setState(347);
      switch ( getInterpreter().adaptivePredict(_input,35,_ctx) ) {
      case 1:
        {
        setState(345);
        linkdot();
        }
        break;
      case 2:
        {
        setState(346);
        linkbrace();
        }
        break;
      }
      }
    }
    catch (RecognitionException re) {
      _localctx.exception = re;
      _errHandler.reportError(this, re);
      _errHandler.recover(this, re);
    }
    finally {
      exitRule();
    }
    return _localctx;
  }
,
>
, <(startLine=40 endLine=53 srcPath=/root/NewExperiment/elasticsearchFilter/01098/src/test/java/org/elasticsearch/index/mapper/source/CompressSourceMappingTests.java)
    public void testCompressDisabled() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("_source").field("compress", false).endObject()
                .endObject().endObject().string();

        DocumentMapper documentMapper = MapperTestUtils.newParser().parse(mapping);

        ParsedDocument doc = documentMapper.parse("type", "1", XContentFactory.jsonBuilder().startObject()
                .field("field1", "value1")
                .field("field2", "value2")
                .endObject().bytes());
        BytesRef bytes = doc.rootDoc().getBinaryValue("_source");
        assertThat(CompressorFactory.isCompressed(bytes.bytes, bytes.offset, bytes.length), equalTo(false));
    }
,
(startLine=56 endLine=70 srcPath=/root/NewExperiment/elasticsearchFilter/01098/src/test/java/org/elasticsearch/index/mapper/source/CompressSourceMappingTests.java)
    public void testCompressEnabled() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("_source").field("compress", true).endObject()
                .endObject().endObject().string();

        DocumentMapper documentMapper = MapperTestUtils.newParser().parse(mapping);

        ParsedDocument doc = documentMapper.parse("type", "1", XContentFactory.jsonBuilder().startObject()
                .field("field1", "value1")
                .field("field2", "value2")
                .endObject().bytes());

        BytesRef bytes = doc.rootDoc().getBinaryValue("_source");
        assertThat(CompressorFactory.isCompressed(bytes.bytes, bytes.offset, bytes.length), equalTo(true));
    }
,
>
, <(startLine=133 endLine=199 srcPath=/root/NewExperiment/elasticsearchFilter/01850/plugins/discovery-ec2/src/main/java/org/elasticsearch/cloud/aws/AwsEc2ServiceImpl.java)
    protected static String findEndpoint(Logger logger, Settings settings) {
        String endpoint = null;
        if (CLOUD_EC2.ENDPOINT_SETTING.exists(settings)) {
            endpoint = CLOUD_EC2.ENDPOINT_SETTING.get(settings);
            logger.debug("using explicit ec2 endpoint [{}]", endpoint);
        } else if (REGION_SETTING.exists(settings) || CLOUD_EC2.REGION_SETTING.exists(settings)) {
            final String region = CLOUD_EC2.REGION_SETTING.get(settings);
            switch (region) {
                case "us-east-1":
                case "us-east":
                    endpoint = "ec2.us-east-1.amazonaws.com";
                    break;
                case "us-east-2":
                    endpoint = "ec2.us-east-2.amazonaws.com";
                    break;
                case "us-west":
                case "us-west-1":
                    endpoint = "ec2.us-west-1.amazonaws.com";
                    break;
                case "us-west-2":
                    endpoint = "ec2.us-west-2.amazonaws.com";
                    break;
                case "ap-southeast":
                case "ap-southeast-1":
                    endpoint = "ec2.ap-southeast-1.amazonaws.com";
                    break;
                case "ap-south":
                case "ap-south-1":
                    endpoint = "ec2.ap-south-1.amazonaws.com";
                    break;
                case "us-gov-west":
                case "us-gov-west-1":
                    endpoint = "ec2.us-gov-west-1.amazonaws.com";
                    break;
                case "ap-southeast-2":
                    endpoint = "ec2.ap-southeast-2.amazonaws.com";
                    break;
                case "ap-northeast":
                case "ap-northeast-1":
                    endpoint = "ec2.ap-northeast-1.amazonaws.com";
                    break;
                case "ap-northeast-2":
                    endpoint = "ec2.ap-northeast-2.amazonaws.com";
                    break;
                case "eu-west":
                case "eu-west-1":
                    endpoint = "ec2.eu-west-1.amazonaws.com";
                    break;
                case "eu-central":
                case "eu-central-1":
                    endpoint = "ec2.eu-central-1.amazonaws.com";
                    break;
                case "sa-east":
                case "sa-east-1":
                    endpoint = "ec2.sa-east-1.amazonaws.com";
                    break;
                case "cn-north":
                case "cn-north-1":
                    endpoint = "ec2.cn-north-1.amazonaws.com.cn";
                    break;
                default:
                    throw new IllegalArgumentException("No automatic endpoint could be derived from region [" + region + "]");
            }
            logger.debug("using ec2 region [{}], with endpoint [{}]", region, endpoint);
        }
        return endpoint;
    }
,
(startLine=166 endLine=226 srcPath=/root/NewExperiment/elasticsearchFilter/01850/plugins/repository-s3/src/main/java/org/elasticsearch/cloud/aws/InternalAwsS3Service.java)
    private static String getEndpoint(String region) {
        final String endpoint;
        switch (region) {
            case "us-east":
            case "us-east-1":
                endpoint = "s3.amazonaws.com";
                break;
            case "us-east-2":
                endpoint = "s3.us-east-2.amazonaws.com";
                break;
            case "us-west":
            case "us-west-1":
                endpoint = "s3-us-west-1.amazonaws.com";
                break;
            case "us-west-2":
                endpoint = "s3-us-west-2.amazonaws.com";
                break;
            case "ap-south":
            case "ap-south-1":
                endpoint = "s3-ap-south-1.amazonaws.com";
                break;
            case "ap-southeast":
            case "ap-southeast-1":
                endpoint = "s3-ap-southeast-1.amazonaws.com";
                break;
            case "ap-southeast-2":
                endpoint = "s3-ap-southeast-2.amazonaws.com";
                break;
            case "ap-northeast":
            case "ap-northeast-1":
                endpoint = "s3-ap-northeast-1.amazonaws.com";
                break;
            case "ap-northeast-2":
                endpoint = "s3-ap-northeast-2.amazonaws.com";
                break;
            case "eu-west":
            case "eu-west-1":
                endpoint = "s3-eu-west-1.amazonaws.com";
                break;
            case "eu-central":
            case "eu-central-1":
                endpoint = "s3.eu-central-1.amazonaws.com";
                break;
            case "sa-east":
            case "sa-east-1":
                endpoint = "s3-sa-east-1.amazonaws.com";
                break;
            case "cn-north":
            case "cn-north-1":
                endpoint = "s3.cn-north-1.amazonaws.com.cn";
                break;
            case "us-gov-west":
            case "us-gov-west-1":
                endpoint = "s3-us-gov-west-1.amazonaws.com";
                break;
            default:
                throw new IllegalArgumentException("No automatic endpoint could be derived from region [" + region + "]");
        }

        return endpoint;
    }
,
>
, <(startLine=900 endLine=912 srcPath=/root/NewExperiment/elasticsearchFilter/01317/src/main/java/org/elasticsearch/common/lucene/search/XMoreLikeThis.java)
    public String[] retrieveInterestingTerms(int docNum) throws IOException {
        ArrayList<Object> al = new ArrayList<>(maxQueryTerms);
        PriorityQueue<Object[]> pq = retrieveTerms(docNum);
        Object cur;
        int lim = maxQueryTerms; // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...
        // we just want to return the top words
        while (((cur = pq.pop()) != null) && lim-- > 0) {
            Object[] ar = (Object[]) cur;
            al.add(ar[0]); // the 1st entry is the interesting word
        }
        String[] res = new String[al.size()];
        return al.toArray(res);
    }
,
(startLine=924 endLine=936 srcPath=/root/NewExperiment/elasticsearchFilter/01317/src/main/java/org/elasticsearch/common/lucene/search/XMoreLikeThis.java)
    public String[] retrieveInterestingTerms(Reader r, String fieldName) throws IOException {
        ArrayList<Object> al = new ArrayList<>(maxQueryTerms);
        PriorityQueue<Object[]> pq = retrieveTerms(r, fieldName);
        Object cur;
        int lim = maxQueryTerms; // have to be careful, retrieveTerms returns all words but that's probably not useful to our caller...
        // we just want to return the top words
        while (((cur = pq.pop()) != null) && lim-- > 0) {
            Object[] ar = (Object[]) cur;
            al.add(ar[0]); // the 1st entry is the interesting word
        }
        String[] res = new String[al.size()];
        return al.toArray(res);
    }
,
>
, <(startLine=392 endLine=410 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/test/framework/src/main/java/org/elasticsearch/indices/analysis/AnalysisFactoryTestCase.java)
        for (Map.Entry<String, Class<?>> entry : getPreConfiguredTokenFilters().entrySet()) {
            String name = entry.getKey();
            Class<?> luceneFactory = entry.getValue();
            PreConfiguredTokenFilter filter = preConfiguredTokenFilters.remove(name);
            assertNotNull("test claims pre built token filter [" + name + "] should be available but it wasn't", filter);
            if (luceneFactory == Void.class) {
                continue;
            }
            if (luceneFactory == null) {
                luceneFactory = TokenFilterFactory.lookupClass(toCamelCase(name));
            }
            assertThat(luceneFactory, typeCompatibleWith(TokenFilterFactory.class));
            if (filter.shouldUseFilterForMultitermQueries()) {
                actual.add("token filter [" + name + "]");
            }
            if (org.apache.lucene.analysis.util.MultiTermAwareComponent.class.isAssignableFrom(luceneFactory)) {
                expected.add("token filter [" + name + "]");
            }
        }
,
(startLine=438 endLine=456 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/test/framework/src/main/java/org/elasticsearch/indices/analysis/AnalysisFactoryTestCase.java)
        for (Map.Entry<String, Class<?>> entry : getPreConfiguredCharFilters().entrySet()) {
            String name = entry.getKey();
            Class<?> luceneFactory = entry.getValue();
            PreConfiguredCharFilter filter = preConfiguredCharFilters.remove(name);
            assertNotNull("test claims pre built char filter [" + name + "] should be available but it wasn't", filter);
            if (luceneFactory == Void.class) {
                continue;
            }
            if (luceneFactory == null) {
                luceneFactory = TokenFilterFactory.lookupClass(toCamelCase(name));
            }
            assertThat(luceneFactory, typeCompatibleWith(CharFilterFactory.class));
            if (filter.shouldUseFilterForMultitermQueries()) {
                actual.add(filter);
            }
            if (org.apache.lucene.analysis.util.MultiTermAwareComponent.class.isAssignableFrom(luceneFactory)) {
                expected.add("token filter [" + name + "]");
            }
        }
,
>
, <(startLine=76 endLine=86 srcPath=/root/NewExperiment/elasticsearchFilter/01999/core/src/test/java/org/elasticsearch/action/bulk/byscroll/DeleteByQueryRequestTests.java)
    public void testTypesGetter() {
        int numTypes = between(1, 50);
        String[] types = new String[numTypes];
        for (int i = 0; i < numTypes; i++) {
            types[i] = randomSimpleString(random(), 1, 30);
        }
        SearchRequest searchRequest = new SearchRequest();
        searchRequest.types(types);
        DeleteByQueryRequest request = new DeleteByQueryRequest(searchRequest);
        assertArrayEquals(request.types(), types);
    }
,
(startLine=88 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/01999/core/src/test/java/org/elasticsearch/action/bulk/byscroll/DeleteByQueryRequestTests.java)
    public void testTypesSetter() {
        int numTypes = between(1, 50);
        String[] types = new String[numTypes];
        for (int i = 0; i < numTypes; i++) {
            types[i] = randomSimpleString(random(), 1, 30);
        }
        SearchRequest searchRequest = new SearchRequest();
        DeleteByQueryRequest request = new DeleteByQueryRequest(searchRequest);
        request.types(types);
        assertArrayEquals(request.types(), types);
    }
,
>
, <(startLine=124 endLine=133 srcPath=/root/NewExperiment/elasticsearchFilter/01116/src/main/java/org/elasticsearch/search/facet/terms/longs/TermsLongFacetExecutor.java)
            } else {
                BoundedTreeSet<InternalLongTermsFacet.LongEntry> ordered = new BoundedTreeSet<InternalLongTermsFacet.LongEntry>(comparatorType.comparator(), shardSize);
                for (int i = 0; i < states.length; i++) {
                    if (states[i]) {
                        ordered.add(new InternalLongTermsFacet.LongEntry(keys[i], values[i]));
                    }
                }
                facets.release();
                return new InternalLongTermsFacet(facetName, comparatorType, size, ordered, missing, total);
            }
,
(startLine=124 endLine=133 srcPath=/root/NewExperiment/elasticsearchFilter/01116/src/main/java/org/elasticsearch/search/facet/terms/doubles/TermsDoubleFacetExecutor.java)
            } else {
                BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry> ordered = new BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>(comparatorType.comparator(), shardSize);
                for (int i = 0; i < states.length; i++) {
                    if (states[i]) {
                        ordered.add(new InternalDoubleTermsFacet.DoubleEntry(keys[i], values[i]));
                    }
                }
                facets.release();
                return new InternalDoubleTermsFacet(facetName, comparatorType, size, ordered, missing, total);
            }
,
>
, <(startLine=53 endLine=117 srcPath=/root/NewExperiment/elasticsearchFilter/02330/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsTests.java)
    protected SignificantTermsAggregationBuilder createTestAggregatorBuilder() {
        String name = randomAlphaOfLengthBetween(3, 20);
        SignificantTermsAggregationBuilder factory = new SignificantTermsAggregationBuilder(name, null);
        String field = randomAlphaOfLengthBetween(3, 20);
        randomFieldOrScript(factory, field);

        if (randomBoolean()) {
            factory.missing("MISSING");
        }
        if (randomBoolean()) {
            factory.bucketCountThresholds().setRequiredSize(randomIntBetween(1, Integer.MAX_VALUE));

        }
        if (randomBoolean()) {
            factory.bucketCountThresholds().setShardSize(randomIntBetween(1, Integer.MAX_VALUE));
        }
        if (randomBoolean()) {
            int minDocCount = randomInt(4);
            switch (minDocCount) {
            case 0:
                break;
            case 1:
            case 2:
            case 3:
            case 4:
                minDocCount = randomIntBetween(0, Integer.MAX_VALUE);
                break;
            }
            factory.bucketCountThresholds().setMinDocCount(minDocCount);
        }
        if (randomBoolean()) {
            int shardMinDocCount = randomInt(4);
            switch (shardMinDocCount) {
            case 0:
                break;
            case 1:
            case 2:
            case 3:
            case 4:
                shardMinDocCount = randomIntBetween(0, Integer.MAX_VALUE);
                break;
            default:
                fail();
            }
            factory.bucketCountThresholds().setShardMinDocCount(shardMinDocCount);
        }
        if (randomBoolean()) {
            factory.executionHint(randomFrom(executionHints));
        }
        if (randomBoolean()) {
            factory.format("###.##");
        }
        if (randomBoolean()) {
            IncludeExclude incExc = getIncludeExclude();
            factory.includeExclude(incExc);
        }
        if (randomBoolean()) {
            SignificanceHeuristic significanceHeuristic = getSignificanceHeuristic();
            factory.significanceHeuristic(significanceHeuristic);
        }
        if (randomBoolean()) {
            factory.backgroundFilter(QueryBuilders.termsQuery("foo", "bar"));
        }
        return factory;
    }
,
(startLine=33 endLine=92 srcPath=/root/NewExperiment/elasticsearchFilter/02330/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTextTests.java)
    protected SignificantTextAggregationBuilder createTestAggregatorBuilder() {
        String name = randomAlphaOfLengthBetween(3, 20);
        String field = randomAlphaOfLengthBetween(3, 20);
        SignificantTextAggregationBuilder factory = new SignificantTextAggregationBuilder(name, field);
        if (randomBoolean()) {
            factory.bucketCountThresholds().setRequiredSize(randomIntBetween(1, Integer.MAX_VALUE));
        }
        if (randomBoolean()) {
            factory.sourceFieldNames(Arrays.asList(new String []{"foo", "bar"}));
        }
        
        if (randomBoolean()) {
            factory.bucketCountThresholds().setShardSize(randomIntBetween(1, Integer.MAX_VALUE));
        }
        if (randomBoolean()) {
            int minDocCount = randomInt(4);
            switch (minDocCount) {
            case 0:
                break;
            case 1:
            case 2:
            case 3:
            case 4:
                minDocCount = randomIntBetween(0, Integer.MAX_VALUE);
                break;
            }
            factory.bucketCountThresholds().setMinDocCount(minDocCount);
        }
        if (randomBoolean()) {
            int shardMinDocCount = randomInt(4);
            switch (shardMinDocCount) {
            case 0:
                break;
            case 1:
            case 2:
            case 3:
            case 4:
                shardMinDocCount = randomIntBetween(0, Integer.MAX_VALUE);
                break;
            default:
                fail();
            }
            factory.bucketCountThresholds().setShardMinDocCount(shardMinDocCount);
        }

        factory.filterDuplicateText(randomBoolean());

        if (randomBoolean()) {
            IncludeExclude incExc = SignificantTermsTests.getIncludeExclude();
            factory.includeExclude(incExc);
        }
        if (randomBoolean()) {
            SignificanceHeuristic significanceHeuristic = SignificantTermsTests.getSignificanceHeuristic();
            factory.significanceHeuristic(significanceHeuristic);
        }
        if (randomBoolean()) {
            factory.backgroundFilter(QueryBuilders.termsQuery("foo", "bar"));
        }
        return factory;
    }
,
>
, <(startLine=86 endLine=104 srcPath=/root/NewExperiment/elasticsearchFilter/01769/core/src/main/java/org/elasticsearch/search/highlight/HighlighterParseElement.java)
                } else if ("fields".equals(topLevelFieldName)) {
                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                        if (token == XContentParser.Token.START_OBJECT) {
                            String highlightFieldName = null;
                            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                                if (token == XContentParser.Token.FIELD_NAME) {
                                    if (highlightFieldName != null) {
                                        throw new IllegalArgumentException("If highlighter fields is an array it must contain objects containing a single field");
                                    }
                                    highlightFieldName = parser.currentName();
                                } else if (token == XContentParser.Token.START_OBJECT) {
                                    fieldsOptions.add(Tuple.tuple(highlightFieldName, parseFields(parser, queryShardContext)));
                                }
                            }
                        } else {
                            throw new IllegalArgumentException("If highlighter fields is an array it must contain objects containing a single field");
                        }
                    }
                }
,
(startLine=264 endLine=283 srcPath=/root/NewExperiment/elasticsearchFilter/01769/core/src/main/java/org/elasticsearch/search/highlight/HighlightBuilder.java)
                } else if (parseContext.parseFieldMatcher().match(topLevelFieldName, FIELDS_FIELD)) {
                    highlightBuilder.useExplicitFieldOrder(true);
                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                        if (token == XContentParser.Token.START_OBJECT) {
                            String highlightFieldName = null;
                            while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                                if (token == XContentParser.Token.FIELD_NAME) {
                                    if (highlightFieldName != null) {
                                        throw new ParsingException(parser.getTokenLocation(), "If highlighter fields is an array it must contain objects containing a single field");
                                    }
                                    highlightFieldName = parser.currentName();
                                } else if (token == XContentParser.Token.START_OBJECT) {
                                    highlightBuilder.field(Field.fromXContent(highlightFieldName, parseContext));
                                }
                            }
                        } else {
                            throw new ParsingException(parser.getTokenLocation(), "If highlighter fields is an array it must contain objects containing a single field");
                        }
                    }
                } else {
,
>
, <(startLine=498 endLine=511 srcPath=/root/NewExperiment/elasticsearchFilter/01794/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java)
                } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LAT_SUFFIX)) {
                    String maybeFieldName = currentFieldName.substring(0,
                            currentFieldName.length() - GeoPointFieldMapper.Names.LAT_SUFFIX.length());
                    if (fieldName == null || fieldName.equals(maybeFieldName)) {
                        fieldName = maybeFieldName;
                    } else {
                        throw new ParsingException(parser.getTokenLocation(), "[" + GeoDistanceRangeQueryBuilder.NAME +
                                "] field name already set to [" + fieldName + "] but found [" + currentFieldName + "]");
                    }
                    if (point == null) {
                        point = new GeoPoint();
                    }
                    point.resetLat(parser.doubleValue());
                } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LON_SUFFIX)) {
,
(startLine=511 endLine=524 srcPath=/root/NewExperiment/elasticsearchFilter/01794/core/src/main/java/org/elasticsearch/index/query/GeoDistanceRangeQueryBuilder.java)
                } else if (currentFieldName.endsWith(GeoPointFieldMapper.Names.LON_SUFFIX)) {
                    String maybeFieldName = currentFieldName.substring(0,
                            currentFieldName.length() - GeoPointFieldMapper.Names.LON_SUFFIX.length());
                    if (fieldName == null || fieldName.equals(maybeFieldName)) {
                        fieldName = maybeFieldName;
                    } else {
                        throw new ParsingException(parser.getTokenLocation(), "[" + GeoDistanceRangeQueryBuilder.NAME +
                                "] field name already set to [" + fieldName + "] but found [" + currentFieldName + "]");
                    }
                    if (point == null) {
                        point = new GeoPoint();
                    }
                    point.resetLon(parser.doubleValue());
                } else if (parseContext.getParseFieldMatcher().match(currentFieldName, NAME_FIELD)) {
,
>
, <(startLine=151 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testSingleValuedField() throws Exception {
        double sigma = randomDouble() * randomIntBetween(1, 10);
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(extendedStats("stats").field("value").sigma(sigma))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (1+2+3+4+5+6+7+8+9+10) / 10));
        assertThat(stats.getMin(), equalTo(1.0));
        assertThat(stats.getMax(), equalTo(10.0));
        assertThat(stats.getSum(), equalTo((double) 1+2+3+4+5+6+7+8+9+10));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 1+4+9+16+25+36+49+64+81+100));
        assertThat(stats.getVariance(), equalTo(variance(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)));
        checkUpperLowerBounds(stats, sigma);
    }
,
(startLine=174 endLine=196 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testSingleValuedFieldDefaultSigma() throws Exception {
        // Same as previous test, but uses a default value for sigma

        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(extendedStats("stats").field("value"))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (1+2+3+4+5+6+7+8+9+10) / 10));
        assertThat(stats.getMin(), equalTo(1.0));
        assertThat(stats.getMax(), equalTo(10.0));
        assertThat(stats.getSum(), equalTo((double) 1+2+3+4+5+6+7+8+9+10));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 1+4+9+16+25+36+49+64+81+100));
        assertThat(stats.getVariance(), equalTo(variance(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)));
        checkUpperLowerBounds(stats, 2);
    }
,
(startLine=274 endLine=295 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testSingleValuedFieldPartiallyUnmapped() throws Exception {
        double sigma = randomDouble() * randomIntBetween(1, 10);
        SearchResponse searchResponse = client().prepareSearch("idx", "idx_unmapped")
                .setQuery(matchAllQuery())
                .addAggregation(extendedStats("stats").field("value").sigma(sigma))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (1+2+3+4+5+6+7+8+9+10) / 10));
        assertThat(stats.getMin(), equalTo(1.0));
        assertThat(stats.getMax(), equalTo(10.0));
        assertThat(stats.getSum(), equalTo((double) 1+2+3+4+5+6+7+8+9+10));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 1+4+9+16+25+36+49+64+81+100));
        assertThat(stats.getVariance(), equalTo(variance(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)));
        checkUpperLowerBounds(stats, sigma);
    }
,
(startLine=298 endLine=324 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testSingleValuedFieldWithValueScript() throws Exception {
        double sigma = randomDouble() * randomIntBetween(1, 10);
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(
                        extendedStats("stats")
                                .field("value")
                                .script(new Script(ScriptType.INLINE,
                                    AggregationTestScriptsPlugin.NAME, "_value + 1", Collections.emptyMap()))
                                .sigma(sigma))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (2+3+4+5+6+7+8+9+10+11) / 10));
        assertThat(stats.getMin(), equalTo(2.0));
        assertThat(stats.getMax(), equalTo(11.0));
        assertThat(stats.getSum(), equalTo((double) 2+3+4+5+6+7+8+9+10+11));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 4+9+16+25+36+49+64+81+100+121));
        assertThat(stats.getVariance(), equalTo(variance(2, 3, 4, 5, 6, 7, 8, 9, 10, 11)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(2, 3, 4, 5, 6, 7, 8, 9, 10, 11)));
        checkUpperLowerBounds(stats, sigma);
    }
,
(startLine=327 endLine=354 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testSingleValuedFieldWithValueScriptWithParams() throws Exception {
        Map<String, Object> params = new HashMap<>();
        params.put("inc", 1);
        double sigma = randomDouble() * randomIntBetween(1, 10);
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(
                        extendedStats("stats")
                                .field("value")
                                .script(new Script(ScriptType.INLINE, AggregationTestScriptsPlugin.NAME, "_value + inc", params))
                                .sigma(sigma))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (2+3+4+5+6+7+8+9+10+11) / 10));
        assertThat(stats.getMin(), equalTo(2.0));
        assertThat(stats.getMax(), equalTo(11.0));
        assertThat(stats.getSum(), equalTo((double) 2+3+4+5+6+7+8+9+10+11));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 4+9+16+25+36+49+64+81+100+121));
        assertThat(stats.getVariance(), equalTo(variance(2, 3, 4, 5, 6, 7, 8, 9, 10, 11)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(2, 3, 4, 5, 6, 7, 8, 9, 10, 11)));
        checkUpperLowerBounds(stats, sigma);
    }
,
(startLine=440 endLine=465 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testScriptSingleValued() throws Exception {
        double sigma = randomDouble() * randomIntBetween(1, 10);
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(
                        extendedStats("stats")
                                .script(new Script(ScriptType.INLINE,
                                    AggregationTestScriptsPlugin.NAME, "doc['value'].value", Collections.emptyMap()))
                                .sigma(sigma))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (1+2+3+4+5+6+7+8+9+10) / 10));
        assertThat(stats.getMin(), equalTo(1.0));
        assertThat(stats.getMax(), equalTo(10.0));
        assertThat(stats.getSum(), equalTo((double) 1+2+3+4+5+6+7+8+9+10));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 1+4+9+16+25+36+49+64+81+100));
        assertThat(stats.getVariance(), equalTo(variance(1, 2, 3, 4, 5, 6, 7, 8 ,9, 10)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(1, 2, 3, 4, 5, 6, 7, 8 ,9, 10)));
        checkUpperLowerBounds(stats, sigma);
    }
,
(startLine=468 endLine=497 srcPath=/root/NewExperiment/elasticsearchFilter/02042/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ExtendedStatsIT.java)
    public void testScriptSingleValuedWithParams() throws Exception {
        Map<String, Object> params = new HashMap<>();
        params.put("inc", 1);

        Script script = new Script(ScriptType.INLINE, AggregationTestScriptsPlugin.NAME, "doc['value'].value + inc", params);

        double sigma = randomDouble() * randomIntBetween(1, 10);
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(
                        extendedStats("stats")
                                .script(script)
                                .sigma(sigma))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        ExtendedStats stats = searchResponse.getAggregations().get("stats");
        assertThat(stats, notNullValue());
        assertThat(stats.getName(), equalTo("stats"));
        assertThat(stats.getAvg(), equalTo((double) (2+3+4+5+6+7+8+9+10+11) / 10));
        assertThat(stats.getMin(), equalTo(2.0));
        assertThat(stats.getMax(), equalTo(11.0));
        assertThat(stats.getSum(), equalTo((double) 2+3+4+5+6+7+8+9+10+11));
        assertThat(stats.getCount(), equalTo(10L));
        assertThat(stats.getSumOfSquares(), equalTo((double) 4+9+16+25+36+49+64+81+100+121));
        assertThat(stats.getVariance(), equalTo(variance(2, 3, 4, 5, 6, 7, 8 ,9, 10, 11)));
        assertThat(stats.getStdDeviation(), equalTo(stdDev(2, 3, 4, 5, 6, 7, 8 ,9, 10, 11)));
        checkUpperLowerBounds(stats, sigma);
    }
,
>
, <(startLine=176 endLine=191 srcPath=/root/NewExperiment/elasticsearchFilter/01769/plugins/lang-plan-a/src/test/java/org/elasticsearch/plan/a/CompoundAssignmentTests.java)
    public void testLeftShift() {
        // byte
        assertEquals((byte) 60, exec("byte x = 15; x <<= 2; return x;"));
        assertEquals((byte) -60, exec("byte x = (byte) -15; x <<= 2; return x;"));
        // short
        assertEquals((short) 60, exec("short x = 15; x <<= 2; return x;"));
        assertEquals((short) -60, exec("short x = (short) -15; x <<= 2; return x;"));
        // char
        assertEquals((char) 60, exec("char x = (char) 15; x <<= 2; return x;"));
        // int
        assertEquals(60, exec("int x = 15; x <<= 2; return x;"));
        assertEquals(-60, exec("int x = -15; x <<= 2; return x;"));
        // long
        assertEquals(60L, exec("long x = 15L; x <<= 2; return x;"));
        assertEquals(-60L, exec("long x = -15L; x <<= 2; return x;"));
    }
,
(startLine=193 endLine=208 srcPath=/root/NewExperiment/elasticsearchFilter/01769/plugins/lang-plan-a/src/test/java/org/elasticsearch/plan/a/CompoundAssignmentTests.java)
    public void testRightShift() {
        // byte
        assertEquals((byte) 15, exec("byte x = 60; x >>= 2; return x;"));
        assertEquals((byte) -15, exec("byte x = (byte) -60; x >>= 2; return x;"));
        // short
        assertEquals((short) 15, exec("short x = 60; x >>= 2; return x;"));
        assertEquals((short) -15, exec("short x = (short) -60; x >>= 2; return x;"));
        // char
        assertEquals((char) 15, exec("char x = (char) 60; x >>= 2; return x;"));
        // int
        assertEquals(15, exec("int x = 60; x >>= 2; return x;"));
        assertEquals(-15, exec("int x = -60; x >>= 2; return x;"));
        // long
        assertEquals(15L, exec("long x = 60L; x >>= 2; return x;"));
        assertEquals(-15L, exec("long x = -60L; x >>= 2; return x;"));
    }
,
(startLine=210 endLine=225 srcPath=/root/NewExperiment/elasticsearchFilter/01769/plugins/lang-plan-a/src/test/java/org/elasticsearch/plan/a/CompoundAssignmentTests.java)
    public void testUnsignedRightShift() {
        // byte
        assertEquals((byte) 15, exec("byte x = 60; x >>>= 2; return x;"));
        assertEquals((byte) -15, exec("byte x = (byte) -60; x >>>= 2; return x;"));
        // short
        assertEquals((short) 15, exec("short x = 60; x >>>= 2; return x;"));
        assertEquals((short) -15, exec("short x = (short) -60; x >>>= 2; return x;"));
        // char
        assertEquals((char) 15, exec("char x = (char) 60; x >>>= 2; return x;"));
        // int
        assertEquals(15, exec("int x = 60; x >>>= 2; return x;"));
        assertEquals(-60 >>> 2, exec("int x = -60; x >>>= 2; return x;"));
        // long
        assertEquals(15L, exec("long x = 60L; x >>>= 2; return x;"));
        assertEquals(-60L >>> 2, exec("long x = -60L; x >>>= 2; return x;"));
    }
,
>
, <(startLine=773 endLine=792 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java)
    public void testAddAliasNullAlias() {
        try {
            admin().indices().prepareAliases().addAliasAction(AliasAction.newAddAliasAction("index1", null)).get();
            fail("Expected ActionRequestValidationException");
        } catch (ActionRequestValidationException e) {
            assertThat(e.getMessage(), containsString("[alias/aliases] may not be empty string"));
        }
        try {
            admin().indices().prepareAliases().addAliasAction(new AliasActions(ADD, "index1", (String)null)).get();
            fail("Expected ActionRequestValidationException");
        } catch (ActionRequestValidationException e) {
            assertThat(e.getMessage(), containsString("[alias/aliases] may not be empty string"));
        }
        try {
            admin().indices().prepareAliases().addAliasAction(new AliasActions(ADD, "index1", (String[])null)).get();
            fail("Expected ActionRequestValidationException");
        } catch (ActionRequestValidationException e) {
            assertThat(e.getMessage(), containsString("[alias/aliases] is either missing or null"));
        }
    }
,
(startLine=873 endLine=892 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/test/java/org/elasticsearch/aliases/IndexAliasesIT.java)
    public void testRemoveAliasNullAlias() {
        try {
            admin().indices().prepareAliases().addAliasAction(AliasAction.newRemoveAliasAction("index1", null)).get();
            fail("Expected ActionRequestValidationException");
        } catch (ActionRequestValidationException e) {
            assertThat(e.getMessage(), containsString("[alias/aliases] may not be empty string"));
        }
        try {
            admin().indices().prepareAliases().addAliasAction(new AliasActions(REMOVE, "index1", (String)null)).get();
            fail("Expected ActionRequestValidationException");
        } catch (ActionRequestValidationException e) {
            assertThat(e.getMessage(), containsString("[alias/aliases] may not be empty string"));
        }
        try {
            admin().indices().prepareAliases().addAliasAction(new AliasActions(REMOVE, "index1", (String[])null)).get();
            fail("Expected ActionRequestValidationException");
        } catch (ActionRequestValidationException e) {
            assertThat(e.getMessage(), containsString("[alias/aliases] is either missing or null"));
        }
    }
,
>
, <(startLine=1420 endLine=1426 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        if ((t = table) != null) {
            Traverser<K,V> it = new Traverser<K,V>(t, t.length, 0, t.length);
            for (Node<K,V> p; (p = it.advance()) != null; ) {
                s.writeObject(p.key);
                s.writeObject(p.val);
            }
        }
,
(startLine=1603 endLine=1608 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        if ((t = table) != null) {
            Traverser<K,V> it = new Traverser<K,V>(t, t.length, 0, t.length);
            for (Node<K,V> p; (p = it.advance()) != null; ) {
                action.apply(p.key, p.val);
            }
        }
,
>
, <(startLine=140 endLine=166 srcPath=/root/NewExperiment/elasticsearchFilter/00631/src/main/java/org/elasticsearch/action/index/IndexResponse.java)
    public void readFrom(StreamInput in) throws IOException {
        index = in.readUTF();
        id = in.readUTF();
        type = in.readUTF();
        version = in.readLong();
        if (in.readBoolean()) {
            int size = in.readVInt();
            if (size == 0) {
                matches = ImmutableList.of();
            } else if (size == 1) {
                matches = ImmutableList.of(in.readUTF());
            } else if (size == 2) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF());
            } else if (size == 3) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF(), in.readUTF());
            } else if (size == 4) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF(), in.readUTF(), in.readUTF());
            } else if (size == 5) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF(), in.readUTF(), in.readUTF(), in.readUTF());
            } else {
                matches = new ArrayList<String>();
                for (int i = 0; i < size; i++) {
                    matches.add(in.readUTF());
                }
            }
        }
    }
,
(startLine=149 endLine=178 srcPath=/root/NewExperiment/elasticsearchFilter/00631/src/main/java/org/elasticsearch/action/update/UpdateResponse.java)
    public void readFrom(StreamInput in) throws IOException {
        index = in.readUTF();
        id = in.readUTF();
        type = in.readUTF();
        version = in.readLong();
        if (in.readBoolean()) {
            int size = in.readVInt();
            if (size == 0) {
                matches = ImmutableList.of();
            } else if (size == 1) {
                matches = ImmutableList.of(in.readUTF());
            } else if (size == 2) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF());
            } else if (size == 3) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF(), in.readUTF());
            } else if (size == 4) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF(), in.readUTF(), in.readUTF());
            } else if (size == 5) {
                matches = ImmutableList.of(in.readUTF(), in.readUTF(), in.readUTF(), in.readUTF(), in.readUTF());
            } else {
                matches = new ArrayList<String>();
                for (int i = 0; i < size; i++) {
                    matches.add(in.readUTF());
                }
            }
        }
        if (in.readBoolean()) {
            getResult = GetResult.readGetResult(in);
        }
    }
,
>
, <(startLine=519 endLine=527 srcPath=/root/NewExperiment/elasticsearchFilter/00529/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    @Test public void testPrefixFilteredQuery() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/prefix-filter.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, instanceOf(FilteredQuery.class));
        FilteredQuery filteredQuery = (FilteredQuery) parsedQuery;
        PrefixFilter prefixFilter = (PrefixFilter) filteredQuery.getFilter();
        assertThat(prefixFilter.getPrefix(), equalTo(new Term("name.first", "sh")));
    }
,
(startLine=529 endLine=538 srcPath=/root/NewExperiment/elasticsearchFilter/00529/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    @Test public void testPrefixNamedFilteredQuery() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/prefix-filter-named.json");
        ParsedQuery parsedQuery = queryParser.parse(query);
        assertThat(parsedQuery.namedFilters().containsKey("test"), equalTo(true));
        assertThat(parsedQuery.query(), instanceOf(FilteredQuery.class));
        FilteredQuery filteredQuery = (FilteredQuery) parsedQuery.query();
        PrefixFilter prefixFilter = (PrefixFilter) filteredQuery.getFilter();
        assertThat(prefixFilter.getPrefix(), equalTo(new Term("name.first", "sh")));
    }
,
>
, <(startLine=238 endLine=254 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingBwcTest.java)
            public void run() {
                ClusterState clusterState = internalCluster().clusterService().state();
                ShardRouting shardRouting = clusterState.routingTable().index("test").shard(0).getShards().get(0);
                String nodeName = clusterState.getNodes().get(shardRouting.currentNodeId()).getName();

                boolean verified = false;
                IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeName);
                IndexService indexService = indicesService.indexService("test");
                if (indexService != null) {
                    MapperService mapperService = indexService.mapperService();
                    DocumentMapper documentMapper = mapperService.documentMapper("child");
                    if (documentMapper != null) {
                        verified = documentMapper.parentFieldMapper().fieldType().fieldDataType().getLoading() == MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS;
                    }
                }
                assertTrue(verified);
            }
,
(startLine=145 endLine=161 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/child/ParentFieldLoadingTest.java)
            public void run() {
                ClusterState clusterState = internalCluster().clusterService().state();
                ShardRouting shardRouting = clusterState.routingTable().index("test").shard(0).getShards().get(0);
                String nodeName = clusterState.getNodes().get(shardRouting.currentNodeId()).getName();

                boolean verified = false;
                IndicesService indicesService = internalCluster().getInstance(IndicesService.class, nodeName);
                IndexService indexService = indicesService.indexService("test");
                if (indexService != null) {
                    MapperService mapperService = indexService.mapperService();
                    DocumentMapper documentMapper = mapperService.documentMapper("child");
                    if (documentMapper != null) {
                        verified = documentMapper.parentFieldMapper().fieldType().fieldDataType().getLoading() == MappedFieldType.Loading.EAGER_GLOBAL_ORDINALS;
                    }
                }
                assertTrue(verified);
            }
,
>
, <(startLine=68 endLine=87 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/HDRPercentileRanksTests.java)
    private static double[] randomPercents(long minValue, long maxValue) {
        final int length = randomIntBetween(1, 20);
        final double[] percents = new double[length];
        for (int i = 0; i < percents.length; ++i) {
            switch (randomInt(20)) {
            case 0:
                percents[i] = minValue;
                break;
            case 1:
                percents[i] = maxValue;
                break;
            default:
                percents[i] = (randomDouble() * (maxValue - minValue)) + minValue;
                break;
            }
        }
        Arrays.sort(percents);
        Loggers.getLogger(HDRPercentileRanksTests.class).info("Using values={}", Arrays.toString(percents));
        return percents;
    }
,
(startLine=69 endLine=89 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/TDigestPercentileRanksTests.java)
    private static double[] randomPercents(long minValue, long maxValue) {

        final int length = randomIntBetween(1, 20);
        final double[] percents = new double[length];
        for (int i = 0; i < percents.length; ++i) {
            switch (randomInt(20)) {
            case 0:
                percents[i] = minValue;
                break;
            case 1:
                percents[i] = maxValue;
                break;
            default:
                percents[i] = (randomDouble() * (maxValue - minValue)) + minValue;
                break;
            }
        }
        Arrays.sort(percents);
        Loggers.getLogger(TDigestPercentileRanksTests.class).info("Using values={}", Arrays.toString(percents));
        return percents;
    }
,
>
, <(startLine=184 endLine=244 srcPath=/root/NewExperiment/elasticsearchFilter/00575/src/test/java/org/elasticsearch/test/integration/search/highlight/HighlighterSearchTests.java)
    public void testPlainHighlighter() throws Exception {
        try {
            client.admin().indices().prepareDelete("test").execute().actionGet();
        } catch (IndexMissingException e) {
            // its ok
        }
        client.admin().indices().prepareCreate("test").execute().actionGet();
        client.admin().cluster().prepareHealth("test").setWaitForGreenStatus().execute().actionGet();

        client.prepareIndex("test", "type1")
                .setSource("field1", "this is a test", "field2", "The quick brown fox jumps over the lazy dog")
                .setRefresh(true).execute().actionGet();

        logger.info("--> highlighting and searching on field1");
        SearchSourceBuilder source = searchSource()
                .query(termQuery("field1", "test"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field1").order("score").preTags("<xxx>").postTags("</xxx>"));

        SearchResponse searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field1").fragments()[0], equalTo("this is a <xxx>test</xxx>"));

        logger.info("--> searching on _all, highlighting on field1");
        source = searchSource()
                .query(termQuery("_all", "test"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field1").order("score").preTags("<xxx>").postTags("</xxx>"));

        searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field1").fragments()[0], equalTo("this is a <xxx>test</xxx>"));

        logger.info("--> searching on _all, highlighting on field2");
        source = searchSource()
                .query(termQuery("_all", "quick"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>"));

        searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field2").fragments()[0], equalTo("The <xxx>quick</xxx> brown fox jumps over the lazy dog"));

        logger.info("--> searching on _all, highlighting on field2");
        source = searchSource()
                .query(prefixQuery("_all", "qui"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field2").order("score").preTags("<xxx>").postTags("</xxx>"));

        searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field2").fragments()[0], equalTo("The <xxx>quick</xxx> brown fox jumps over the lazy dog"));
    }
,
(startLine=247 endLine=311 srcPath=/root/NewExperiment/elasticsearchFilter/00575/src/test/java/org/elasticsearch/test/integration/search/highlight/HighlighterSearchTests.java)
    public void testFastVectorHighlighter() throws Exception {
        try {
            client.admin().indices().prepareDelete("test").execute().actionGet();
        } catch (IndexMissingException e) {
            // its ok
        }
        client.admin().indices().prepareCreate("test").addMapping("type1", type1TermVectorMapping()).execute().actionGet();
        client.admin().cluster().prepareHealth("test").setWaitForGreenStatus().execute().actionGet();

        client.prepareIndex("test", "type1")
                .setSource("field1", "this is a test", "field2", "The quick brown fox jumps over the lazy dog")
                .setRefresh(true).execute().actionGet();

        logger.info("--> highlighting and searching on field1");
        SearchSourceBuilder source = searchSource()
                .query(termQuery("field1", "test"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field1", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>"));

        SearchResponse searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        // LUCENE 3.1 UPGRADE: Caused adding the space at the end...
        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field1").fragments()[0], equalTo("this is a <xxx>test</xxx> "));

        logger.info("--> searching on _all, highlighting on field1");
        source = searchSource()
                .query(termQuery("_all", "test"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field1", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>"));

        searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        // LUCENE 3.1 UPGRADE: Caused adding the space at the end...
        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field1").fragments()[0], equalTo("this is a <xxx>test</xxx> "));

        logger.info("--> searching on _all, highlighting on field2");
        source = searchSource()
                .query(termQuery("_all", "quick"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field2", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>"));

        searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        // LUCENE 3.1 UPGRADE: Caused adding the space at the end...
        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field2").fragments()[0], equalTo("The <xxx>quick</xxx> brown fox jumps over the lazy dog "));

        logger.info("--> searching on _all, highlighting on field2");
        source = searchSource()
                .query(prefixQuery("_all", "qui"))
                .from(0).size(60).explain(true)
                .highlight(highlight().field("field2", 100, 0).order("score").preTags("<xxx>").postTags("</xxx>"));

        searchResponse = client.search(searchRequest("test").source(source).searchType(QUERY_THEN_FETCH).scroll(timeValueMinutes(10))).actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));

        // LUCENE 3.1 UPGRADE: Caused adding the space at the end...
        assertThat(searchResponse.hits().getAt(0).highlightFields().get("field2").fragments()[0], equalTo("The <xxx>quick</xxx> brown fox jumps over the lazy dog "));
    }
,
>
, <(startLine=73 endLine=85 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testUnmapped() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx_unmapped")
                .setQuery(matchAllQuery())
                .addAggregation(min("min").field("value"))
                .execute().actionGet();

        assertThat(searchResponse.getHits().getTotalHits(), equalTo(0l));

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(Double.POSITIVE_INFINITY));
    }
,
(startLine=88 endLine=100 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testSingleValuedField() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(min("min").field("value"))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(1.0));
    }
,
(startLine=102 endLine=113 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testSingleValuedFieldWithFormatter() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                .addAggregation(min("min").format("0000.0").field("value")).execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(1.0));
        assertThat(min.getValueAsString(), equalTo("0001.0"));
    }
,
(startLine=141 endLine=153 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testSingleValuedFieldPartiallyUnmapped() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx", "idx_unmapped")
                .setQuery(matchAllQuery())
                .addAggregation(min("min").field("value"))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(1.0));
    }
,
(startLine=156 endLine=168 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testSingleValuedFieldWithValueScript() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(min("min").field("value").script(new Script("_value - 1")))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(0.0));
    }
,
(startLine=188 endLine=200 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testMultiValuedField() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(min("min").field("values"))
                .execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(2.0));
    }
,
(startLine=203 endLine=214 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testMultiValuedFieldWithValueScript() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx")
                .setQuery(matchAllQuery())
                .addAggregation(min("min").field("values").script(new Script("_value - 1"))).execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(1.0));
    }
,
(startLine=216 endLine=228 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testMultiValuedFieldWithValueScriptReverse() throws Exception {
        // test what happens when values arrive in reverse order since the min
        // aggregator is optimized to work on sorted values
        SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                .addAggregation(min("min").field("values").script(new Script("_value * -1"))).execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(-12d));
    }
,
(startLine=247 endLine=257 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testScriptSingleValued() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                .addAggregation(min("min").script(new Script("doc['value'].value"))).execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(1.0));
    }
,
(startLine=292 endLine=302 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testScriptMultiValued() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                .addAggregation(min("min").script(new Script("doc['values'].values"))).execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(2.0));
    }
,
(startLine=305 endLine=315 srcPath=/root/NewExperiment/elasticsearchFilter/01766/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/MinTests.java)
    public void testScriptExplicitMultiValued() throws Exception {
        SearchResponse searchResponse = client().prepareSearch("idx").setQuery(matchAllQuery())
                .addAggregation(min("min").script(new Script("doc['values'].values"))).execute().actionGet();

        assertHitCount(searchResponse, 10);

        Min min = searchResponse.getAggregations().get("min");
        assertThat(min, notNullValue());
        assertThat(min.getName(), equalTo("min"));
        assertThat(min.getValue(), equalTo(2.0));
    }
,
>
, <(startLine=143 endLine=150 srcPath=/root/NewExperiment/elasticsearchFilter/00554/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/SourceFieldMapper.java)
                } else if (fieldName.equals("includes")) {
                    List<Object> values = (List<Object>) fieldNode;
                    String[] includes = new String[values.size()];
                    for (int i = 0; i < includes.length; i++) {
                        includes[i] = values.get(i).toString();
                    }
                    builder.includes(includes);
                } else if (fieldName.equals("excludes")) {
,
(startLine=150 endLine=157 srcPath=/root/NewExperiment/elasticsearchFilter/00554/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/internal/SourceFieldMapper.java)
                } else if (fieldName.equals("excludes")) {
                    List<Object> values = (List<Object>) fieldNode;
                    String[] excludes = new String[values.size()];
                    for (int i = 0; i < excludes.length; i++) {
                        excludes[i] = values.get(i).toString();
                    }
                    builder.excludes(excludes);
                }
,
>
, <(startLine=577 endLine=595 srcPath=/root/NewExperiment/elasticsearchFilter/00206/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/highscalelib/NonBlockingHashMap.java)
    public String toString() {
        Iterator<Entry<TypeK, TypeV>> i = entrySet().iterator();
        if (!i.hasNext())
            return "{}";

        StringBuilder sb = new StringBuilder();
        sb.append('{');
        for (; ;) {
            Entry<TypeK, TypeV> e = i.next();
            TypeK key = e.getKey();
            TypeV value = e.getValue();
            sb.append(key == this ? "(this Map)" : key);
            sb.append('=');
            sb.append(value == this ? "(this Map)" : value);
            if (!i.hasNext())
                return sb.append('}').toString();
            sb.append(", ");
        }
    }
,
(startLine=578 endLine=596 srcPath=/root/NewExperiment/elasticsearchFilter/00206/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/highscalelib/NonBlockingHashtable.java)
    public String toString() {
        Iterator<Entry<TypeK, TypeV>> i = entrySet().iterator();
        if (!i.hasNext())
            return "{}";

        StringBuilder sb = new StringBuilder();
        sb.append('{');
        for (; ;) {
            Entry<TypeK, TypeV> e = i.next();
            TypeK key = e.getKey();
            TypeV value = e.getValue();
            sb.append(key == this ? "(this Map)" : key);
            sb.append('=');
            sb.append(value == this ? "(this Map)" : value);
            if (!i.hasNext())
                return sb.append('}').toString();
            sb.append(", ");
        }
    }
,
(startLine=573 endLine=591 srcPath=/root/NewExperiment/elasticsearchFilter/00206/modules/elasticsearch/src/main/java/org/elasticsearch/common/util/concurrent/highscalelib/NonBlockingIdentityHashMap.java)
    public String toString() {
        Iterator<Entry<TypeK, TypeV>> i = entrySet().iterator();
        if (!i.hasNext())
            return "{}";

        StringBuilder sb = new StringBuilder();
        sb.append('{');
        for (; ;) {
            Entry<TypeK, TypeV> e = i.next();
            TypeK key = e.getKey();
            TypeV value = e.getValue();
            sb.append(key == this ? "(this Map)" : key);
            sb.append('=');
            sb.append(value == this ? "(this Map)" : value);
            if (!i.hasNext())
                return sb.append('}').toString();
            sb.append(", ");
        }
    }
,
>
, <(startLine=213 endLine=230 srcPath=/root/NewExperiment/elasticsearchFilter/01714/core/src/test/java/org/elasticsearch/search/aggregations/bucket/FiltersTests.java)
    public void withContextBasedSubAggregation() throws Exception {

        try {
            client().prepareSearch("idx")
                    .addAggregation(
                            filters("tags")
                                    .filter("tag1", termQuery("tag", "tag1"))
                                    .filter("tag2", termQuery("tag", "tag2"))
                                    .subAggregation(avg("avg_value"))
                    )
                    .execute().actionGet();

            fail("expected execution to fail - an attempt to have a context based numeric sub-aggregation, but there is not value source" +
                    "context which the sub-aggregation can inherit");

        } catch (ElasticsearchException ese) {
        }
    }
,
(startLine=153 endLine=167 srcPath=/root/NewExperiment/elasticsearchFilter/01714/core/src/test/java/org/elasticsearch/search/aggregations/bucket/FilterTests.java)
    public void withContextBasedSubAggregation() throws Exception {

        try {
            client().prepareSearch("idx")
                    .addAggregation(filter("tag1")
                            .filter(termQuery("tag", "tag1"))
                            .subAggregation(avg("avg_value")))
                    .execute().actionGet();

            fail("expected execution to fail - an attempt to have a context based numeric sub-aggregation, but there is not value source" +
                    "context which the sub-aggregation can inherit");

        } catch (ElasticsearchException ese) {
        }
    }
,
>
, <(startLine=37 endLine=51 srcPath=/root/NewExperiment/elasticsearchFilter/00609/src/main/java/org/elasticsearch/index/mapper/selector/UidAndSourceFieldSelector.java)
    public FieldSelectorResult accept(String fieldName) {
        if (UidFieldMapper.NAME.equals(fieldName)) {
            if (++match == 2) {
                return FieldSelectorResult.LOAD_AND_BREAK;
            }
            return FieldSelectorResult.LOAD;
        }
        if (SourceFieldMapper.NAME.equals(fieldName)) {
            if (++match == 2) {
                return FieldSelectorResult.LOAD_AND_BREAK;
            }
            return FieldSelectorResult.LOAD;
        }
        return FieldSelectorResult.NO_LOAD;
    }
,
(startLine=35 endLine=49 srcPath=/root/NewExperiment/elasticsearchFilter/00609/src/main/java/org/elasticsearch/index/mapper/selector/UidAndRoutingFieldSelector.java)
    public FieldSelectorResult accept(String fieldName) {
        if (UidFieldMapper.NAME.equals(fieldName)) {
            if (++match == 2) {
                return FieldSelectorResult.LOAD_AND_BREAK;
            }
            return FieldSelectorResult.LOAD;
        }
        if (RoutingFieldMapper.NAME.equals(fieldName)) {
            if (++match == 2) {
                return FieldSelectorResult.LOAD_AND_BREAK;
            }
            return FieldSelectorResult.LOAD;
        }
        return FieldSelectorResult.NO_LOAD;
    }
,
>
, <(startLine=75 endLine=114 srcPath=/root/NewExperiment/elasticsearchFilter/02090/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/SignificantLongTermsAggregator.java)
    public SignificantLongTerms buildAggregation(long owningBucketOrdinal) throws IOException {
        assert owningBucketOrdinal == 0;

        final int size = (int) Math.min(bucketOrds.size(), bucketCountThresholds.getShardSize());

        long supersetSize = termsAggFactory.getSupersetNumDocs();
        long subsetSize = numCollectedDocs;

        BucketSignificancePriorityQueue<SignificantLongTerms.Bucket> ordered = new BucketSignificancePriorityQueue<>(size);
        SignificantLongTerms.Bucket spare = null;
        for (long i = 0; i < bucketOrds.size(); i++) {
            final int docCount = bucketDocCount(i);
            if (docCount < bucketCountThresholds.getShardMinDocCount()) {
                continue;
            }
            if (spare == null) {
                spare = new SignificantLongTerms.Bucket(0, 0, 0, 0, 0, null, format);
            }
            spare.term = bucketOrds.get(i);
            spare.subsetDf = docCount;
            spare.subsetSize = subsetSize;
            spare.supersetDf = termsAggFactory.getBackgroundFrequency(spare.term);
            spare.supersetSize = supersetSize;
            // During shard-local down-selection we use subset/superset stats that are for this shard only
            // Back at the central reducer these properties will be updated with global stats
            spare.updateScore(significanceHeuristic);

            spare.bucketOrd = i;
            spare = ordered.insertWithOverflow(spare);
        }

        final SignificantLongTerms.Bucket[] list = new SignificantLongTerms.Bucket[ordered.size()];
        for (int i = ordered.size() - 1; i >= 0; i--) {
            final SignificantLongTerms.Bucket bucket = ordered.pop();
            bucket.aggregations = bucketAggregations(bucket.bucketOrd);
            list[i] = bucket;
        }
        return new SignificantLongTerms(name, bucketCountThresholds.getRequiredSize(), bucketCountThresholds.getMinDocCount(),
                pipelineAggregators(), metaData(), format, subsetSize, supersetSize, significanceHeuristic, Arrays.asList(list));
    }
,
(startLine=78 endLine=124 srcPath=/root/NewExperiment/elasticsearchFilter/02090/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/SignificantStringTermsAggregator.java)
    public SignificantStringTerms buildAggregation(long owningBucketOrdinal) throws IOException {
        assert owningBucketOrdinal == 0;

        final int size = (int) Math.min(bucketOrds.size(), bucketCountThresholds.getShardSize());
        long supersetSize = termsAggFactory.getSupersetNumDocs();
        long subsetSize = numCollectedDocs;

        BucketSignificancePriorityQueue<SignificantStringTerms.Bucket> ordered = new BucketSignificancePriorityQueue<>(size);
        SignificantStringTerms.Bucket spare = null;
        for (int i = 0; i < bucketOrds.size(); i++) {
            final int docCount = bucketDocCount(i);
            if (docCount < bucketCountThresholds.getShardMinDocCount()) {
                continue;
            }

            if (spare == null) {
                spare = new SignificantStringTerms.Bucket(new BytesRef(), 0, 0, 0, 0, null, format);
            }

            bucketOrds.get(i, spare.termBytes);
            spare.subsetDf = docCount;
            spare.subsetSize = subsetSize;
            spare.supersetDf = termsAggFactory.getBackgroundFrequency(spare.termBytes);
            spare.supersetSize = supersetSize;
            // During shard-local down-selection we use subset/superset stats
            // that are for this shard only
            // Back at the central reducer these properties will be updated with
            // global stats
            spare.updateScore(significanceHeuristic);

            spare.bucketOrd = i;
            spare = ordered.insertWithOverflow(spare);
        }

        final SignificantStringTerms.Bucket[] list = new SignificantStringTerms.Bucket[ordered.size()];
        for (int i = ordered.size() - 1; i >= 0; i--) {
            final SignificantStringTerms.Bucket bucket = ordered.pop();
            // the terms are owned by the BytesRefHash, we need to pull a copy since the BytesRef hash data may be recycled at some point
            bucket.termBytes = BytesRef.deepCopyOf(bucket.termBytes);
            bucket.aggregations = bucketAggregations(bucket.bucketOrd);
            list[i] = bucket;
        }

        return new SignificantStringTerms( name, bucketCountThresholds.getRequiredSize(),
                bucketCountThresholds.getMinDocCount(), pipelineAggregators(),
                metaData(), format, subsetSize, supersetSize, significanceHeuristic, Arrays.asList(list));
    }
,
>
, <(startLine=67 endLine=74 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/GeoLongitudeValueSource.java)
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null) return false;
        if (getClass() != obj.getClass()) return false;
        GeoLongitudeValueSource other = (GeoLongitudeValueSource) obj;
        if (!fieldData.equals(other.fieldData)) return false;
        return true;
    }
,
(startLine=69 endLine=76 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/EmptyMemberValueSource.java)
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null) return false;
        if (getClass() != obj.getClass()) return false;
        EmptyMemberValueSource other = (EmptyMemberValueSource) obj;
        if (!fieldData.equals(other.fieldData)) return false;
        return true;
    }
,
(startLine=67 endLine=74 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/GeoLatitudeValueSource.java)
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null) return false;
        if (getClass() != obj.getClass()) return false;
        GeoLatitudeValueSource other = (GeoLatitudeValueSource) obj;
        if (!fieldData.equals(other.fieldData)) return false;
        return true;
    }
,
(startLine=67 endLine=74 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-expression/src/main/java/org/elasticsearch/script/expression/GeoEmptyValueSource.java)
    public boolean equals(Object obj) {
        if (this == obj) return true;
        if (obj == null) return false;
        if (getClass() != obj.getClass()) return false;
        GeoEmptyValueSource other = (GeoEmptyValueSource) obj;
        if (!fieldData.equals(other.fieldData)) return false;
        return true;
    }
,
>
, <(startLine=107 endLine=119 srcPath=/root/NewExperiment/elasticsearchFilter/01786/test/framework/src/test/java/org/elasticsearch/test/rest/yaml/parser/AssertionParsersTests.java)
    public void testParseMatchSimpleIntegerValue() throws Exception {
        parser = YamlXContent.yamlXContent.createParser(
                "{ field: 10 }"
        );

        MatchParser matchParser = new MatchParser();
        MatchAssertion matchAssertion = matchParser.parse(new ClientYamlTestSuiteParseContext("api", "suite", parser));

        assertThat(matchAssertion, notNullValue());
        assertThat(matchAssertion.getField(), equalTo("field"));
        assertThat(matchAssertion.getExpectedValue(), instanceOf(Integer.class));
        assertThat((Integer) matchAssertion.getExpectedValue(), equalTo(10));
    }
,
(startLine=121 endLine=133 srcPath=/root/NewExperiment/elasticsearchFilter/01786/test/framework/src/test/java/org/elasticsearch/test/rest/yaml/parser/AssertionParsersTests.java)
    public void testParseMatchSimpleStringValue() throws Exception {
        parser = YamlXContent.yamlXContent.createParser(
                "{ foo: bar }"
        );

        MatchParser matchParser = new MatchParser();
        MatchAssertion matchAssertion = matchParser.parse(new ClientYamlTestSuiteParseContext("api", "suite", parser));

        assertThat(matchAssertion, notNullValue());
        assertThat(matchAssertion.getField(), equalTo("foo"));
        assertThat(matchAssertion.getExpectedValue(), instanceOf(String.class));
        assertThat(matchAssertion.getExpectedValue().toString(), equalTo("bar"));
    }
,
>
, <(startLine=90 endLine=99 srcPath=/root/NewExperiment/elasticsearchFilter/02071/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/AwsS3ServiceImplTests.java)
    public void testGlobalMaxRetriesBackcompat() {
        Settings settings = Settings.builder()
            .put(S3Repository.Repositories.MAX_RETRIES_SETTING.getKey(), 10)
            .build();
        launchAWSConfigurationTest(settings, Settings.EMPTY, Protocol.HTTPS, null, -1, null,
            null, 10, false, 50000);
        assertSettingDeprecationsAndWarnings(new Setting<?>[]{
            S3Repository.Repositories.MAX_RETRIES_SETTING
        });
    }
,
(startLine=123 endLine=132 srcPath=/root/NewExperiment/elasticsearchFilter/02071/plugins/repository-s3/src/test/java/org/elasticsearch/repositories/s3/AwsS3ServiceImplTests.java)
    public void testGlobalThrottleRetriesBackcompat() {
        Settings settings = Settings.builder()
            .put(S3Repository.Repositories.USE_THROTTLE_RETRIES_SETTING.getKey(), true)
            .build();
        launchAWSConfigurationTest(settings, Settings.EMPTY, Protocol.HTTPS, null, -1, null,
            null, 3, true, 50000);
        assertSettingDeprecationsAndWarnings(new Setting<?>[]{
            S3Repository.Repositories.USE_THROTTLE_RETRIES_SETTING
        });
    }
,
>
, <(startLine=278 endLine=298 srcPath=/root/NewExperiment/elasticsearchFilter/01251/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/StringTermsAggregator.java)
        public void collect(int doc, long owningBucketOrdinal) throws IOException {
            assert owningBucketOrdinal == 0 : "this is a per_bucket aggregator";
            final int valuesCount = ordinals.setDocument(doc);

            for (int i = 0; i < valuesCount; ++i) {
                final long ord = ordinals.nextOrd();
                long bucketOrd = ordinalToBucket.get(ord);
                if (bucketOrd < 0) { // unlikely condition on a low-cardinality field
                    final BytesRef bytes = bytesValues.getValueByOrd(ord);
                    final int hash = bytesValues.currentValueHash();
                    assert hash == bytes.hashCode();
                    bucketOrd = bucketOrds.add(bytes, hash);
                    if (bucketOrd < 0) { // already seen in another segment
                        bucketOrd = - 1 - bucketOrd;
                    }
                    ordinalToBucket.set(ord, bucketOrd);
                }

                collectBucket(doc, bucketOrd);
            }
        }
,
(startLine=154 endLine=175 srcPath=/root/NewExperiment/elasticsearchFilter/01251/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/SignificantStringTermsAggregator.java)
        public void collect(int doc, long owningBucketOrdinal) throws IOException {
            assert owningBucketOrdinal == 0 : "this is a per_bucket aggregator";
            numCollectedDocs++;
            final int valuesCount = ordinals.setDocument(doc);

            for (int i = 0; i < valuesCount; ++i) {
                final long ord = ordinals.nextOrd();
                long bucketOrd = ordinalToBucket.get(ord);
                if (bucketOrd < 0) { // unlikely condition on a low-cardinality field
                    final BytesRef bytes = bytesValues.getValueByOrd(ord);
                    final int hash = bytesValues.currentValueHash();
                    assert hash == bytes.hashCode();
                    bucketOrd = bucketOrds.add(bytes, hash);
                    if (bucketOrd < 0) { // already seen in another segment
                        bucketOrd = -1 - bucketOrd;
                    }
                    ordinalToBucket.set(ord, bucketOrd);
                }

                collectBucket(doc, bucketOrd);
            }
        }
,
>
, <(startLine=488 endLine=532 srcPath=/root/NewExperiment/elasticsearchFilter/01364/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java)
    public void testFailAllReplicasInitializingOnPrimaryFail() {
        AllocationService allocation = createAllocationService(settingsBuilder()
                .build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder("test").numberOfShards(1).numberOfReplicas(2))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index("test"))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();

        // add 4 nodes
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2")).put(newNode("node3")).put(newNode("node4"))).build();
        clusterState = ClusterState.builder(clusterState).routingTable(allocation.reroute(clusterState).routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(UNASSIGNED).size(), equalTo(2));
        // start primary shards
        clusterState = ClusterState.builder(clusterState).routingTable(allocation.applyStartedShards(clusterState, clusterState.routingNodes().shardsWithState(INITIALIZING)).routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(STARTED).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(2));

        // fail the primary shard, check replicas get removed as well...
        ShardRouting primaryShardToFail = clusterState.routingTable().index("test").shard(0).primaryShard();
        RoutingAllocation.Result routingResult = allocation.applyFailedShard(clusterState, primaryShardToFail);
        assertThat(routingResult.changed(), equalTo(true));
        clusterState = ClusterState.builder(clusterState).routingTable(routingResult.routingTable()).build();
        // the primary gets allocated on another node, replicas are unassigned
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(UNASSIGNED).size(), equalTo(2));

        ShardRouting newPrimaryShard = clusterState.routingTable().index("test").shard(0).primaryShard();
        assertThat(newPrimaryShard, not(equalTo(primaryShardToFail)));

        // start the primary shard
        clusterState = ClusterState.builder(clusterState).routingTable(allocation.applyStartedShards(clusterState, clusterState.routingNodes().shardsWithState(INITIALIZING)).routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(STARTED).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(2));

        // simulate another failure coming in, with the "old" shard routing, verify that nothing changes, and we ignore it
        routingResult = allocation.applyFailedShard(clusterState, primaryShardToFail);
        assertThat(routingResult.changed(), equalTo(false));
    }
,
(startLine=535 endLine=578 srcPath=/root/NewExperiment/elasticsearchFilter/01364/src/test/java/org/elasticsearch/cluster/routing/allocation/FailedShardsRoutingTests.java)
    public void testFailAllReplicasInitializingOnPrimaryFailWhileHavingAReplicaToElect() {
        AllocationService allocation = createAllocationService(settingsBuilder()
                .build());

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder("test").numberOfShards(1).numberOfReplicas(2))
                .build();

        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index("test"))
                .build();

        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.DEFAULT).metaData(metaData).routingTable(routingTable).build();

        // add 4 nodes
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().put(newNode("node1")).put(newNode("node2")).put(newNode("node3")).put(newNode("node4"))).build();
        clusterState = ClusterState.builder(clusterState).routingTable(allocation.reroute(clusterState).routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(UNASSIGNED).size(), equalTo(2));
        // start primary shards
        clusterState = ClusterState.builder(clusterState).routingTable(allocation.applyStartedShards(clusterState, clusterState.routingNodes().shardsWithState(INITIALIZING)).routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(STARTED).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(2));

        // start another replica shard, while keep one initializing
        clusterState = ClusterState.builder(clusterState).routingTable(allocation.applyStartedShards(clusterState, ImmutableList.of(clusterState.routingNodes().shardsWithState(INITIALIZING).get(0))).routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(STARTED).size(), equalTo(2));
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(1));

        // fail the primary shard, check one replica gets elected to primary, others become INITIALIZING (from it)
        ShardRouting primaryShardToFail = clusterState.routingTable().index("test").shard(0).primaryShard();
        RoutingAllocation.Result routingResult = allocation.applyFailedShard(clusterState, primaryShardToFail);
        assertThat(routingResult.changed(), equalTo(true));
        clusterState = ClusterState.builder(clusterState).routingTable(routingResult.routingTable()).build();
        assertThat(clusterState.routingNodes().shardsWithState(STARTED).size(), equalTo(1));
        assertThat(clusterState.routingNodes().shardsWithState(INITIALIZING).size(), equalTo(2));

        ShardRouting newPrimaryShard = clusterState.routingTable().index("test").shard(0).primaryShard();
        assertThat(newPrimaryShard, not(equalTo(primaryShardToFail)));

        // simulate another failure coming in, with the "old" shard routing, verify that nothing changes, and we ignore it
        routingResult = allocation.applyFailedShard(clusterState, primaryShardToFail);
        assertThat(routingResult.changed(), equalTo(false));
    }
,
>
, <(startLine=43 endLine=57 srcPath=/root/NewExperiment/elasticsearchFilter/01628/src/test/java/org/elasticsearch/common/cli/CliToolTests.java)
    public void testOK() throws Exception {
        Terminal terminal = new MockTerminal();
        final AtomicReference<Boolean> executed = new AtomicReference<>(false);
        final NamedCommand cmd = new NamedCommand("cmd", terminal) {
            @Override
            public CliTool.ExitStatus execute(Settings settings, Environment env) {
                executed.set(true);
                return CliTool.ExitStatus.OK;
            }
        };
        SingleCmdTool tool = new SingleCmdTool("tool", terminal, cmd);
        int status = tool.execute();
        assertStatus(status, CliTool.ExitStatus.OK);
        assertCommandHasBeenExecuted(executed);
    }
,
(startLine=60 endLine=74 srcPath=/root/NewExperiment/elasticsearchFilter/01628/src/test/java/org/elasticsearch/common/cli/CliToolTests.java)
    public void testUsageError() throws Exception {
        Terminal terminal = new MockTerminal();
        final AtomicReference<Boolean> executed = new AtomicReference<>(false);
        final NamedCommand cmd = new NamedCommand("cmd", terminal) {
            @Override
            public CliTool.ExitStatus execute(Settings settings, Environment env) {
                executed.set(true);
                return CliTool.ExitStatus.USAGE;
            }
        };
        SingleCmdTool tool = new SingleCmdTool("tool", terminal, cmd);
        int status = tool.execute();
        assertStatus(status, CliTool.ExitStatus.USAGE);
        assertCommandHasBeenExecuted(executed);
    }
,
(startLine=77 endLine=91 srcPath=/root/NewExperiment/elasticsearchFilter/01628/src/test/java/org/elasticsearch/common/cli/CliToolTests.java)
    public void testIOError() throws Exception {
        Terminal terminal = new MockTerminal();
        final AtomicReference<Boolean> executed = new AtomicReference<>(false);
        final NamedCommand cmd = new NamedCommand("cmd", terminal) {
            @Override
            public CliTool.ExitStatus execute(Settings settings, Environment env) throws Exception {
                executed.set(true);
                throw new IOException("io error");
            }
        };
        SingleCmdTool tool = new SingleCmdTool("tool", terminal, cmd);
        int status = tool.execute();
        assertStatus(status, CliTool.ExitStatus.IO_ERROR);
        assertCommandHasBeenExecuted(executed);
    }
,
(startLine=94 endLine=108 srcPath=/root/NewExperiment/elasticsearchFilter/01628/src/test/java/org/elasticsearch/common/cli/CliToolTests.java)
    public void testCodeError() throws Exception {
        Terminal terminal = new MockTerminal();
        final AtomicReference<Boolean> executed = new AtomicReference<>(false);
        final NamedCommand cmd = new NamedCommand("cmd", terminal) {
            @Override
            public CliTool.ExitStatus execute(Settings settings, Environment env) throws Exception {
                executed.set(true);
                throw new Exception("random error");
            }
        };
        SingleCmdTool tool = new SingleCmdTool("tool", terminal, cmd);
        int status = tool.execute();
        assertStatus(status, CliTool.ExitStatus.CODE_ERROR);
        assertCommandHasBeenExecuted(executed);
    }
,
>
, <(startLine=172 endLine=229 srcPath=/root/NewExperiment/elasticsearchFilter/01686/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java)
    public void testValidateLatLonValues() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties").startObject("point").field("type", "geo_point").field("lat_lon", true).field("normalize", false).field("validate", true).endObject().endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);


        ParsedDocument doc = defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 90).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", -91).field("lon", 1.3).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 91).field("lon", 1.3).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 1.2).field("lon", -181).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 1.2).field("lon", 181).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }
    }
,
(startLine=232 endLine=269 srcPath=/root/NewExperiment/elasticsearchFilter/01686/src/test/java/org/elasticsearch/index/mapper/geo/GeoPointFieldMapperTests.java)
    public void testNoValidateLatLonValues() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties").startObject("point").field("type", "geo_point").field("lat_lon", true).field("normalize", false).field("validate", false).endObject().endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);


        ParsedDocument doc = defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 90).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", -91).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 91).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 1.2).field("lon", -181).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 1.2).field("lon", 181).endObject()
                .endObject()
                .bytes());
    }
,
>
, <(startLine=65 endLine=73 srcPath=/root/NewExperiment/elasticsearchFilter/01926/plugins/ingest-user-agent/src/main/java/org/elasticsearch/ingest/useragent/UserAgentParser.java)
                if (token == XContentParser.Token.FIELD_NAME && yamlParser.currentName().equals("user_agent_parsers")) {
                    List<Map<String, String>> parserConfigurations = readParserConfigurations(yamlParser);
                    
                    for (Map<String, String> map : parserConfigurations) {
                        uaPatterns.add(new UserAgentSubpattern(compilePattern(map.get("regex"), map.get("regex_flag")),
                                map.get("family_replacement"), map.get("v1_replacement"), map.get("v2_replacement"),
                                map.get("v3_replacement"), map.get("v4_replacement")));
                    }
                }
,
(startLine=74 endLine=82 srcPath=/root/NewExperiment/elasticsearchFilter/01926/plugins/ingest-user-agent/src/main/java/org/elasticsearch/ingest/useragent/UserAgentParser.java)
                else if (token == XContentParser.Token.FIELD_NAME && yamlParser.currentName().equals("os_parsers")) {
                    List<Map<String, String>> parserConfigurations = readParserConfigurations(yamlParser);
                    
                    for (Map<String, String> map : parserConfigurations) {
                        osPatterns.add(new UserAgentSubpattern(compilePattern(map.get("regex"), map.get("regex_flag")),
                                map.get("os_replacement"), map.get("os_v1_replacement"), map.get("os_v2_replacement"),
                                map.get("os_v3_replacement"), map.get("os_v4_replacement")));
                    }
                }
,
>
, <(startLine=62 endLine=70 srcPath=/root/NewExperiment/elasticsearchFilter/00408/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/search/RestSearchAction.java)
    @Inject public RestSearchAction(Settings settings, Client client, RestController controller) {
        super(settings, client);
        controller.registerHandler(GET, "/_search", this);
        controller.registerHandler(POST, "/_search", this);
        controller.registerHandler(GET, "/{index}/_search", this);
        controller.registerHandler(POST, "/{index}/_search", this);
        controller.registerHandler(GET, "/{index}/{type}/_search", this);
        controller.registerHandler(POST, "/{index}/{type}/_search", this);
    }
,
(startLine=46 endLine=54 srcPath=/root/NewExperiment/elasticsearchFilter/00408/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/count/RestCountAction.java)
    @Inject public RestCountAction(Settings settings, Client client, RestController controller) {
        super(settings, client);
        controller.registerHandler(POST, "/_count", this);
        controller.registerHandler(GET, "/_count", this);
        controller.registerHandler(POST, "/{index}/_count", this);
        controller.registerHandler(GET, "/{index}/_count", this);
        controller.registerHandler(POST, "/{index}/{type}/_count", this);
        controller.registerHandler(GET, "/{index}/{type}/_count", this);
    }
,
>
, <(startLine=57 endLine=65 srcPath=/root/NewExperiment/elasticsearchFilter/00090/plugins/attachments/src/test/java/org/elasticsearch/plugin/attachments/test/SimpleAttachmentIntegrationTests.java)
    @BeforeMethod public void createIndex() {
        logger.info("creating index [test]");
        node.client().admin().indices().create(createIndexRequest("test").settings(settingsBuilder().put("index.numberOfReplicas", 0))).actionGet();
        logger.info("Running Cluster Health");
        ClusterHealthResponse clusterHealth = node.client().admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();
        logger.info("Done Cluster Health, status " + clusterHealth.status());
        assertThat(clusterHealth.timedOut(), equalTo(false));
        assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.GREEN));
    }
,
(startLine=49 endLine=61 srcPath=/root/NewExperiment/elasticsearchFilter/00090/modules/test/integration/src/test/java/org/elasticsearch/test/integration/terms/TermsActionTests.java)
    @BeforeMethod public void createNodesAndClient() throws Exception {
        startNode("server1");
        startNode("server2");
        client = getClient();

        logger.info("Creating index test");
        client.admin().indices().create(createIndexRequest("test")).actionGet();
        logger.info("Running Cluster Health");
        ClusterHealthResponse clusterHealth = client.admin().cluster().health(clusterHealth().waitForGreenStatus()).actionGet();
        logger.info("Done Cluster Health, status " + clusterHealth.status());
        assertThat(clusterHealth.timedOut(), equalTo(false));
        assertThat(clusterHealth.status(), equalTo(ClusterHealthStatus.GREEN));
    }
,
>
, <(startLine=695 endLine=709 srcPath=/root/NewExperiment/elasticsearchFilter/02023/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java)
    private void assertNoShardsOn(final List<String> nodeList) throws Exception {
        assertBusy(new Runnable() {
            @Override
            public void run() {
                ClusterStateResponse resp = client().admin().cluster().prepareState().get();
                RoutingNodes nodes = resp.getState().getRoutingNodes();
                for (RoutingNode node : nodes) {
                    logger.info("--> node {} has {} shards", node.node().getName(), node.numberOfOwningShards());
                    if (nodeList.contains(node.node().getName())) {
                        assertThat("no shards on node", node.numberOfOwningShards(), equalTo(0));
                    }
                }
            }
        }, 1, TimeUnit.MINUTES);
    }
,
(startLine=712 endLine=726 srcPath=/root/NewExperiment/elasticsearchFilter/02023/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java)
    private void assertShardCountOn(final String nodeName, final int shardCount) throws Exception {
        assertBusy(new Runnable() {
            @Override
            public void run() {
                ClusterStateResponse resp = client().admin().cluster().prepareState().get();
                RoutingNodes nodes = resp.getState().getRoutingNodes();
                for (RoutingNode node : nodes) {
                    logger.info("--> node {} has {} shards", node.node().getName(), node.numberOfOwningShards());
                    if (nodeName.equals(node.node().getName())) {
                        assertThat(node.numberOfOwningShards(), equalTo(shardCount));
                    }
                }
            }
        }, 1, TimeUnit.MINUTES);
    }
,
>
, <(startLine=107 endLine=131 srcPath=/root/NewExperiment/elasticsearchFilter/00867/src/test/java/org/elasticsearch/test/unit/index/fielddata/DuellFieldDataTest.java)
        while (!list.isEmpty()) {
            Entry<FieldDataType, Type> left;
            Entry<FieldDataType, Type> right;
            if (list.size() > 1) {
                left = list.remove(random.nextInt(list.size()));
                right = list.remove(random.nextInt(list.size()));
            } else {
                right = left = list.remove(0);
            }
            ifdService.clear();
            IndexFieldData leftFieldData = ifdService.getForField(new FieldMapper.Names(left.getValue().name().toLowerCase(Locale.ROOT)),
                    left.getKey());
            ifdService.clear();
            IndexFieldData rightFieldData = ifdService.getForField(new FieldMapper.Names(right.getValue().name().toLowerCase(Locale.ROOT)),
                    right.getKey());
            duellFieldDataBytes(random, context, leftFieldData, rightFieldData, pre);
            duellFieldDataBytes(random, context, rightFieldData, leftFieldData, pre);
            
            DirectoryReader perSegment = DirectoryReader.open(writer, true);
            CompositeReaderContext composite = perSegment.getContext();
            List<AtomicReaderContext> leaves = composite.leaves();
            for (AtomicReaderContext atomicReaderContext : leaves) {
                duellFieldDataBytes(random, atomicReaderContext, leftFieldData, rightFieldData, pre);
            }
        }
,
(startLine=163 endLine=187 srcPath=/root/NewExperiment/elasticsearchFilter/00867/src/test/java/org/elasticsearch/test/unit/index/fielddata/DuellFieldDataTest.java)
        while (!list.isEmpty()) {
            Entry<FieldDataType, Type> left;
            Entry<FieldDataType, Type> right;
            if (list.size() > 1) {
                left = list.remove(random.nextInt(list.size()));
                right = list.remove(random.nextInt(list.size()));
            } else {
                right = left = list.remove(0);
            }
            ifdService.clear();
            IndexNumericFieldData leftFieldData = ifdService.getForField(new FieldMapper.Names(left.getValue().name().toLowerCase(Locale.ROOT)),
                    left.getKey());
            ifdService.clear();
            IndexNumericFieldData rightFieldData = ifdService.getForField(new FieldMapper.Names(right.getValue().name().toLowerCase(Locale.ROOT)),
                    right.getKey());
            duellFieldDataLong(random, context, leftFieldData, rightFieldData);
            duellFieldDataLong(random, context, rightFieldData, leftFieldData);
            
            DirectoryReader perSegment = DirectoryReader.open(writer, true);
            CompositeReaderContext composite = perSegment.getContext();
            List<AtomicReaderContext> leaves = composite.leaves();
            for (AtomicReaderContext atomicReaderContext : leaves) {
                duellFieldDataLong(random, atomicReaderContext, leftFieldData, rightFieldData);
            }
        }
,
(startLine=217 endLine=241 srcPath=/root/NewExperiment/elasticsearchFilter/00867/src/test/java/org/elasticsearch/test/unit/index/fielddata/DuellFieldDataTest.java)
        while (!list.isEmpty()) {
            Entry<FieldDataType, Type> left;
            Entry<FieldDataType, Type> right;
            if (list.size() > 1) {
                left = list.remove(random.nextInt(list.size()));
                right = list.remove(random.nextInt(list.size()));
            } else {
                right = left = list.remove(0);
            }
            ifdService.clear();
            IndexNumericFieldData leftFieldData = ifdService.getForField(new FieldMapper.Names(left.getValue().name().toLowerCase(Locale.ROOT)),
                    left.getKey());
            ifdService.clear();
            IndexNumericFieldData rightFieldData = ifdService.getForField(new FieldMapper.Names(right.getValue().name().toLowerCase(Locale.ROOT)),
                    right.getKey());
            duellFieldDataDouble(random, context, leftFieldData, rightFieldData);
            duellFieldDataDouble(random, context, rightFieldData, leftFieldData);
            
            DirectoryReader perSegment = DirectoryReader.open(writer, true);
            CompositeReaderContext composite = perSegment.getContext();
            List<AtomicReaderContext> leaves = composite.leaves();
            for (AtomicReaderContext atomicReaderContext : leaves) {
                duellFieldDataDouble(random, atomicReaderContext, leftFieldData, rightFieldData);
            }
        }
,
(startLine=277 endLine=302 srcPath=/root/NewExperiment/elasticsearchFilter/00867/src/test/java/org/elasticsearch/test/unit/index/fielddata/DuellFieldDataTest.java)
        while (!list.isEmpty()) {
            Entry<FieldDataType, Type> left;
            Entry<FieldDataType, Type> right;
            if (list.size() > 1) {
                left = list.remove(random.nextInt(list.size()));
                right = list.remove(random.nextInt(list.size()));
            } else {
                right = left = list.remove(0);
            }
            ifdService.clear();
            IndexFieldData leftFieldData = ifdService.getForField(new FieldMapper.Names(left.getValue().name().toLowerCase(Locale.ROOT)),
                    left.getKey());
            ifdService.clear();
            IndexFieldData rightFieldData = ifdService.getForField(new FieldMapper.Names(right.getValue().name().toLowerCase(Locale.ROOT)),
                    right.getKey());
            duellFieldDataBytes(random, context, leftFieldData, rightFieldData, pre);
            duellFieldDataBytes(random, context, rightFieldData, leftFieldData, pre);
            
            DirectoryReader perSegment = DirectoryReader.open(writer, true);
            CompositeReaderContext composite = perSegment.getContext();
            List<AtomicReaderContext> leaves = composite.leaves();
            for (AtomicReaderContext atomicReaderContext : leaves) {
                duellFieldDataBytes(random, atomicReaderContext, leftFieldData, rightFieldData, pre);
            }
            perSegment.close();
        }
,
>
, <(startLine=1477 endLine=1498 srcPath=/root/NewExperiment/elasticsearchFilter/01056/src/main/java/jsr166e/ForkJoinPool.java)
    final void externalPush(ForkJoinTask<?> task) {
        Submitter z = submitters.get();
        WorkQueue q; int r, m, s, n, am; ForkJoinTask<?>[] a;
        int ps = plock;
        WorkQueue[] ws = workQueues;
        if (z != null && ps > 0 && ws != null && (m = (ws.length - 1)) >= 0 &&
            (q = ws[m & (r = z.seed) & SQMASK]) != null && r != 0 &&
            U.compareAndSwapInt(q, QLOCK, 0, 1)) { // lock
            if ((a = q.array) != null &&
                (am = a.length - 1) > (n = (s = q.top) - q.base)) {
                int j = ((am & s) << ASHIFT) + ABASE;
                U.putOrderedObject(a, j, task);
                q.top = s + 1;                     // push on to deque
                q.qlock = 0;
                if (n <= 1)
                    signalWork(ws, q);
                return;
            }
            q.qlock = 0;
        }
        fullExternalPush(task);
    }
,
(startLine=1465 endLine=1484 srcPath=/root/NewExperiment/elasticsearchFilter/01056/src/main/java/jsr166y/ForkJoinPool.java)
    final void externalPush(ForkJoinTask<?> task) {
        WorkQueue[] ws; WorkQueue q; Submitter z; int m; ForkJoinTask<?>[] a;
        if ((z = submitters.get()) != null && plock > 0 &&
            (ws = workQueues) != null && (m = (ws.length - 1)) >= 0 &&
            (q = ws[m & z.seed & SQMASK]) != null &&
            U.compareAndSwapInt(q, QLOCK, 0, 1)) { // lock
            int b = q.base, s = q.top, n, an;
            if ((a = q.array) != null && (an = a.length) > (n = s + 1 - b)) {
                int j = (((an - 1) & s) << ASHIFT) + ABASE;
                U.putOrderedObject(a, j, task);
                q.top = s + 1;                     // push on to deque
                q.qlock = 0;
                if (n <= 2)
                    signalWork(q);
                return;
            }
            q.qlock = 0;
        }
        fullExternalPush(task);
    }
,
>
, <(startLine=118 endLine=126 srcPath=/root/NewExperiment/elasticsearchFilter/02374/core/src/main/java/org/elasticsearch/index/mapper/SourceFieldMapper.java)
                } else if (fieldName.equals("includes")) {
                    List<Object> values = (List<Object>) fieldNode;
                    String[] includes = new String[values.size()];
                    for (int i = 0; i < includes.length; i++) {
                        includes[i] = values.get(i).toString();
                    }
                    builder.includes(includes);
                    iterator.remove();
                } else if (fieldName.equals("excludes")) {
,
(startLine=126 endLine=134 srcPath=/root/NewExperiment/elasticsearchFilter/02374/core/src/main/java/org/elasticsearch/index/mapper/SourceFieldMapper.java)
                } else if (fieldName.equals("excludes")) {
                    List<Object> values = (List<Object>) fieldNode;
                    String[] excludes = new String[values.size()];
                    for (int i = 0; i < excludes.length; i++) {
                        excludes[i] = values.get(i).toString();
                    }
                    builder.excludes(excludes);
                    iterator.remove();
                }
,
>
, <(startLine=243 endLine=254 srcPath=/root/NewExperiment/elasticsearchFilter/00922/src/main/java/org/elasticsearch/action/admin/cluster/node/stats/NodesStatsRequest.java)
    public void writeTo(StreamOutput out) throws IOException {
        super.writeTo(out);
        indices.writeTo(out);
        out.writeBoolean(os);
        out.writeBoolean(process);
        out.writeBoolean(jvm);
        out.writeBoolean(threadPool);
        out.writeBoolean(network);
        out.writeBoolean(fs);
        out.writeBoolean(transport);
        out.writeBoolean(http);
    }
,
(startLine=238 endLine=249 srcPath=/root/NewExperiment/elasticsearchFilter/00922/src/main/java/org/elasticsearch/action/admin/cluster/node/info/NodesInfoRequest.java)
    public void writeTo(StreamOutput out) throws IOException {
        super.writeTo(out);
        out.writeBoolean(settings);
        out.writeBoolean(os);
        out.writeBoolean(process);
        out.writeBoolean(jvm);
        out.writeBoolean(threadPool);
        out.writeBoolean(network);
        out.writeBoolean(transport);
        out.writeBoolean(http);
        out.writeBoolean(plugin);
    }
,
>
, <(startLine=107 endLine=119 srcPath=/root/NewExperiment/elasticsearchFilter/01769/test-framework/src/test/java/org/elasticsearch/test/rest/test/AssertionParsersTests.java)
    public void testParseMatchSimpleIntegerValue() throws Exception {
        parser = YamlXContent.yamlXContent.createParser(
                "{ field: 10 }"
        );

        MatchParser matchParser = new MatchParser();
        MatchAssertion matchAssertion = matchParser.parse(new RestTestSuiteParseContext("api", "suite", parser));

        assertThat(matchAssertion, notNullValue());
        assertThat(matchAssertion.getField(), equalTo("field"));
        assertThat(matchAssertion.getExpectedValue(), instanceOf(Integer.class));
        assertThat((Integer) matchAssertion.getExpectedValue(), equalTo(10));
    }
,
(startLine=121 endLine=133 srcPath=/root/NewExperiment/elasticsearchFilter/01769/test-framework/src/test/java/org/elasticsearch/test/rest/test/AssertionParsersTests.java)
    public void testParseMatchSimpleStringValue() throws Exception {
        parser = YamlXContent.yamlXContent.createParser(
                "{ foo: bar }"
        );

        MatchParser matchParser = new MatchParser();
        MatchAssertion matchAssertion = matchParser.parse(new RestTestSuiteParseContext("api", "suite", parser));

        assertThat(matchAssertion, notNullValue());
        assertThat(matchAssertion.getField(), equalTo("foo"));
        assertThat(matchAssertion.getExpectedValue(), instanceOf(String.class));
        assertThat(matchAssertion.getExpectedValue().toString(), equalTo("bar"));
    }
,
>
, <(startLine=167 endLine=178 srcPath=/root/NewExperiment/elasticsearchFilter/01977/core/src/main/java/org/elasticsearch/common/logging/Loggers.java)
    public static void addAppender(final Logger logger, final Appender appender) {
        final LoggerContext ctx = (LoggerContext) LogManager.getContext(false);
        final Configuration config = ctx.getConfiguration();
        config.addAppender(appender);
        LoggerConfig loggerConfig = config.getLoggerConfig(logger.getName());
        if (!logger.getName().equals(loggerConfig.getName())) {
            loggerConfig = new LoggerConfig(logger.getName(), logger.getLevel(), true);
            config.addLogger(logger.getName(), loggerConfig);
        }
        loggerConfig.addAppender(appender, null, null);
        ctx.updateLoggers();
    }
,
(startLine=180 endLine=190 srcPath=/root/NewExperiment/elasticsearchFilter/01977/core/src/main/java/org/elasticsearch/common/logging/Loggers.java)
    public static void removeAppender(final Logger logger, final Appender appender) {
        final LoggerContext ctx = (LoggerContext) LogManager.getContext(false);
        final Configuration config = ctx.getConfiguration();
        LoggerConfig loggerConfig = config.getLoggerConfig(logger.getName());
        if (!logger.getName().equals(loggerConfig.getName())) {
            loggerConfig = new LoggerConfig(logger.getName(), logger.getLevel(), true);
            config.addLogger(logger.getName(), loggerConfig);
        }
        loggerConfig.removeAppender(appender.getName());
        ctx.updateLoggers();
    }
,
>
, <(startLine=436 endLine=442 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchTests.java)
        for (int i = 0; i < indexRequestBuilders.length; i++) {
            indexRequestBuilders[i] = client().prepareIndex("test", "type1", Integer.toString(i))
                    .setSource(XContentFactory.jsonBuilder().startObject()
                            .field("title", "This is a test on the highlighting bug present in elasticsearch")
                            .startArray("attachments").startObject().field("body", "attachment 1").endObject().startObject().field("body", "attachment 2").endObject().endArray()
                            .endObject());
        }
,
(startLine=476 endLine=482 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/highlight/HighlighterSearchTests.java)
        for (int i = 0; i < indexRequestBuilders.length; i++) {
            indexRequestBuilders[i] = client().prepareIndex("test", "type1", Integer.toString(i))
                    .setSource(XContentFactory.jsonBuilder().startObject()
                            .field("title", "This is a test on the highlighting bug present in elasticsearch")
                            .startArray("attachments").startObject().field("body", "attachment 1").endObject().startObject().field("body", "attachment 2").endObject().endArray()
                            .endObject());
        }
,
>
, <(startLine=112 endLine=161 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/index/mapper/nested/NestedMappingTests.java)
    public void multiNested() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type").startObject("properties")
                .startObject("nested1").field("type", "nested").startObject("properties")
                .startObject("nested2").field("type", "nested")
                .endObject().endObject()
                .endObject().endObject().endObject().string();

        DocumentMapper docMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);

        assertThat(docMapper.hasNestedObjects(), equalTo(true));
        ObjectMapper nested1Mapper = docMapper.objectMappers().get("nested1");
        assertThat(nested1Mapper.nested().isNested(), equalTo(true));
        assertThat(nested1Mapper.nested().isIncludeInParent(), equalTo(false));
        assertThat(nested1Mapper.nested().isIncludeInRoot(), equalTo(false));
        ObjectMapper nested2Mapper = docMapper.objectMappers().get("nested1.nested2");
        assertThat(nested2Mapper.nested().isNested(), equalTo(true));
        assertThat(nested2Mapper.nested().isIncludeInParent(), equalTo(false));
        assertThat(nested2Mapper.nested().isIncludeInRoot(), equalTo(false));

        ParsedDocument doc = docMapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .field("field", "value")
                .startArray("nested1")
                .startObject().field("field1", "1").startArray("nested2").startObject().field("field2", "2").endObject().startObject().field("field2", "3").endObject().endArray().endObject()
                .startObject().field("field1", "4").startArray("nested2").startObject().field("field2", "5").endObject().startObject().field("field2", "6").endObject().endArray().endObject()
                .endArray()
                .endObject()
                .bytes());

        assertThat(doc.docs().size(), equalTo(7));
        assertThat(doc.docs().get(0).get("nested1.nested2.field2"), equalTo("6"));
        assertThat(doc.docs().get(0).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(0).get("field"), nullValue());
        assertThat(doc.docs().get(1).get("nested1.nested2.field2"), equalTo("5"));
        assertThat(doc.docs().get(1).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(1).get("field"), nullValue());
        assertThat(doc.docs().get(2).get("nested1.field1"), equalTo("4"));
        assertThat(doc.docs().get(2).get("nested1.nested2.field2"), nullValue());
        assertThat(doc.docs().get(2).get("field"), nullValue());
        assertThat(doc.docs().get(3).get("nested1.nested2.field2"), equalTo("3"));
        assertThat(doc.docs().get(3).get("field"), nullValue());
        assertThat(doc.docs().get(4).get("nested1.nested2.field2"), equalTo("2"));
        assertThat(doc.docs().get(4).get("field"), nullValue());
        assertThat(doc.docs().get(5).get("nested1.field1"), equalTo("1"));
        assertThat(doc.docs().get(5).get("nested1.nested2.field2"), nullValue());
        assertThat(doc.docs().get(5).get("field"), nullValue());
        assertThat(doc.docs().get(6).get("field"), equalTo("value"));
        assertThat(doc.docs().get(6).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(6).get("nested1.nested2.field2"), nullValue());
    }
,
(startLine=164 endLine=213 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/index/mapper/nested/NestedMappingTests.java)
    public void multiObjectAndNested1() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type").startObject("properties")
                .startObject("nested1").field("type", "nested").startObject("properties")
                .startObject("nested2").field("type", "nested").field("include_in_parent", true)
                .endObject().endObject()
                .endObject().endObject().endObject().string();

        DocumentMapper docMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);

        assertThat(docMapper.hasNestedObjects(), equalTo(true));
        ObjectMapper nested1Mapper = docMapper.objectMappers().get("nested1");
        assertThat(nested1Mapper.nested().isNested(), equalTo(true));
        assertThat(nested1Mapper.nested().isIncludeInParent(), equalTo(false));
        assertThat(nested1Mapper.nested().isIncludeInRoot(), equalTo(false));
        ObjectMapper nested2Mapper = docMapper.objectMappers().get("nested1.nested2");
        assertThat(nested2Mapper.nested().isNested(), equalTo(true));
        assertThat(nested2Mapper.nested().isIncludeInParent(), equalTo(true));
        assertThat(nested2Mapper.nested().isIncludeInRoot(), equalTo(false));

        ParsedDocument doc = docMapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .field("field", "value")
                .startArray("nested1")
                .startObject().field("field1", "1").startArray("nested2").startObject().field("field2", "2").endObject().startObject().field("field2", "3").endObject().endArray().endObject()
                .startObject().field("field1", "4").startArray("nested2").startObject().field("field2", "5").endObject().startObject().field("field2", "6").endObject().endArray().endObject()
                .endArray()
                .endObject()
                .bytes());

        assertThat(doc.docs().size(), equalTo(7));
        assertThat(doc.docs().get(0).get("nested1.nested2.field2"), equalTo("6"));
        assertThat(doc.docs().get(0).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(0).get("field"), nullValue());
        assertThat(doc.docs().get(1).get("nested1.nested2.field2"), equalTo("5"));
        assertThat(doc.docs().get(1).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(1).get("field"), nullValue());
        assertThat(doc.docs().get(2).get("nested1.field1"), equalTo("4"));
        assertThat(doc.docs().get(2).get("nested1.nested2.field2"), equalTo("5"));
        assertThat(doc.docs().get(2).get("field"), nullValue());
        assertThat(doc.docs().get(3).get("nested1.nested2.field2"), equalTo("3"));
        assertThat(doc.docs().get(3).get("field"), nullValue());
        assertThat(doc.docs().get(4).get("nested1.nested2.field2"), equalTo("2"));
        assertThat(doc.docs().get(4).get("field"), nullValue());
        assertThat(doc.docs().get(5).get("nested1.field1"), equalTo("1"));
        assertThat(doc.docs().get(5).get("nested1.nested2.field2"), equalTo("2"));
        assertThat(doc.docs().get(5).get("field"), nullValue());
        assertThat(doc.docs().get(6).get("field"), equalTo("value"));
        assertThat(doc.docs().get(6).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(6).get("nested1.nested2.field2"), nullValue());
    }
,
(startLine=216 endLine=265 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/index/mapper/nested/NestedMappingTests.java)
    public void multiObjectAndNested2() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type").startObject("properties")
                .startObject("nested1").field("type", "nested").field("include_in_parent", true).startObject("properties")
                .startObject("nested2").field("type", "nested").field("include_in_parent", true)
                .endObject().endObject()
                .endObject().endObject().endObject().string();

        DocumentMapper docMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);

        assertThat(docMapper.hasNestedObjects(), equalTo(true));
        ObjectMapper nested1Mapper = docMapper.objectMappers().get("nested1");
        assertThat(nested1Mapper.nested().isNested(), equalTo(true));
        assertThat(nested1Mapper.nested().isIncludeInParent(), equalTo(true));
        assertThat(nested1Mapper.nested().isIncludeInRoot(), equalTo(false));
        ObjectMapper nested2Mapper = docMapper.objectMappers().get("nested1.nested2");
        assertThat(nested2Mapper.nested().isNested(), equalTo(true));
        assertThat(nested2Mapper.nested().isIncludeInParent(), equalTo(true));
        assertThat(nested2Mapper.nested().isIncludeInRoot(), equalTo(false));

        ParsedDocument doc = docMapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .field("field", "value")
                .startArray("nested1")
                .startObject().field("field1", "1").startArray("nested2").startObject().field("field2", "2").endObject().startObject().field("field2", "3").endObject().endArray().endObject()
                .startObject().field("field1", "4").startArray("nested2").startObject().field("field2", "5").endObject().startObject().field("field2", "6").endObject().endArray().endObject()
                .endArray()
                .endObject()
                .bytes());

        assertThat(doc.docs().size(), equalTo(7));
        assertThat(doc.docs().get(0).get("nested1.nested2.field2"), equalTo("6"));
        assertThat(doc.docs().get(0).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(0).get("field"), nullValue());
        assertThat(doc.docs().get(1).get("nested1.nested2.field2"), equalTo("5"));
        assertThat(doc.docs().get(1).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(1).get("field"), nullValue());
        assertThat(doc.docs().get(2).get("nested1.field1"), equalTo("4"));
        assertThat(doc.docs().get(2).get("nested1.nested2.field2"), equalTo("5"));
        assertThat(doc.docs().get(2).get("field"), nullValue());
        assertThat(doc.docs().get(3).get("nested1.nested2.field2"), equalTo("3"));
        assertThat(doc.docs().get(3).get("field"), nullValue());
        assertThat(doc.docs().get(4).get("nested1.nested2.field2"), equalTo("2"));
        assertThat(doc.docs().get(4).get("field"), nullValue());
        assertThat(doc.docs().get(5).get("nested1.field1"), equalTo("1"));
        assertThat(doc.docs().get(5).get("nested1.nested2.field2"), equalTo("2"));
        assertThat(doc.docs().get(5).get("field"), nullValue());
        assertThat(doc.docs().get(6).get("field"), equalTo("value"));
        assertThat(doc.docs().get(6).getFields("nested1.field1").length, equalTo(2));
        assertThat(doc.docs().get(6).getFields("nested1.nested2.field2").length, equalTo(4));
    }
,
(startLine=268 endLine=317 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/index/mapper/nested/NestedMappingTests.java)
    public void multiRootAndNested1() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type").startObject("properties")
                .startObject("nested1").field("type", "nested").startObject("properties")
                .startObject("nested2").field("type", "nested").field("include_in_root", true)
                .endObject().endObject()
                .endObject().endObject().endObject().string();

        DocumentMapper docMapper = createIndex("test").mapperService().documentMapperParser().parse(mapping);

        assertThat(docMapper.hasNestedObjects(), equalTo(true));
        ObjectMapper nested1Mapper = docMapper.objectMappers().get("nested1");
        assertThat(nested1Mapper.nested().isNested(), equalTo(true));
        assertThat(nested1Mapper.nested().isIncludeInParent(), equalTo(false));
        assertThat(nested1Mapper.nested().isIncludeInRoot(), equalTo(false));
        ObjectMapper nested2Mapper = docMapper.objectMappers().get("nested1.nested2");
        assertThat(nested2Mapper.nested().isNested(), equalTo(true));
        assertThat(nested2Mapper.nested().isIncludeInParent(), equalTo(false));
        assertThat(nested2Mapper.nested().isIncludeInRoot(), equalTo(true));

        ParsedDocument doc = docMapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .field("field", "value")
                .startArray("nested1")
                .startObject().field("field1", "1").startArray("nested2").startObject().field("field2", "2").endObject().startObject().field("field2", "3").endObject().endArray().endObject()
                .startObject().field("field1", "4").startArray("nested2").startObject().field("field2", "5").endObject().startObject().field("field2", "6").endObject().endArray().endObject()
                .endArray()
                .endObject()
                .bytes());

        assertThat(doc.docs().size(), equalTo(7));
        assertThat(doc.docs().get(0).get("nested1.nested2.field2"), equalTo("6"));
        assertThat(doc.docs().get(0).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(0).get("field"), nullValue());
        assertThat(doc.docs().get(1).get("nested1.nested2.field2"), equalTo("5"));
        assertThat(doc.docs().get(1).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(1).get("field"), nullValue());
        assertThat(doc.docs().get(2).get("nested1.field1"), equalTo("4"));
        assertThat(doc.docs().get(2).get("nested1.nested2.field2"), nullValue());
        assertThat(doc.docs().get(2).get("field"), nullValue());
        assertThat(doc.docs().get(3).get("nested1.nested2.field2"), equalTo("3"));
        assertThat(doc.docs().get(3).get("field"), nullValue());
        assertThat(doc.docs().get(4).get("nested1.nested2.field2"), equalTo("2"));
        assertThat(doc.docs().get(4).get("field"), nullValue());
        assertThat(doc.docs().get(5).get("nested1.field1"), equalTo("1"));
        assertThat(doc.docs().get(5).get("nested1.nested2.field2"), nullValue());
        assertThat(doc.docs().get(5).get("field"), nullValue());
        assertThat(doc.docs().get(6).get("field"), equalTo("value"));
        assertThat(doc.docs().get(6).get("nested1.field1"), nullValue());
        assertThat(doc.docs().get(6).getFields("nested1.nested2.field2").length, equalTo(4));
    }
,
>
, <(startLine=799 endLine=879 srcPath=/root/NewExperiment/elasticsearchFilter/01418/src/main/java/org/apache/lucene/expressions/js/XJavascriptParser.java)
    public final XJavascriptParser.equality_return equality() throws RecognitionException {
        XJavascriptParser.equality_return retval = new XJavascriptParser.equality_return();
        retval.start = input.LT(1);

        CommonTree root_0 = null;

        Token set24=null;
        ParserRuleReturnScope relational23 =null;
        ParserRuleReturnScope relational25 =null;

        CommonTree set24_tree=null;

        try {
            // src/java/org/apache/lucene/expressions/js/Javascript.g:279:5: ( relational ( ( AT_COMP_EQ | AT_COMP_NEQ ) ^ relational )* )
            // src/java/org/apache/lucene/expressions/js/Javascript.g:279:7: relational ( ( AT_COMP_EQ | AT_COMP_NEQ ) ^ relational )*
            {
                root_0 = (CommonTree)adaptor.nil();


                pushFollow(FOLLOW_relational_in_equality913);
                relational23=relational();
                state._fsp--;

                adaptor.addChild(root_0, relational23.getTree());

                // src/java/org/apache/lucene/expressions/js/Javascript.g:279:18: ( ( AT_COMP_EQ | AT_COMP_NEQ ) ^ relational )*
                loop7:
                while (true) {
                    int alt7=2;
                    int LA7_0 = input.LA(1);
                    if ( (LA7_0==AT_COMP_EQ||LA7_0==AT_COMP_NEQ) ) {
                        alt7=1;
                    }

                    switch (alt7) {
                        case 1 :
                            // src/java/org/apache/lucene/expressions/js/Javascript.g:279:19: ( AT_COMP_EQ | AT_COMP_NEQ ) ^ relational
                        {
                            set24=input.LT(1);
                            set24=input.LT(1);
                            if ( input.LA(1)==AT_COMP_EQ||input.LA(1)==AT_COMP_NEQ ) {
                                input.consume();
                                root_0 = (CommonTree)adaptor.becomeRoot((CommonTree)adaptor.create(set24), root_0);
                                state.errorRecovery=false;
                            }
                            else {
                                MismatchedSetException mse = new MismatchedSetException(null,input);
                                throw mse;
                            }
                            pushFollow(FOLLOW_relational_in_equality925);
                            relational25=relational();
                            state._fsp--;

                            adaptor.addChild(root_0, relational25.getTree());

                        }
                        break;

                        default :
                            break loop7;
                    }
                }

            }

            retval.stop = input.LT(-1);

            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }
        catch (RecognitionException re) {
            reportError(re);
            recover(input,re);
            retval.tree = (CommonTree)adaptor.errorNode(input, retval.start, input.LT(-1), re);
        }
        finally {
            // do for sure before leaving
        }
        return retval;
    }
,
(startLine=892 endLine=972 srcPath=/root/NewExperiment/elasticsearchFilter/01418/src/main/java/org/apache/lucene/expressions/js/XJavascriptParser.java)
    public final XJavascriptParser.relational_return relational() throws RecognitionException {
        XJavascriptParser.relational_return retval = new XJavascriptParser.relational_return();
        retval.start = input.LT(1);

        CommonTree root_0 = null;

        Token set27=null;
        ParserRuleReturnScope shift26 =null;
        ParserRuleReturnScope shift28 =null;

        CommonTree set27_tree=null;

        try {
            // src/java/org/apache/lucene/expressions/js/Javascript.g:283:5: ( shift ( ( AT_COMP_LT | AT_COMP_GT | AT_COMP_LTE | AT_COMP_GTE ) ^ shift )* )
            // src/java/org/apache/lucene/expressions/js/Javascript.g:283:7: shift ( ( AT_COMP_LT | AT_COMP_GT | AT_COMP_LTE | AT_COMP_GTE ) ^ shift )*
            {
                root_0 = (CommonTree)adaptor.nil();


                pushFollow(FOLLOW_shift_in_relational944);
                shift26=shift();
                state._fsp--;

                adaptor.addChild(root_0, shift26.getTree());

                // src/java/org/apache/lucene/expressions/js/Javascript.g:283:13: ( ( AT_COMP_LT | AT_COMP_GT | AT_COMP_LTE | AT_COMP_GTE ) ^ shift )*
                loop8:
                while (true) {
                    int alt8=2;
                    int LA8_0 = input.LA(1);
                    if ( ((LA8_0 >= AT_COMP_GT && LA8_0 <= AT_COMP_LTE)) ) {
                        alt8=1;
                    }

                    switch (alt8) {
                        case 1 :
                            // src/java/org/apache/lucene/expressions/js/Javascript.g:283:14: ( AT_COMP_LT | AT_COMP_GT | AT_COMP_LTE | AT_COMP_GTE ) ^ shift
                        {
                            set27=input.LT(1);
                            set27=input.LT(1);
                            if ( (input.LA(1) >= AT_COMP_GT && input.LA(1) <= AT_COMP_LTE) ) {
                                input.consume();
                                root_0 = (CommonTree)adaptor.becomeRoot((CommonTree)adaptor.create(set27), root_0);
                                state.errorRecovery=false;
                            }
                            else {
                                MismatchedSetException mse = new MismatchedSetException(null,input);
                                throw mse;
                            }
                            pushFollow(FOLLOW_shift_in_relational964);
                            shift28=shift();
                            state._fsp--;

                            adaptor.addChild(root_0, shift28.getTree());

                        }
                        break;

                        default :
                            break loop8;
                    }
                }

            }

            retval.stop = input.LT(-1);

            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }
        catch (RecognitionException re) {
            reportError(re);
            recover(input,re);
            retval.tree = (CommonTree)adaptor.errorNode(input, retval.start, input.LT(-1), re);
        }
        finally {
            // do for sure before leaving
        }
        return retval;
    }
,
(startLine=985 endLine=1065 srcPath=/root/NewExperiment/elasticsearchFilter/01418/src/main/java/org/apache/lucene/expressions/js/XJavascriptParser.java)
    public final XJavascriptParser.shift_return shift() throws RecognitionException {
        XJavascriptParser.shift_return retval = new XJavascriptParser.shift_return();
        retval.start = input.LT(1);

        CommonTree root_0 = null;

        Token set30=null;
        ParserRuleReturnScope additive29 =null;
        ParserRuleReturnScope additive31 =null;

        CommonTree set30_tree=null;

        try {
            // src/java/org/apache/lucene/expressions/js/Javascript.g:287:5: ( additive ( ( AT_BIT_SHL | AT_BIT_SHR | AT_BIT_SHU ) ^ additive )* )
            // src/java/org/apache/lucene/expressions/js/Javascript.g:287:7: additive ( ( AT_BIT_SHL | AT_BIT_SHR | AT_BIT_SHU ) ^ additive )*
            {
                root_0 = (CommonTree)adaptor.nil();


                pushFollow(FOLLOW_additive_in_shift983);
                additive29=additive();
                state._fsp--;

                adaptor.addChild(root_0, additive29.getTree());

                // src/java/org/apache/lucene/expressions/js/Javascript.g:287:16: ( ( AT_BIT_SHL | AT_BIT_SHR | AT_BIT_SHU ) ^ additive )*
                loop9:
                while (true) {
                    int alt9=2;
                    int LA9_0 = input.LA(1);
                    if ( ((LA9_0 >= AT_BIT_SHL && LA9_0 <= AT_BIT_SHU)) ) {
                        alt9=1;
                    }

                    switch (alt9) {
                        case 1 :
                            // src/java/org/apache/lucene/expressions/js/Javascript.g:287:17: ( AT_BIT_SHL | AT_BIT_SHR | AT_BIT_SHU ) ^ additive
                        {
                            set30=input.LT(1);
                            set30=input.LT(1);
                            if ( (input.LA(1) >= AT_BIT_SHL && input.LA(1) <= AT_BIT_SHU) ) {
                                input.consume();
                                root_0 = (CommonTree)adaptor.becomeRoot((CommonTree)adaptor.create(set30), root_0);
                                state.errorRecovery=false;
                            }
                            else {
                                MismatchedSetException mse = new MismatchedSetException(null,input);
                                throw mse;
                            }
                            pushFollow(FOLLOW_additive_in_shift999);
                            additive31=additive();
                            state._fsp--;

                            adaptor.addChild(root_0, additive31.getTree());

                        }
                        break;

                        default :
                            break loop9;
                    }
                }

            }

            retval.stop = input.LT(-1);

            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }
        catch (RecognitionException re) {
            reportError(re);
            recover(input,re);
            retval.tree = (CommonTree)adaptor.errorNode(input, retval.start, input.LT(-1), re);
        }
        finally {
            // do for sure before leaving
        }
        return retval;
    }
,
(startLine=1078 endLine=1158 srcPath=/root/NewExperiment/elasticsearchFilter/01418/src/main/java/org/apache/lucene/expressions/js/XJavascriptParser.java)
    public final XJavascriptParser.additive_return additive() throws RecognitionException {
        XJavascriptParser.additive_return retval = new XJavascriptParser.additive_return();
        retval.start = input.LT(1);

        CommonTree root_0 = null;

        Token set33=null;
        ParserRuleReturnScope multiplicative32 =null;
        ParserRuleReturnScope multiplicative34 =null;

        CommonTree set33_tree=null;

        try {
            // src/java/org/apache/lucene/expressions/js/Javascript.g:291:5: ( multiplicative ( ( AT_ADD | AT_SUBTRACT ) ^ multiplicative )* )
            // src/java/org/apache/lucene/expressions/js/Javascript.g:291:7: multiplicative ( ( AT_ADD | AT_SUBTRACT ) ^ multiplicative )*
            {
                root_0 = (CommonTree)adaptor.nil();


                pushFollow(FOLLOW_multiplicative_in_additive1018);
                multiplicative32=multiplicative();
                state._fsp--;

                adaptor.addChild(root_0, multiplicative32.getTree());

                // src/java/org/apache/lucene/expressions/js/Javascript.g:291:22: ( ( AT_ADD | AT_SUBTRACT ) ^ multiplicative )*
                loop10:
                while (true) {
                    int alt10=2;
                    int LA10_0 = input.LA(1);
                    if ( (LA10_0==AT_ADD||LA10_0==AT_SUBTRACT) ) {
                        alt10=1;
                    }

                    switch (alt10) {
                        case 1 :
                            // src/java/org/apache/lucene/expressions/js/Javascript.g:291:23: ( AT_ADD | AT_SUBTRACT ) ^ multiplicative
                        {
                            set33=input.LT(1);
                            set33=input.LT(1);
                            if ( input.LA(1)==AT_ADD||input.LA(1)==AT_SUBTRACT ) {
                                input.consume();
                                root_0 = (CommonTree)adaptor.becomeRoot((CommonTree)adaptor.create(set33), root_0);
                                state.errorRecovery=false;
                            }
                            else {
                                MismatchedSetException mse = new MismatchedSetException(null,input);
                                throw mse;
                            }
                            pushFollow(FOLLOW_multiplicative_in_additive1030);
                            multiplicative34=multiplicative();
                            state._fsp--;

                            adaptor.addChild(root_0, multiplicative34.getTree());

                        }
                        break;

                        default :
                            break loop10;
                    }
                }

            }

            retval.stop = input.LT(-1);

            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }
        catch (RecognitionException re) {
            reportError(re);
            recover(input,re);
            retval.tree = (CommonTree)adaptor.errorNode(input, retval.start, input.LT(-1), re);
        }
        finally {
            // do for sure before leaving
        }
        return retval;
    }
,
>
, <(startLine=4395 endLine=4401 srcPath=/root/NewExperiment/elasticsearchFilter/00877/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public ConcurrentHashMapSpliterator<K> spliterator() {
            Node<K,V>[] t;
            ConcurrentHashMapV8<K,V> m = map;
            long n = m.sumCount();
            int f = (t = m.table) == null ? 0 : t.length;
            return new KeySpliterator<K,V>(t, f, 0, f, n < 0L ? 0L : n);
        }
,
(startLine=4453 endLine=4459 srcPath=/root/NewExperiment/elasticsearchFilter/00877/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public ConcurrentHashMapSpliterator<V> spliterator() {
            Node<K,V>[] t;
            ConcurrentHashMapV8<K,V> m = map;
            long n = m.sumCount();
            int f = (t = m.table) == null ? 0 : t.length;
            return new ValueSpliterator<K,V>(t, f, 0, f, n < 0L ? 0L : n);
        }
,
(startLine=4541 endLine=4547 srcPath=/root/NewExperiment/elasticsearchFilter/00877/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public ConcurrentHashMapSpliterator<Map.Entry<K,V>> spliterator() {
            Node<K,V>[] t;
            ConcurrentHashMapV8<K,V> m = map;
            long n = m.sumCount();
            int f = (t = m.table) == null ? 0 : t.length;
            return new EntrySpliterator<K,V>(t, f, 0, f, n < 0L ? 0L : n, m);
        }
,
>
, <(startLine=77 endLine=90 srcPath=/root/NewExperiment/elasticsearchFilter/01059/src/main/java/org/elasticsearch/rest/action/get/RestGetSourceAction.java)
            public void onResponse(GetResponse response) {

                try {
                    XContentBuilder builder = restContentBuilder(request, response.getSourceInternal());
                    if (!response.isExists()) {
                        channel.sendResponse(new XContentRestResponse(request, NOT_FOUND, builder));
                    } else {
                        RestXContentBuilder.directSource(response.getSourceInternal(), builder, request);
                        channel.sendResponse(new XContentRestResponse(request, OK, builder));
                    }
                } catch (Throwable e) {
                    onFailure(e);
                }
            }
,
(startLine=80 endLine=93 srcPath=/root/NewExperiment/elasticsearchFilter/01059/src/main/java/org/elasticsearch/rest/action/get/RestGetAction.java)
            public void onResponse(GetResponse response) {

                try {
                    XContentBuilder builder = restContentBuilder(request);
                    response.toXContent(builder, request);
                    if (!response.isExists()) {
                        channel.sendResponse(new XContentRestResponse(request, NOT_FOUND, builder));
                    } else {
                        channel.sendResponse(new XContentRestResponse(request, OK, builder));
                    }
                } catch (Throwable e) {
                    onFailure(e);
                }
            }
,
>
, <(startLine=82 endLine=102 srcPath=/root/NewExperiment/elasticsearchFilter/00624/src/test/java/org/elasticsearch/test/unit/index/mapper/dynamic/DynamicMappingTests.java)
    public void testDynamicStrict() throws IOException {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .field("dynamic", "strict")
                .startObject("properties")
                .startObject("field1").field("type", "string").endObject()
                .endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTests.newParser().parse(mapping);

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .field("field1", "value1")
                    .field("field2", "value2")
                    .copiedBytes());
            assert false;
        } catch (StrictDynamicMappingException e) {
            // all is well
        }
    }
,
(startLine=129 endLine=152 srcPath=/root/NewExperiment/elasticsearchFilter/00624/src/test/java/org/elasticsearch/test/unit/index/mapper/dynamic/DynamicMappingTests.java)
    public void testDynamicStrictWithInnerObjectButDynamicSetOnRoot() throws IOException {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .field("dynamic", "strict")
                .startObject("properties")
                .startObject("obj1").startObject("properties")
                .startObject("field1").field("type", "string").endObject()
                .endObject().endObject()
                .endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTests.newParser().parse(mapping);

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject().startObject("obj1")
                    .field("field1", "value1")
                    .field("field2", "value2")
                    .endObject()
                    .copiedBytes());
            assert false;
        } catch (StrictDynamicMappingException e) {
            // all is well
        }
    }
,
>
, <(startLine=103 endLine=111 srcPath=/root/NewExperiment/elasticsearchFilter/01330/src/main/java/org/elasticsearch/action/termvector/TransportMultiTermVectorsAction.java)
                public void onResponse(MultiTermVectorsShardResponse response) {
                    for (int i = 0; i < response.locations.size(); i++) {
                        responses.set(response.locations.get(i), new MultiTermVectorsItemResponse(response.responses.get(i),
                                response.failures.get(i)));
                    }
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }
,
(startLine=102 endLine=109 srcPath=/root/NewExperiment/elasticsearchFilter/01330/src/main/java/org/elasticsearch/action/get/TransportMultiGetAction.java)
                public void onResponse(MultiGetShardResponse response) {
                    for (int i = 0; i < response.locations.size(); i++) {
                        responses.set(response.locations.get(i), new MultiGetItemResponse(response.responses.get(i), response.failures.get(i)));
                    }
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }
,
>
, <(startLine=887 endLine=939 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgTests.java)
    public void testGiantGap() {

        SearchResponse response = client()
                .prepareSearch("idx").setTypes("gap_type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(1).extendedBounds(0L, 49L)
                                .subAggregation(min("the_metric").field(GAP_FIELD))
                                .subAggregation(movingAvg("movavg_values")
                                        .window(windowSize)
                                        .modelBuilder(randomModelBuilder())
                                        .gapPolicy(gapPolicy)
                                        .setBucketsPaths("the_metric"))
                ).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(50));

        double lastValue = ((SimpleValue)(buckets.get(0).getAggregations().get("movavg_values"))).value();
        assertThat(Double.compare(lastValue, 0.0d), greaterThanOrEqualTo(0));

        double currentValue;
        for (int i = 1; i < 49; i++) {
            SimpleValue current = buckets.get(i).getAggregations().get("movavg_values");
            if (current != null) {
                currentValue = current.value();

                // Since there are only two values in this test, at the beginning and end, the moving average should
                // decrease every step (until it reaches zero).  Crude way to check that it's doing the right thing
                // without actually verifying the computed values.  Should work for all types of moving avgs and
                // gap policies
                assertThat(Double.compare(lastValue, currentValue), greaterThanOrEqualTo(0));
                lastValue = currentValue;
            }
        }


        SimpleValue current = buckets.get(49).getAggregations().get("movavg_values");
        assertThat(current, notNullValue());
        currentValue = current.value();

        if (gapPolicy.equals(BucketHelpers.GapPolicy.SKIP)) {
            // if we are ignoring, movavg could go up (holt) or stay the same (simple, linear, ewma)
            assertThat(Double.compare(lastValue, currentValue), lessThanOrEqualTo(0));
        } else if (gapPolicy.equals(BucketHelpers.GapPolicy.INSERT_ZEROS)) {
            // If we insert zeros, this should always increase the moving avg since the last bucket has a real value
            assertThat(Double.compare(lastValue, currentValue), equalTo(-1));
        }
    }
,
(startLine=945 endLine=1008 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgTests.java)
    public void testGiantGapWithPredict() {
        int numPredictions = randomIntBetween(1, 10);

        SearchResponse response = client()
                .prepareSearch("idx").setTypes("gap_type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(1).extendedBounds(0L, 49L)
                                .subAggregation(min("the_metric").field(GAP_FIELD))
                                .subAggregation(movingAvg("movavg_values")
                                        .window(windowSize)
                                        .modelBuilder(randomModelBuilder())
                                        .gapPolicy(gapPolicy)
                                        .setBucketsPaths("the_metric")
                                        .predict(numPredictions))
                ).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(50 + numPredictions));


        double lastValue = ((SimpleValue)(buckets.get(0).getAggregations().get("movavg_values"))).value();
        assertThat(Double.compare(lastValue, 0.0d), greaterThanOrEqualTo(0));

        double currentValue;
        for (int i = 1; i < 49; i++) {
            SimpleValue current = buckets.get(i).getAggregations().get("movavg_values");
            if (current != null) {
                currentValue = current.value();

                // Since there are only two values in this test, at the beginning and end, the moving average should
                // decrease every step (until it reaches zero).  Crude way to check that it's doing the right thing
                // without actually verifying the computed values.  Should work for all types of moving avgs and
                // gap policies
                assertThat(Double.compare(lastValue, currentValue), greaterThanOrEqualTo(0));
                lastValue = currentValue;
            }
        }

        SimpleValue current = buckets.get(49).getAggregations().get("movavg_values");
        assertThat(current, notNullValue());
        currentValue = current.value();

        if (gapPolicy.equals(BucketHelpers.GapPolicy.SKIP)) {
            // if we are ignoring, movavg could go up (holt) or stay the same (simple, linear, ewma)
            assertThat(Double.compare(lastValue, currentValue), lessThanOrEqualTo(0));
        } else if (gapPolicy.equals(BucketHelpers.GapPolicy.INSERT_ZEROS)) {
            // If we insert zeros, this should always increase the moving avg since the last bucket has a real value
            assertThat(Double.compare(lastValue, currentValue), equalTo(-1));
        }

        // Now check predictions
        for (int i = 50; i < 50 + numPredictions; i++) {
            // Unclear at this point which direction the predictions will go, just verify they are
            // not null, and that we don't have the_metric anymore
            assertThat((buckets.get(i).getAggregations().get("movavg_values")), notNullValue());
            assertThat((buckets.get(i).getAggregations().get("the_metric")), nullValue());
        }
    }
,
>
, <(startLine=2197 endLine=2205 srcPath=/root/NewExperiment/elasticsearchFilter/00900/src/test/java/org/elasticsearch/test/unit/index/query/SimpleIndexQueryParserTests.java)
    public void testCommonTermsQuery1() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/test/unit/index/query/commonTerms-query1.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, instanceOf(ExtendedCommonTermsQuery.class));
        ExtendedCommonTermsQuery ectQuery = (ExtendedCommonTermsQuery) parsedQuery;
        assertThat(ectQuery.getHighFreqMinimumNumberShouldMatch(), nullValue());
        assertThat(ectQuery.getLowFreqMinimumNumberShouldMatch(), equalTo("2"));
    }
,
(startLine=2208 endLine=2216 srcPath=/root/NewExperiment/elasticsearchFilter/00900/src/test/java/org/elasticsearch/test/unit/index/query/SimpleIndexQueryParserTests.java)
    public void testCommonTermsQuery2() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/test/unit/index/query/commonTerms-query2.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, instanceOf(ExtendedCommonTermsQuery.class));
        ExtendedCommonTermsQuery ectQuery = (ExtendedCommonTermsQuery) parsedQuery;
        assertThat(ectQuery.getHighFreqMinimumNumberShouldMatch(), equalTo("50%"));
        assertThat(ectQuery.getLowFreqMinimumNumberShouldMatch(), equalTo("5<20%"));
    }
,
(startLine=2219 endLine=2227 srcPath=/root/NewExperiment/elasticsearchFilter/00900/src/test/java/org/elasticsearch/test/unit/index/query/SimpleIndexQueryParserTests.java)
    public void testCommonTermsQuery3() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/test/unit/index/query/commonTerms-query3.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, instanceOf(ExtendedCommonTermsQuery.class));
        ExtendedCommonTermsQuery ectQuery = (ExtendedCommonTermsQuery) parsedQuery;
        assertThat(ectQuery.getHighFreqMinimumNumberShouldMatch(), nullValue());
        assertThat(ectQuery.getLowFreqMinimumNumberShouldMatch(), equalTo("2"));
    }
,
>
, <(startLine=251 endLine=263 srcPath=/root/NewExperiment/elasticsearchFilter/00109/modules/elasticsearch/src/main/java/org/elasticsearch/util/guice/inject/spi/InjectionPoint.java)
  public static Set<InjectionPoint> forStaticMethodsAndFields(TypeLiteral type) {
    List<InjectionPoint> sink = Lists.newArrayList();
    Errors errors = new Errors();

    addInjectionPoints(type, Factory.FIELDS, true, sink, errors);
    addInjectionPoints(type, Factory.METHODS, true, sink, errors);

    ImmutableSet<InjectionPoint> result = ImmutableSet.copyOf(sink);
    if (errors.hasErrors()) {
      throw new ConfigurationException(errors.getMessages()).withPartialValue(result);
    }
    return result;
  }
,
(startLine=291 endLine=304 srcPath=/root/NewExperiment/elasticsearchFilter/00109/modules/elasticsearch/src/main/java/org/elasticsearch/util/guice/inject/spi/InjectionPoint.java)
  public static Set<InjectionPoint> forInstanceMethodsAndFields(TypeLiteral<?> type) {
    List<InjectionPoint> sink = Lists.newArrayList();
    Errors errors = new Errors();

    // TODO (crazybob): Filter out overridden members.
    addInjectionPoints(type, Factory.FIELDS, false, sink, errors);
    addInjectionPoints(type, Factory.METHODS, false, sink, errors);

    ImmutableSet<InjectionPoint> result = ImmutableSet.copyOf(sink);
    if (errors.hasErrors()) {
      throw new ConfigurationException(errors.getMessages()).withPartialValue(result);
    }
    return result;
  }
,
>
, <(startLine=332 endLine=341 srcPath=/root/NewExperiment/elasticsearchFilter/01643/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java)
        if (includeRelocations) {
            long relocatingShardsSize = sizeOfRelocatingShards(node, shardSizes, false);
            DiskUsage usageIncludingRelocations = new DiskUsage(node.nodeId(), node.node().name(),
                    usage.getTotalBytes(), usage.getFreeBytes() - relocatingShardsSize);
            if (logger.isTraceEnabled()) {
                logger.trace("usage without relocations: {}", usage);
                logger.trace("usage with relocations: [{} bytes] {}", relocatingShardsSize, usageIncludingRelocations);
            }
            usage = usageIncludingRelocations;
        }
,
(startLine=478 endLine=488 srcPath=/root/NewExperiment/elasticsearchFilter/01643/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java)
        if (includeRelocations) {
            Map<String, Long> shardSizes = clusterInfo.getShardSizes();
            long relocatingShardsSize = sizeOfRelocatingShards(node, shardSizes, true);
            DiskUsage usageIncludingRelocations = new DiskUsage(node.nodeId(), node.node().name(),
                    usage.getTotalBytes(), usage.getFreeBytes() - relocatingShardsSize);
            if (logger.isTraceEnabled()) {
                logger.trace("usage without relocations: {}", usage);
                logger.trace("usage with relocations: [{} bytes] {}", relocatingShardsSize, usageIncludingRelocations);
            }
            usage = usageIncludingRelocations;
        }
,
>
, <(startLine=332 endLine=368 srcPath=/root/NewExperiment/elasticsearchFilter/00956/src/test/java/org/elasticsearch/index/fielddata/DuellFieldDataTests.java)
    private static void duellFieldDataDouble(Random random, AtomicReaderContext context, IndexNumericFieldData left, IndexNumericFieldData right) throws Exception {
        AtomicNumericFieldData leftData = random.nextBoolean() ? left.load(context) : left.loadDirect(context);
        AtomicNumericFieldData rightData = random.nextBoolean() ? right.load(context) : right.loadDirect(context);

        assertThat(leftData.isMultiValued(), equalTo(rightData.isMultiValued()));
        assertThat(leftData.getNumDocs(), equalTo(rightData.getNumDocs()));

        int numDocs = leftData.getNumDocs();
        DoubleValues leftDoubleValues = leftData.getDoubleValues();
        DoubleValues rightDoubleValues = rightData.getDoubleValues();
        for (int i = 0; i < numDocs; i++) {
            assertThat(leftDoubleValues.hasValue(i), equalTo(rightDoubleValues.hasValue(i)));
            if (leftDoubleValues.hasValue(i)) {
                assertThat(leftDoubleValues.getValue(i), equalTo(rightDoubleValues.getValue(i)));

            } else {
                assertThat(leftDoubleValues.getValue(i), equalTo(0d));
                assertThat(rightDoubleValues.getValue(i), equalTo(0d));
            }

            boolean hasValue = leftDoubleValues.hasValue(i);
            DoubleValues.Iter leftIter = leftDoubleValues.getIter(i);
            DoubleValues.Iter rightIter = rightDoubleValues.getIter(i);
            assertThat(leftIter.hasNext(), equalTo(rightIter.hasNext()));
            assertThat(leftIter.hasNext(), equalTo(hasValue));

            while (leftIter.hasNext()) {
                assertThat(hasValue, equalTo(true));
                assertThat(leftIter.hasNext(), equalTo(rightIter.hasNext()));
                double rightValue = rightIter.next();
                double leftValue = leftIter.next();

                assertThat(leftValue, equalTo(rightValue));
            }
            assertThat(leftIter.hasNext(), equalTo(rightIter.hasNext()));
        }
    }
,
(startLine=370 endLine=406 srcPath=/root/NewExperiment/elasticsearchFilter/00956/src/test/java/org/elasticsearch/index/fielddata/DuellFieldDataTests.java)
    private static void duellFieldDataLong(Random random, AtomicReaderContext context, IndexNumericFieldData left, IndexNumericFieldData right) throws Exception {
        AtomicNumericFieldData leftData = random.nextBoolean() ? left.load(context) : left.loadDirect(context);
        AtomicNumericFieldData rightData = random.nextBoolean() ? right.load(context) : right.loadDirect(context);

        assertThat(leftData.isMultiValued(), equalTo(rightData.isMultiValued()));
        assertThat(leftData.getNumDocs(), equalTo(rightData.getNumDocs()));

        int numDocs = leftData.getNumDocs();
        LongValues leftDoubleValues = leftData.getLongValues();
        LongValues rightDoubleValues = rightData.getLongValues();
        for (int i = 0; i < numDocs; i++) {
            assertThat(leftDoubleValues.hasValue(i), equalTo(rightDoubleValues.hasValue(i)));
            if (leftDoubleValues.hasValue(i)) {
                assertThat(leftDoubleValues.getValue(i), equalTo(rightDoubleValues.getValue(i)));

            } else {
                assertThat(leftDoubleValues.getValue(i), equalTo(0l));
                assertThat(rightDoubleValues.getValue(i), equalTo(0l));
            }

            boolean hasValue = leftDoubleValues.hasValue(i);
            LongValues.Iter leftIter = leftDoubleValues.getIter(i);
            LongValues.Iter rightIter = rightDoubleValues.getIter(i);
            assertThat(leftIter.hasNext(), equalTo(rightIter.hasNext()));
            assertThat(leftIter.hasNext(), equalTo(hasValue));

            while (leftIter.hasNext()) {
                assertThat(hasValue, equalTo(true));
                assertThat(leftIter.hasNext(), equalTo(rightIter.hasNext()));
                long rightValue = rightIter.next();
                long leftValue = leftIter.next();

                assertThat(leftValue, equalTo(rightValue));
            }
            assertThat(leftIter.hasNext(), equalTo(rightIter.hasNext()));
        }
    }
,
>
, <(startLine=61 endLine=80 srcPath=/root/NewExperiment/elasticsearchFilter/01731/core/src/test/java/org/elasticsearch/index/query/SpanNearQueryBuilderTests.java)
    public void testValidate() {
        SpanNearQueryBuilder queryBuilder = new SpanNearQueryBuilder(1);
        assertValidate(queryBuilder, 1); // empty clause list

        int totalExpectedErrors = 0;
        int clauses = randomIntBetween(1, 10);
        for (int i = 0; i < clauses; i++) {
            if (randomBoolean()) {
                if (randomBoolean()) {
                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
                } else {
                    queryBuilder.clause(null);
                }
                totalExpectedErrors++;
            } else {
                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
            }
        }
        assertValidate(queryBuilder, totalExpectedErrors);
    }
,
(startLine=57 endLine=76 srcPath=/root/NewExperiment/elasticsearchFilter/01731/core/src/test/java/org/elasticsearch/index/query/SpanOrQueryBuilderTests.java)
    public void testValidate() {
        SpanOrQueryBuilder queryBuilder = new SpanOrQueryBuilder();
        assertValidate(queryBuilder, 1); // empty clause list

        int totalExpectedErrors = 0;
        int clauses = randomIntBetween(1, 10);
        for (int i = 0; i < clauses; i++) {
            if (randomBoolean()) {
                if (randomBoolean()) {
                    queryBuilder.clause(new SpanTermQueryBuilder("", "test"));
                } else {
                    queryBuilder.clause(null);
                }
                totalExpectedErrors++;
            } else {
                queryBuilder.clause(new SpanTermQueryBuilder("name", "value"));
            }
        }
        assertValidate(queryBuilder, totalExpectedErrors);
    }
,
>
, <(startLine=50 endLine=81 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryResponse.java)
    public void readFrom(StreamInput in) throws IOException {
        super.readFrom(in);
        int size = in.readVInt();
        phase1FileNames = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1FileNames.add(in.readString());
        }
        size = in.readVInt();
        phase1FileSizes = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1FileSizes.add(in.readVLong());
        }

        size = in.readVInt();
        phase1ExistingFileNames = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1ExistingFileNames.add(in.readString());
        }
        size = in.readVInt();
        phase1ExistingFileSizes = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1ExistingFileSizes.add(in.readVLong());
        }

        phase1TotalSize = in.readVLong();
        phase1ExistingTotalSize = in.readVLong();
        phase1Time = in.readVLong();
        phase1ThrottlingWaitTime = in.readVLong();
        startTime = in.readVLong();
        phase2Operations = in.readVInt();
        phase2Time = in.readVLong();
    }
,
(startLine=66 endLine=94 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/indices/recovery/RecoveryFilesInfoRequest.java)
    public void readFrom(StreamInput in) throws IOException {
        super.readFrom(in);
        recoveryId = in.readLong();
        shardId = ShardId.readShardId(in);
        int size = in.readVInt();
        phase1FileNames = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1FileNames.add(in.readString());
        }

        size = in.readVInt();
        phase1FileSizes = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1FileSizes.add(in.readVLong());
        }

        size = in.readVInt();
        phase1ExistingFileNames = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1ExistingFileNames.add(in.readString());
        }

        size = in.readVInt();
        phase1ExistingFileSizes = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            phase1ExistingFileSizes.add(in.readVLong());
        }
        totalTranslogOps = in.readVInt();
    }
,
>
, <(startLine=134 endLine=148 srcPath=/root/NewExperiment/elasticsearchFilter/00505/plugins/lang/javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineTests.java)
    @Test public void testChangingVarsCrossExecution1() {
        Map<String, Object> vars = new HashMap<String, Object>();
        Map<String, Object> ctx = new HashMap<String, Object>();
        vars.put("ctx", ctx);
        Object compiledScript = se.compile("ctx.value");

        ExecutableScript script = se.executable(compiledScript, vars);
        ctx.put("value", 1);
        Object o = script.run();
        assertThat(((Number) o).intValue(), equalTo(1));

        ctx.put("value", 2);
        o = script.run();
        assertThat(((Number) o).intValue(), equalTo(2));
    }
,
(startLine=150 endLine=162 srcPath=/root/NewExperiment/elasticsearchFilter/00505/plugins/lang/javascript/src/test/java/org/elasticsearch/script/javascript/JavaScriptScriptEngineTests.java)
    @Test public void testChangingVarsCrossExecution2() {
        Map<String, Object> vars = new HashMap<String, Object>();
        Object compiledScript = se.compile("value");

        ExecutableScript script = se.executable(compiledScript, vars);
        script.setNextVar("value", 1);
        Object o = script.run();
        assertThat(((Number) o).intValue(), equalTo(1));

        script.setNextVar("value", 2);
        o = script.run();
        assertThat(((Number) o).intValue(), equalTo(2));
    }
,
(startLine=110 endLine=124 srcPath=/root/NewExperiment/elasticsearchFilter/00505/plugins/lang/python/src/test/java/org/elasticsearch/script/python/PythonScriptEngineTests.java)
    @Test public void testChangingVarsCrossExecution1() {
        Map<String, Object> vars = new HashMap<String, Object>();
        Map<String, Object> ctx = new HashMap<String, Object>();
        vars.put("ctx", ctx);
        Object compiledScript = se.compile("ctx['value']");

        ExecutableScript script = se.executable(compiledScript, vars);
        ctx.put("value", 1);
        Object o = script.run();
        assertThat(((Number) o).intValue(), equalTo(1));

        ctx.put("value", 2);
        o = script.run();
        assertThat(((Number) o).intValue(), equalTo(2));
    }
,
(startLine=126 endLine=139 srcPath=/root/NewExperiment/elasticsearchFilter/00505/plugins/lang/python/src/test/java/org/elasticsearch/script/python/PythonScriptEngineTests.java)
    @Test public void testChangingVarsCrossExecution2() {
        Map<String, Object> vars = new HashMap<String, Object>();
        Map<String, Object> ctx = new HashMap<String, Object>();
        Object compiledScript = se.compile("value");

        ExecutableScript script = se.executable(compiledScript, vars);
        script.setNextVar("value", 1);
        Object o = script.run();
        assertThat(((Number) o).intValue(), equalTo(1));

        script.setNextVar("value", 2);
        o = script.run();
        assertThat(((Number) o).intValue(), equalTo(2));
    }
,
>
, <(startLine=70 endLine=92 srcPath=/root/NewExperiment/elasticsearchFilter/01762/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java)
            } else if (token == XContentParser.Token.START_OBJECT) {
                switch (currentFieldName) {
                case "must":
                    query = parseContext.parseInnerQueryBuilder();
                    mustClauses.add(query);
                    break;
                case "should":
                    query = parseContext.parseInnerQueryBuilder();
                    shouldClauses.add(query);
                    break;
                case "filter":
                    query = parseContext.parseInnerQueryBuilder();
                    filterClauses.add(query);
                    break;
                case "must_not":
                case "mustNot":
                    query = parseContext.parseInnerQueryBuilder();
                    mustNotClauses.add(query);
                    break;
                default:
                    throw new ParsingException(parser.getTokenLocation(), "[bool] query does not support [" + currentFieldName + "]");
                }
            } else if (token == XContentParser.Token.START_ARRAY) {
,
(startLine=92 endLine=116 srcPath=/root/NewExperiment/elasticsearchFilter/01762/core/src/main/java/org/elasticsearch/index/query/BoolQueryParser.java)
            } else if (token == XContentParser.Token.START_ARRAY) {
                while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                    switch (currentFieldName) {
                    case "must":
                        query = parseContext.parseInnerQueryBuilder();
                        mustClauses.add(query);
                        break;
                    case "should":
                        query = parseContext.parseInnerQueryBuilder();
                        shouldClauses.add(query);
                        break;
                    case "filter":
                        query = parseContext.parseInnerQueryBuilder();
                        filterClauses.add(query);
                        break;
                    case "must_not":
                    case "mustNot":
                        query = parseContext.parseInnerQueryBuilder();
                        mustNotClauses.add(query);
                        break;
                    default:
                        throw new ParsingException(parser.getTokenLocation(), "bool query does not support [" + currentFieldName + "]");
                    }
                }
            } else if (token.isValue()) {
,
>
, <(startLine=308 endLine=328 srcPath=/root/NewExperiment/elasticsearchFilter/00959/src/test/java/org/elasticsearch/search/facet/SimpleFacetsTests.java)
                public void judge(Facets firstRun, Facets result) {
                    for (Facet f : result) {
                        TermsFacet facet = (TermsFacet) f;
                        assertThat(facet.getName(), isIn(new String[] {"short", "double", "byte", "float", "integer", "long", "termFacet"}));
                        TermsFacet firstRunFacet = (TermsFacet) firstRun.getFacets().get(facet.getName());
                        assertThat(facet.getEntries().size(), equalTo(firstRunFacet.getEntries().size()));

                        assertThat(facet.getEntries().size(), equalTo(10));
                        assertThat(facet.getTotalCount(), equalTo(100l));
                        assertThat(facet.getOtherCount(), equalTo(90l));
                        assertThat(facet.getMissingCount(), equalTo(10l));

                        List<? extends Entry> right = facet.getEntries();
                        List<? extends Entry> left = firstRunFacet.getEntries();

                        for (int i = 0; i < facet.getEntries().size(); i++) {
                            assertThat(left.get(i).getTerm(), equalTo(right.get(i).getTerm()));
                            assertThat(left.get(i).getCount(), equalTo(right.get(i).getCount()));
                        }
                    }
                }
,
(startLine=364 endLine=384 srcPath=/root/NewExperiment/elasticsearchFilter/00959/src/test/java/org/elasticsearch/search/facet/SimpleFacetsTests.java)
                 public void judge(Facets firstRun, Facets result) {
                     for (Facet f : result) {
                         TermsFacet facet = (TermsFacet) f;
                         assertThat(facet.getName(), equalTo("termFacet"));
                         TermsFacet firstRunFacet = (TermsFacet) firstRun.getFacets().get(facet.getName());
                         assertThat(facet.getEntries().size(), equalTo(firstRunFacet.getEntries().size()));

                         assertThat(facet.getEntries().size(), equalTo(10));
                         assertThat(facet.getTotalCount(), equalTo(100l));
                         assertThat(facet.getOtherCount(), equalTo(90l));
                         assertThat(facet.getMissingCount(), equalTo(10l));

                         List<? extends Entry> right = facet.getEntries();
                         List<? extends Entry> left = firstRunFacet.getEntries();

                         for (int i = 0; i < facet.getEntries().size(); i++) {
                             assertThat(left.get(i).getTerm(), equalTo(right.get(i).getTerm()));
                             assertThat(left.get(i).getCount(), equalTo(right.get(i).getCount()));
                         }
                     }
                 }
,
>
, <(startLine=112 endLine=135 srcPath=/root/NewExperiment/elasticsearchFilter/00398/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java)
                    try {
                        do {
                            Term term = termEnum.term();
                            if (term == null || term.field() != field) break;
                            // TODO we can optimize this, since type is the prefix, and we get terms ordered
                            // so, only need to move to the next type once its different
                            Uid uid = Uid.createUid(term.text());

                            TypeBuilder typeBuilder = readerBuilder.get(uid.type());
                            if (typeBuilder == null) {
                                typeBuilder = new TypeBuilder(reader);
                                readerBuilder.put(StringHelper.intern(uid.type()), typeBuilder);
                            }

                            BytesWrap idAsBytes = checkIfCanReuse(builders, new BytesWrap(uid.id()));
                            termDocs.seek(termEnum);
                            while (termDocs.next()) {
                                // when traversing, make sure to ignore deleted docs, so the key->docId will be correct
                                if (!reader.isDeleted(termDocs.doc())) {
                                    typeBuilder.idToDoc.put(idAsBytes, termDocs.doc());
                                }
                            }
                        } while (termEnum.next());
                    } finally {
,
(startLine=155 endLine=187 srcPath=/root/NewExperiment/elasticsearchFilter/00398/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java)
                    try {
                        do {
                            Term term = termEnum.term();
                            if (term == null || term.field() != field) break;
                            // TODO we can optimize this, since type is the prefix, and we get terms ordered
                            // so, only need to move to the next type once its different
                            Uid uid = Uid.createUid(term.text());

                            TypeBuilder typeBuilder = readerBuilder.get(uid.type());
                            if (typeBuilder == null) {
                                typeBuilder = new TypeBuilder(reader);
                                readerBuilder.put(StringHelper.intern(uid.type()), typeBuilder);
                            }

                            BytesWrap idAsBytes = checkIfCanReuse(builders, new BytesWrap(uid.id()));
                            boolean added = false; // optimize for when all the docs are deleted for this id

                            termDocs.seek(termEnum);
                            while (termDocs.next()) {
                                // ignore deleted docs while we are at it
                                if (!reader.isDeleted(termDocs.doc())) {
                                    if (!added) {
                                        typeBuilder.parentIdsValues.add(idAsBytes);
                                        added = true;
                                    }
                                    typeBuilder.parentIdsOrdinals[termDocs.doc()] = t;
                                }
                            }
                            if (added) {
                                t++;
                            }
                        } while (termEnum.next());
                    } finally {
,
>
, <(startLine=83 endLine=134 srcPath=/root/NewExperiment/elasticsearchFilter/00617/src/main/java/org/elasticsearch/common/bloom/MurmurHash.java)
    public static long hash64(ByteBuffer key, int offset, int length, long seed) {
        long m64 = 0xc6a4a7935bd1e995L;
        int r64 = 47;

        long h64 = (seed & 0xffffffffL) ^ (m64 * length);

        int lenLongs = length >> 3;

        for (int i = 0; i < lenLongs; ++i) {
            int i_8 = i << 3;

            long k64 = ((long) key.get(offset + i_8 + 0) & 0xff) + (((long) key.get(offset + i_8 + 1) & 0xff) << 8) +
                    (((long) key.get(offset + i_8 + 2) & 0xff) << 16) + (((long) key.get(offset + i_8 + 3) & 0xff) << 24) +
                    (((long) key.get(offset + i_8 + 4) & 0xff) << 32) + (((long) key.get(offset + i_8 + 5) & 0xff) << 40) +
                    (((long) key.get(offset + i_8 + 6) & 0xff) << 48) + (((long) key.get(offset + i_8 + 7) & 0xff) << 56);

            k64 *= m64;
            k64 ^= k64 >>> r64;
            k64 *= m64;

            h64 ^= k64;
            h64 *= m64;
        }

        int rem = length & 0x7;

        switch (rem) {
            case 0:
                break;
            case 7:
                h64 ^= (long) key.get(offset + length - rem + 6) << 48;
            case 6:
                h64 ^= (long) key.get(offset + length - rem + 5) << 40;
            case 5:
                h64 ^= (long) key.get(offset + length - rem + 4) << 32;
            case 4:
                h64 ^= (long) key.get(offset + length - rem + 3) << 24;
            case 3:
                h64 ^= (long) key.get(offset + length - rem + 2) << 16;
            case 2:
                h64 ^= (long) key.get(offset + length - rem + 1) << 8;
            case 1:
                h64 ^= (long) key.get(offset + length - rem);
                h64 *= m64;
        }

        h64 ^= h64 >>> r64;
        h64 *= m64;
        h64 ^= h64 >>> r64;

        return h64;
    }
,
(startLine=136 endLine=187 srcPath=/root/NewExperiment/elasticsearchFilter/00617/src/main/java/org/elasticsearch/common/bloom/MurmurHash.java)
    public static long hash64(byte[] key, int offset, int length, long seed) {
        long m64 = 0xc6a4a7935bd1e995L;
        int r64 = 47;

        long h64 = (seed & 0xffffffffL) ^ (m64 * length);

        int lenLongs = length >> 3;

        for (int i = 0; i < lenLongs; ++i) {
            int i_8 = i << 3;

            long k64 = ((long) key[offset + i_8 + 0] & 0xff) + (((long) key[offset + i_8 + 1] & 0xff) << 8) +
                    (((long) key[offset + i_8 + 2] & 0xff) << 16) + (((long) key[offset + i_8 + 3] & 0xff) << 24) +
                    (((long) key[offset + i_8 + 4] & 0xff) << 32) + (((long) key[offset + i_8 + 5] & 0xff) << 40) +
                    (((long) key[offset + i_8 + 6] & 0xff) << 48) + (((long) key[offset + i_8 + 7] & 0xff) << 56);

            k64 *= m64;
            k64 ^= k64 >>> r64;
            k64 *= m64;

            h64 ^= k64;
            h64 *= m64;
        }

        int rem = length & 0x7;

        switch (rem) {
            case 0:
                break;
            case 7:
                h64 ^= (long) key[offset + length - rem + 6] << 48;
            case 6:
                h64 ^= (long) key[offset + length - rem + 5] << 40;
            case 5:
                h64 ^= (long) key[offset + length - rem + 4] << 32;
            case 4:
                h64 ^= (long) key[offset + length - rem + 3] << 24;
            case 3:
                h64 ^= (long) key[offset + length - rem + 2] << 16;
            case 2:
                h64 ^= (long) key[offset + length - rem + 1] << 8;
            case 1:
                h64 ^= (long) key[offset + length - rem];
                h64 *= m64;
        }

        h64 ^= h64 >>> r64;
        h64 *= m64;
        h64 ^= h64 >>> r64;

        return h64;
    }
,
>
, <(startLine=230 endLine=237 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java)
        if ("node1".equals(allowedNode)) {
            assertEquals("source primary is allocated on this node",
                resizeAllocationDecider.canAllocate(shardRouting, clusterState.getRoutingNodes().node("node1"),
                    routingAllocation).getExplanation());
            assertEquals("source primary is allocated on another node",
                resizeAllocationDecider.canAllocate(shardRouting, clusterState.getRoutingNodes().node("node2"),
                    routingAllocation).getExplanation());
        } else {
,
(startLine=237 endLine=244 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ResizeAllocationDeciderTests.java)
        } else {
            assertEquals("source primary is allocated on another node",
                resizeAllocationDecider.canAllocate(shardRouting, clusterState.getRoutingNodes().node("node1"),
                    routingAllocation).getExplanation());
            assertEquals("source primary is allocated on this node",
                resizeAllocationDecider.canAllocate(shardRouting, clusterState.getRoutingNodes().node("node2"),
                    routingAllocation).getExplanation());
        }
,
>
, <(startLine=1771 endLine=1798 srcPath=/root/NewExperiment/elasticsearchFilter/00793/src/main/java/jsr166e/ForkJoinPool.java)
    private void idleAwaitWork(WorkQueue w, long currentCtl, long prevCtl) {
        if (w != null && w.eventCount < 0 &&
            !tryTerminate(false, false) && (int)prevCtl != 0 &&
            ctl == currentCtl) {
            int dc = -(short)(currentCtl >>> TC_SHIFT);
            long parkTime = dc < 0 ? FAST_IDLE_TIMEOUT: (dc + 1) * IDLE_TIMEOUT;
            long deadline = System.nanoTime() + parkTime - TIMEOUT_SLOP;
            Thread wt = Thread.currentThread();
            while (ctl == currentCtl) {
                Thread.interrupted();  // timed variant of version in scan()
                U.putObject(wt, PARKBLOCKER, this);
                w.parker = wt;
                if (ctl == currentCtl)
                    U.park(false, parkTime);
                w.parker = null;
                U.putObject(wt, PARKBLOCKER, null);
                if (ctl != currentCtl)
                    break;
                if (deadline - System.nanoTime() <= 0L &&
                    U.compareAndSwapLong(this, CTL, currentCtl, prevCtl)) {
                    w.eventCount = (w.eventCount + E_SEQ) | E_MASK;
                    w.hint = -1;
                    w.qlock = -1;   // shrink
                    break;
                }
            }
        }
    }
,
(startLine=1771 endLine=1798 srcPath=/root/NewExperiment/elasticsearchFilter/00793/src/main/java/jsr166y/ForkJoinPool.java)
    private void idleAwaitWork(WorkQueue w, long currentCtl, long prevCtl) {
        if (w != null && w.eventCount < 0 &&
            !tryTerminate(false, false) && (int)prevCtl != 0 &&
            ctl == currentCtl) {
            int dc = -(short)(currentCtl >>> TC_SHIFT);
            long parkTime = dc < 0 ? FAST_IDLE_TIMEOUT: (dc + 1) * IDLE_TIMEOUT;
            long deadline = System.nanoTime() + parkTime - TIMEOUT_SLOP;
            Thread wt = Thread.currentThread();
            while (ctl == currentCtl) {
                Thread.interrupted();  // timed variant of version in scan()
                U.putObject(wt, PARKBLOCKER, this);
                w.parker = wt;
                if (ctl == currentCtl)
                    U.park(false, parkTime);
                w.parker = null;
                U.putObject(wt, PARKBLOCKER, null);
                if (ctl != currentCtl)
                    break;
                if (deadline - System.nanoTime() <= 0L &&
                    U.compareAndSwapLong(this, CTL, currentCtl, prevCtl)) {
                    w.eventCount = (w.eventCount + E_SEQ) | E_MASK;
                    w.hint = -1;
                    w.qlock = -1;   // shrink
                    break;
                }
            }
        }
    }
,
>
, <(startLine=45 endLine=52 srcPath=/root/NewExperiment/elasticsearchFilter/00106/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/optimize/RestOptimizeAction.java)
    @Inject public RestOptimizeAction(Settings settings, Client client, RestController controller) {
        super(settings, client);
        controller.registerHandler(POST, "/_optimize", this);
        controller.registerHandler(POST, "/{index}/_optimize", this);

        controller.registerHandler(GET, "/_optimize", this);
        controller.registerHandler(GET, "/{index}/_optimize", this);
    }
,
(startLine=45 endLine=52 srcPath=/root/NewExperiment/elasticsearchFilter/00106/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/refresh/RestRefreshAction.java)
    @Inject public RestRefreshAction(Settings settings, Client client, RestController controller) {
        super(settings, client);
        controller.registerHandler(POST, "/_refresh", this);
        controller.registerHandler(POST, "/{index}/_refresh", this);

        controller.registerHandler(GET, "/_refresh", this);
        controller.registerHandler(GET, "/{index}/_refresh", this);
    }
,
(startLine=45 endLine=52 srcPath=/root/NewExperiment/elasticsearchFilter/00106/modules/elasticsearch/src/main/java/org/elasticsearch/rest/action/admin/indices/flush/RestFlushAction.java)
    @Inject public RestFlushAction(Settings settings, Client client, RestController controller) {
        super(settings, client);
        controller.registerHandler(POST, "/_flush", this);
        controller.registerHandler(POST, "/{index}/_flush", this);

        controller.registerHandler(GET, "/_flush", this);
        controller.registerHandler(GET, "/{index}/_flush", this);
    }
,
>
, <(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/ip/TermsIpOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                long value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalIpTermsFacet.LongEntry entry = new InternalIpTermsFacet.LongEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=196 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/ip/TermsIpOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            long value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalIpTermsFacet.LongEntry entry = new InternalIpTermsFacet.LongEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/ints/TermsIntOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                int value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalIntTermsFacet.IntEntry entry = new InternalIntTermsFacet.IntEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=196 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/ints/TermsIntOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            int value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalIntTermsFacet.IntEntry entry = new InternalIntTermsFacet.IntEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
(startLine=161 endLine=182 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/bytes/TermsByteOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                byte value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalByteTermsFacet.ByteEntry entry = new InternalByteTermsFacet.ByteEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=197 endLine=218 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/bytes/TermsByteOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            byte value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalByteTermsFacet.ByteEntry entry = new InternalByteTermsFacet.ByteEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/floats/TermsFloatOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                float value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalFloatTermsFacet.FloatEntry entry = new InternalFloatTermsFacet.FloatEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=196 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/floats/TermsFloatOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            float value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalFloatTermsFacet.FloatEntry entry = new InternalFloatTermsFacet.FloatEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/longs/TermsLongOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                long value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalLongTermsFacet.LongEntry entry = new InternalLongTermsFacet.LongEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=196 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/longs/TermsLongOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            long value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalLongTermsFacet.LongEntry entry = new InternalLongTermsFacet.LongEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/shorts/TermsShortOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                short value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalShortTermsFacet.ShortEntry entry = new InternalShortTermsFacet.ShortEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=196 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/shorts/TermsShortOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            short value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalShortTermsFacet.ShortEntry entry = new InternalShortTermsFacet.ShortEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
(startLine=160 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/doubles/TermsDoubleOrdinalsFacetCollector.java)
            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                double value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalDoubleTermsFacet.DoubleEntry entry = new InternalDoubleTermsFacet.DoubleEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
,
(startLine=196 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00635/src/main/java/org/elasticsearch/search/facet/terms/doubles/TermsDoubleOrdinalsFacetCollector.java)
        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            double value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalDoubleTermsFacet.DoubleEntry entry = new InternalDoubleTermsFacet.DoubleEntry(value, count);
                    ordered.add(entry);
                }
            }
        }
,
>
, <(startLine=69 endLine=78 srcPath=/root/NewExperiment/elasticsearchFilter/00920/src/main/java/org/elasticsearch/cluster/settings/Validator.java)
        public String validate(String setting, String value) {
            try {
                if (Float.parseFloat(value) < 0.0) {
                    return "the value of the setting " + setting + " must be a non negative float";
                }
            } catch (NumberFormatException ex) {
                return "cannot parse value [" + value + "] as a double";
            }
            return null;
        }
,
(startLine=95 endLine=104 srcPath=/root/NewExperiment/elasticsearchFilter/00920/src/main/java/org/elasticsearch/cluster/settings/Validator.java)
        public String validate(String setting, String value) {
            try {
                if (Double.parseDouble(value) < 0.0) {
                    return "the value of the setting " + setting + " must be a non negative double";
                }
            } catch (NumberFormatException ex) {
                return "cannot parse value [" + value + "] as a double";
            }
            return null;
        }
,
(startLine=109 endLine=118 srcPath=/root/NewExperiment/elasticsearchFilter/00920/src/main/java/org/elasticsearch/cluster/settings/Validator.java)
        public String validate(String setting, String value) {
            try {
                if (Double.parseDouble(value) < 2.0) {
                    return "the value of the setting " + setting + " must be >= 2.0";
                }
            } catch (NumberFormatException ex) {
                return "cannot parse value [" + value + "] as a double";
            }
            return null;
        }
,
(startLine=135 endLine=144 srcPath=/root/NewExperiment/elasticsearchFilter/00920/src/main/java/org/elasticsearch/cluster/settings/Validator.java)
        public String validate(String setting, String value) {
            try {
                if (Integer.parseInt(value) <= 0) {
                    return "the value of the setting " + setting + " must be a positive integer";
                }
            } catch (NumberFormatException ex) {
                return "cannot parse value [" + value + "] as an integer";
            }
            return null;
        }
,
(startLine=149 endLine=158 srcPath=/root/NewExperiment/elasticsearchFilter/00920/src/main/java/org/elasticsearch/cluster/settings/Validator.java)
        public String validate(String setting, String value) {
            try {
                if (Integer.parseInt(value) < 0) {
                    return "the value of the setting " + setting + " must be a non negative integer";
                }
            } catch (NumberFormatException ex) {
                return "cannot parse value [" + value + "] as an integer";
            }
            return null;
        }
,
(startLine=163 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/00920/src/main/java/org/elasticsearch/cluster/settings/Validator.java)
        public String validate(String setting, String value) {
            try {
                if (Integer.parseInt(value) < 2) {
                    return "the value of the setting " + setting + " must be >= 2";
                }
            } catch (NumberFormatException ex) {
                return "cannot parse value [" + value + "] as an integer";
            }
            return null;
        }
,
>
, <(startLine=872 endLine=892 srcPath=/root/NewExperiment/elasticsearchFilter/01711/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsTests.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (double) i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (double)i));
            assertThat(bucket.getDocCount(), equalTo(1l));

            Avg avg = bucket.getAggregations().get("avg_i");
            assertThat(avg, notNullValue());
            assertThat(avg.getValue(), equalTo((double) i));

            Terms subTermsAgg = bucket.getAggregations().get("subTerms");
            assertThat(subTermsAgg, notNullValue());
            assertThat(subTermsAgg.getBuckets().size(), equalTo(2));
            double j = i;
            for (Terms.Bucket subBucket : subTermsAgg.getBuckets()) {
                assertThat(subBucket, notNullValue());
                assertThat(key(subBucket), equalTo(String.valueOf(j)));
                assertThat(subBucket.getDocCount(), equalTo(1l));
                j++;
            }
        }
,
(startLine=868 endLine=888 srcPath=/root/NewExperiment/elasticsearchFilter/01711/core/src/test/java/org/elasticsearch/search/aggregations/bucket/LongTermsTests.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + i));
            assertThat(bucket.getDocCount(), equalTo(1l));

            Avg avg = bucket.getAggregations().get("avg_i");
            assertThat(avg, notNullValue());
            assertThat(avg.getValue(), equalTo((double) i));

            Terms subTermsAgg = bucket.getAggregations().get("subTerms");
            assertThat(subTermsAgg, notNullValue());
            assertThat(subTermsAgg.getBuckets().size(), equalTo(2));
            int j = i;
            for (Terms.Bucket subBucket : subTermsAgg.getBuckets()) {
                assertThat(subBucket, notNullValue());
                assertThat(key(subBucket), equalTo(String.valueOf(j)));
                assertThat(subBucket.getDocCount(), equalTo(1l));
                j++;
            }
        }
,
(startLine=1454 endLine=1474 srcPath=/root/NewExperiment/elasticsearchFilter/01711/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java)
        for (Terms.Bucket bucket : terms.getBuckets()) {
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("val" + i));
            assertThat(bucket.getDocCount(), equalTo(1l));

            ExtendedStats stats = bucket.getAggregations().get("stats");
            assertThat(stats, notNullValue());
            assertThat(stats.getMax(), equalTo((double) i));

            Terms subTermsAgg = bucket.getAggregations().get("subTerms");
            assertThat(subTermsAgg, notNullValue());
            assertThat(subTermsAgg.getBuckets().size(), equalTo(2));
            int j = i;
            for (Terms.Bucket subBucket : subTermsAgg.getBuckets()) {
                assertThat(subBucket, notNullValue());
                assertThat(key(subBucket), equalTo("val" + j));
                assertThat(subBucket.getDocCount(), equalTo(1l));
                j++;
            }
            i++;
        }
,
>
, <(startLine=74 endLine=96 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentilesIT.java)
    private void assertConsistent(double[] pcts, Percentiles percentiles, long minValue, long maxValue, int numberSigDigits) {
        final List<Percentile> percentileList = CollectionUtils.iterableAsArrayList(percentiles);
        assertEquals(pcts.length, percentileList.size());
        for (int i = 0; i < pcts.length; ++i) {
            final Percentile percentile = percentileList.get(i);
            assertThat(percentile.getPercent(), equalTo(pcts[i]));
            double value = percentile.getValue();
            double allowedError = value / Math.pow(10, numberSigDigits);
            assertThat(value, greaterThanOrEqualTo(minValue - allowedError));
            assertThat(value, lessThanOrEqualTo(maxValue + allowedError));

            if (percentile.getPercent() == 0) {
                assertThat(value, closeTo(minValue, allowedError));
            }
            if (percentile.getPercent() == 100) {
                assertThat(value, closeTo(maxValue, allowedError));
            }
        }

        for (int i = 1; i < percentileList.size(); ++i) {
            assertThat(percentileList.get(i).getValue(), greaterThanOrEqualTo(percentileList.get(i - 1).getValue()));
        }
    }
,
(startLine=78 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentileRanksIT.java)
    private void assertConsistent(double[] pcts, PercentileRanks percentiles, long minValue, long maxValue) {
        final List<Percentile> percentileList = CollectionUtils.iterableAsArrayList(percentiles);
        assertEquals(pcts.length, percentileList.size());
        for (int i = 0; i < pcts.length; ++i) {
            final Percentile percentile = percentileList.get(i);
            assertThat(percentile.getValue(), equalTo(pcts[i]));
            assertThat(percentile.getPercent(), greaterThanOrEqualTo(0.0));
            assertThat(percentile.getPercent(), lessThanOrEqualTo(100.0));

            if (percentile.getPercent() == 0) {
                assertThat(percentile.getValue(), lessThanOrEqualTo((double) minValue));
            }
            if (percentile.getPercent() == 100) {
                assertThat(percentile.getValue(), greaterThanOrEqualTo((double) maxValue));
            }
        }

        for (int i = 1; i < percentileList.size(); ++i) {
            assertThat(percentileList.get(i).getValue(), greaterThanOrEqualTo(percentileList.get(i - 1).getValue()));
        }
    }
,
(startLine=75 endLine=97 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentileRanksIT.java)
    private void assertConsistent(double[] pcts, PercentileRanks percentiles, long minValue, long maxValue, int numberSigDigits) {
        final List<Percentile> percentileList = iterableAsArrayList(percentiles);
        assertEquals(pcts.length, percentileList.size());
        for (int i = 0; i < pcts.length; ++i) {
            final Percentile percentile = percentileList.get(i);
            assertThat(percentile.getValue(), equalTo(pcts[i]));
            assertThat(percentile.getPercent(), greaterThanOrEqualTo(0.0));
            assertThat(percentile.getPercent(), lessThanOrEqualTo(100.0));

            if (percentile.getPercent() == 0) {
                double allowedError = minValue / Math.pow(10, numberSigDigits);
                assertThat(percentile.getValue(), lessThanOrEqualTo(minValue + allowedError));
            }
            if (percentile.getPercent() == 100) {
                double allowedError = maxValue / Math.pow(10, numberSigDigits);
                assertThat(percentile.getValue(), greaterThanOrEqualTo(maxValue - allowedError));
            }
        }

        for (int i = 1; i < percentileList.size(); ++i) {
            assertThat(percentileList.get(i).getValue(), greaterThanOrEqualTo(percentileList.get(i - 1).getValue()));
        }
    }
,
(startLine=77 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentilesIT.java)
    private void assertConsistent(double[] pcts, Percentiles percentiles, long minValue, long maxValue) {
        final List<Percentile> percentileList = CollectionUtils.iterableAsArrayList(percentiles);
        assertEquals(pcts.length, percentileList.size());
        for (int i = 0; i < pcts.length; ++i) {
            final Percentile percentile = percentileList.get(i);
            assertThat(percentile.getPercent(), equalTo(pcts[i]));
            double value = percentile.getValue();
            assertThat(value, greaterThanOrEqualTo((double) minValue));
            assertThat(value, lessThanOrEqualTo((double) maxValue));

            if (percentile.getPercent() == 0) {
                assertThat(value, equalTo((double) minValue));
            }
            if (percentile.getPercent() == 100) {
                assertThat(value, equalTo((double) maxValue));
            }
        }

        for (int i = 1; i < percentileList.size(); ++i) {
            assertThat(percentileList.get(i).getValue(), greaterThanOrEqualTo(percentileList.get(i - 1).getValue()));
        }
    }
,
>
, <(startLine=80 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/01838/core/src/main/java/org/elasticsearch/common/lucene/uid/PerThreadIDAndVersionLookup.java)
    public DocIdAndVersion lookup(BytesRef id, Bits liveDocs, LeafReaderContext context) throws IOException {
        if (termsEnum.seekExact(id)) {
            // there may be more than one matching docID, in the case of nested docs, so we want the last one:
            docsEnum = termsEnum.postings(docsEnum, 0);
            int docID = DocIdSetIterator.NO_MORE_DOCS;
            for (int d = docsEnum.nextDoc(); d != DocIdSetIterator.NO_MORE_DOCS; d = docsEnum.nextDoc()) {
                if (liveDocs != null && liveDocs.get(d) == false) {
                    continue;
                }
                docID = d;
            }

            if (docID != DocIdSetIterator.NO_MORE_DOCS) {
                return new DocIdAndVersion(docID, versions.get(docID), context);
            }
        }

        return null;
    }
,
(startLine=246 endLine=261 srcPath=/root/NewExperiment/elasticsearchFilter/01838/core/src/main/java/org/elasticsearch/common/lucene/uid/Versions.java)
                    if (termsEnum.seekExact(id)) {
                        // there may be more than one matching docID, in the
                        // case of nested docs, so we want the last one:
                        docsEnum = termsEnum.postings(docsEnum, 0);
                        int docID = DocIdSetIterator.NO_MORE_DOCS;
                        for (int d = docsEnum.nextDoc(); d != DocIdSetIterator.NO_MORE_DOCS; d = docsEnum.nextDoc()) {
                            if (liveDocs != null && liveDocs.get(d) == false) {
                                continue;
                            }
                            docID = d;
                        }

                        if (docID != DocIdSetIterator.NO_MORE_DOCS) {
                            return dvField.get(docID);
                        }
                    }
,
>
, <(startLine=986 endLine=1003 srcPath=/root/NewExperiment/elasticsearchFilter/02312/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testBadModelParams() {
        try {
            SearchResponse response = client()
                    .prepareSearch("idx").setTypes("type")
                    .addAggregation(
                            histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                    .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                    .subAggregation(metric)
                                    .subAggregation(movingAvg("movavg_counts", "_count")
                                            .window(10)
                                            .modelBuilder(randomModelBuilder(100))
                                            .gapPolicy(gapPolicy))
                    ).execute().actionGet();
        } catch (SearchPhaseExecutionException e) {
            // All good
        }

    }
,
(startLine=1193 endLine=1206 srcPath=/root/NewExperiment/elasticsearchFilter/02312/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
            try {
                client()
                        .prepareSearch("idx").setTypes("type")
                        .addAggregation(
                                histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                        .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                        .subAggregation(metric)
                                        .subAggregation(movingAvg("movavg_counts", "_count")
                                                .window(numBuckets)
                                                .modelBuilder(builder)
                                                .gapPolicy(gapPolicy)
                                                .minimize(true))
                        ).execute().actionGet();
            } catch (SearchPhaseExecutionException e) {
,
>
, <(startLine=37 endLine=52 srcPath=/root/NewExperiment/elasticsearchFilter/01802/test/framework/src/test/java/org/elasticsearch/test/rest/yaml/parser/SkipSectionParserTests.java)
    public void testParseSkipSectionVersionNoFeature() throws Exception {
        parser = YamlXContent.yamlXContent.createParser(
                "version:     \" - 2.1.0\"\n" +
                "reason:      Delete ignores the parent param"
        );

        SkipSectionParser skipSectionParser = new SkipSectionParser();

        SkipSection skipSection = skipSectionParser.parse(new ClientYamlTestSuiteParseContext("api", "suite", parser));

        assertThat(skipSection, notNullValue());
        assertThat(skipSection.getLowerVersion(), equalTo(VersionUtils.getFirstVersion()));
        assertThat(skipSection.getUpperVersion(), equalTo(Version.V_2_1_0));
        assertThat(skipSection.getFeatures().size(), equalTo(0));
        assertThat(skipSection.getReason(), equalTo("Delete ignores the parent param"));
    }
,
(startLine=54 endLine=69 srcPath=/root/NewExperiment/elasticsearchFilter/01802/test/framework/src/test/java/org/elasticsearch/test/rest/yaml/parser/SkipSectionParserTests.java)
    public void testParseSkipSectionAllVersions() throws Exception {
        parser = YamlXContent.yamlXContent.createParser(
            "version:     \" all \"\n" +
            "reason:      Delete ignores the parent param"
        );

        SkipSectionParser skipSectionParser = new SkipSectionParser();

        SkipSection skipSection = skipSectionParser.parse(new ClientYamlTestSuiteParseContext("api", "suite", parser));

        assertThat(skipSection, notNullValue());
        assertThat(skipSection.getLowerVersion(), equalTo(VersionUtils.getFirstVersion()));
        assertThat(skipSection.getUpperVersion(), equalTo(Version.CURRENT));
        assertThat(skipSection.getFeatures().size(), equalTo(0));
        assertThat(skipSection.getReason(), equalTo("Delete ignores the parent param"));
    }
,
>
, <(startLine=168 endLine=176 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchTests.java)
        try {
            client().prepareIndex(INDEX, TYPE, "1").setSource(jsonBuilder()
                    .startObject().startObject(FIELD)
                    .startArray("input").value("sth").endArray()
                    .field("weight", 2.5)
                    .endObject().endObject()
            ).get();
            fail("Indexing with a float weight was successful, but should not be");
        } catch (MapperParsingException e) {
,
(startLine=212 endLine=220 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchTests.java)
        try {
            client().prepareIndex(INDEX, TYPE, "1").setSource(jsonBuilder()
                            .startObject().startObject(FIELD)
                            .startArray("input").value("sth").endArray()
                            .field("weight", "thisIsNotValid")
                            .endObject().endObject()
            ).get();
            fail("Indexing with a non-number representing string as weight was successful, but should not be");
        } catch (MapperParsingException e) {
,
(startLine=230 endLine=238 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchTests.java)
        try {
            client().prepareIndex(INDEX, TYPE, "1").setSource(jsonBuilder()
                            .startObject().startObject(FIELD)
                            .startArray("input").value("testing").endArray()
                            .field("weight", weight)
                            .endObject().endObject()
            ).get();
            fail("Indexing with weight string representing value > Int.MAX_VALUE was successful, but should not be");
        } catch (MapperParsingException e) {
,
>
, <(startLine=204 endLine=221 srcPath=/root/NewExperiment/elasticsearchFilter/00149/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchDfsQueryThenFetchAction.java)
                } else {
                    boolean localAsync = request.operationThreading() == SearchOperationThreading.THREAD_PER_SHARD;
                    for (Map.Entry<SearchShardTarget, ExtTIntArrayList> entry : docIdsToLoad.entrySet()) {
                        final DiscoveryNode node = nodes.get(entry.getKey().nodeId());
                        if (node.id().equals(nodes.localNodeId())) {
                            final FetchSearchRequest fetchSearchRequest = new FetchSearchRequest(queryResults.get(entry.getKey()).id(), entry.getValue());
                            if (localAsync) {
                                threadPool.execute(new Runnable() {
                                    @Override public void run() {
                                        executeFetch(counter, fetchSearchRequest, node);
                                    }
                                });
                            } else {
                                executeFetch(counter, fetchSearchRequest, node);
                            }
                        }
                    }
                }
,
(startLine=119 endLine=136 srcPath=/root/NewExperiment/elasticsearchFilter/00149/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchQueryThenFetchAction.java)
                } else {
                    boolean localAsync = request.operationThreading() == SearchOperationThreading.THREAD_PER_SHARD;
                    for (Map.Entry<SearchShardTarget, ExtTIntArrayList> entry : docIdsToLoad.entrySet()) {
                        final DiscoveryNode node = nodes.get(entry.getKey().nodeId());
                        if (node.id().equals(nodes.localNodeId())) {
                            final FetchSearchRequest fetchSearchRequest = new FetchSearchRequest(queryResults.get(entry.getKey()).id(), entry.getValue());
                            if (localAsync) {
                                threadPool.execute(new Runnable() {
                                    @Override public void run() {
                                        executeFetch(counter, fetchSearchRequest, node);
                                    }
                                });
                            } else {
                                executeFetch(counter, fetchSearchRequest, node);
                            }
                        }
                    }
                }
,
>
, <(startLine=63 endLine=72 srcPath=/root/NewExperiment/elasticsearchFilter/02391/core/src/main/java/org/elasticsearch/common/settings/AddFileKeyStoreCommand.java)
        if (keystore == null) {
            if (options.has(forceOption) == false &&
                terminal.promptYesNo("The elasticsearch keystore does not exist. Do you want to create it?", false) == false) {
                terminal.println("Exiting without creating keystore.");
                return;
            }
            keystore = KeyStoreWrapper.create(new char[0] /* always use empty passphrase for auto created keystore */);
            keystore.save(env.configFile());
            terminal.println("Created elasticsearch keystore in " + env.configFile());
        } else {
,
(startLine=60 endLine=69 srcPath=/root/NewExperiment/elasticsearchFilter/02391/core/src/main/java/org/elasticsearch/common/settings/AddStringKeyStoreCommand.java)
        if (keystore == null) {
            if (options.has(forceOption) == false &&
                terminal.promptYesNo("The elasticsearch keystore does not exist. Do you want to create it?", false) == false) {
                terminal.println("Exiting without creating keystore.");
                return;
            }
            keystore = KeyStoreWrapper.create(new char[0] /* always use empty passphrase for auto created keystore */);
            keystore.save(env.configFile());
            terminal.println("Created elasticsearch keystore in " + env.configFile());
        } else {
,
>
, <(startLine=606 endLine=617 srcPath=/root/NewExperiment/elasticsearchFilter/00153/modules/elasticsearch/src/main/java/org/elasticsearch/util/concurrent/jsr166y/Phaser.java)
    public int awaitAdvance(int phase) {
        if (phase < 0)
            return phase;
        long s = getReconciledState();
        int p = phaseOf(s);
        if (p != phase)
            return p;
        if (unarrivedOf(s) == 0 && parent != null)
            parent.awaitAdvance(phase);
        // Fall here even if parent waited, to reconcile and help release
        return untimedWait(phase);
    }
,
(startLine=635 endLine=645 srcPath=/root/NewExperiment/elasticsearchFilter/00153/modules/elasticsearch/src/main/java/org/elasticsearch/util/concurrent/jsr166y/Phaser.java)
            throws InterruptedException {
        if (phase < 0)
            return phase;
        long s = getReconciledState();
        int p = phaseOf(s);
        if (p != phase)
            return p;
        if (unarrivedOf(s) == 0 && parent != null)
            parent.awaitAdvanceInterruptibly(phase);
        return interruptibleWait(phase);
    }
,
(startLine=670 endLine=680 srcPath=/root/NewExperiment/elasticsearchFilter/00153/modules/elasticsearch/src/main/java/org/elasticsearch/util/concurrent/jsr166y/Phaser.java)
            throws InterruptedException, TimeoutException {
        if (phase < 0)
            return phase;
        long s = getReconciledState();
        int p = phaseOf(s);
        if (p != phase)
            return p;
        if (unarrivedOf(s) == 0 && parent != null)
            parent.awaitAdvanceInterruptibly(phase, timeout, unit);
        return timedWait(phase, unit.toNanos(timeout));
    }
,
>
, <(startLine=642 endLine=687 srcPath=/root/NewExperiment/elasticsearchFilter/00091/modules/elasticsearch/src/main/java/org/elasticsearch/util/concurrent/highscalelib/NonBlockingHashtable.java)
    private static final Object get_impl(final NonBlockingHashtable topmap, final Object[] kvs, final Object key, final int fullhash) {
        final int len = len(kvs); // Count of key/value pairs, reads kvs.length
        final CHM chm = chm(kvs); // The CHM, for a volatile read below; reads slot 0 of kvs
        final int[] hashes = hashes(kvs); // The memoized hashes; reads slot 1 of kvs

        int idx = fullhash & (len - 1); // First key hash

        // Main spin/reprobe loop, looking for a Key hit
        int reprobe_cnt = 0;
        while (true) {
            // Probe table.  Each read of 'val' probably misses in cache in a big
            // table; hopefully the read of 'key' then hits in cache.
            final Object K = key(kvs, idx); // Get key   before volatile read, could be null
            final Object V = val(kvs, idx); // Get value before volatile read, could be null or Tombstone or Prime
            if (K == null) return null;   // A clear miss

            // We need a volatile-read here to preserve happens-before semantics on
            // newly inserted Keys.  If the Key body was written just before inserting
            // into the table a Key-compare here might read the uninitalized Key body.
            // Annoyingly this means we have to volatile-read before EACH key compare.
            // .
            // We also need a volatile-read between reading a newly inserted Value
            // and returning the Value (so the user might end up reading the stale
            // Value contents).  Same problem as with keys - and the one volatile
            // read covers both.
            final Object[] newkvs = chm._newkvs; // VOLATILE READ before key compare

            // Key-compare
            if (keyeq(K, key, hashes, idx, fullhash)) {
                // Key hit!  Check for no table-copy-in-progress
                if (!(V instanceof Prime)) // No copy?
                    return (V == TOMBSTONE) ? null : V; // Return the value
                // Key hit - but slot is (possibly partially) copied to the new table.
                // Finish the copy & retry in the new table.
                return get_impl(topmap, chm.copy_slot_and_check(topmap, kvs, idx, key), key, fullhash); // Retry in the new table
            }
            // get and put must have the same key lookup logic!  But only 'put'
            // needs to force a table-resize for a too-long key-reprobe sequence.
            // Check for too-many-reprobes on get - and flip to the new table.
            if (++reprobe_cnt >= reprobe_limit(len) || // too many probes
                    key == TOMBSTONE) // found a TOMBSTONE key, means no more keys in this table
                return newkvs == null ? null : get_impl(topmap, topmap.help_copy(newkvs), key, fullhash); // Retry in the new table

            idx = (idx + 1) & (len - 1);    // Reprobe by 1!  (could now prefetch)
        }
    }
,
(startLine=614 endLine=658 srcPath=/root/NewExperiment/elasticsearchFilter/00091/modules/elasticsearch/src/main/java/org/elasticsearch/util/concurrent/highscalelib/NonBlockingIdentityHashMap.java)
    private static final Object get_impl(final NonBlockingIdentityHashMap topmap, final Object[] kvs, final Object key, final int fullhash) {
        final int len = len(kvs); // Count of key/value pairs, reads kvs.length
        final CHM chm = chm(kvs); // The CHM, for a volatile read below; reads slot 0 of kvs

        int idx = fullhash & (len - 1); // First key hash

        // Main spin/reprobe loop, looking for a Key hit
        int reprobe_cnt = 0;
        while (true) {
            // Probe table.  Each read of 'val' probably misses in cache in a big
            // table; hopefully the read of 'key' then hits in cache.
            final Object K = key(kvs, idx); // Get key   before volatile read, could be null
            final Object V = val(kvs, idx); // Get value before volatile read, could be null or Tombstone or Prime
            if (K == null) return null;   // A clear miss

            // We need a volatile-read here to preserve happens-before semantics on
            // newly inserted Keys.  If the Key body was written just before inserting
            // into the table a Key-compare here might read the uninitalized Key body.
            // Annoyingly this means we have to volatile-read before EACH key compare.
            // .
            // We also need a volatile-read between reading a newly inserted Value
            // and returning the Value (so the user might end up reading the stale
            // Value contents).  Same problem as with keys - and the one volatile
            // read covers both.
            final Object[] newkvs = chm._newkvs; // VOLATILE READ before key compare

            // Key-compare
            if (K == key) {
                // Key hit!  Check for no table-copy-in-progress
                if (!(V instanceof Prime)) // No copy?
                    return (V == TOMBSTONE) ? null : V; // Return the value
                // Key hit - but slot is (possibly partially) copied to the new table.
                // Finish the copy & retry in the new table.
                return get_impl(topmap, chm.copy_slot_and_check(topmap, kvs, idx, key), key, fullhash); // Retry in the new table
            }
            // get and put must have the same key lookup logic!  But only 'put'
            // needs to force a table-resize for a too-long key-reprobe sequence.
            // Check for too-many-reprobes on get - and flip to the new table.
            if (++reprobe_cnt >= reprobe_limit(len) || // too many probes
                    key == TOMBSTONE) // found a TOMBSTONE key, means no more keys in this table
                return newkvs == null ? null : get_impl(topmap, topmap.help_copy(newkvs), key, fullhash); // Retry in the new table

            idx = (idx + 1) & (len - 1);    // Reprobe by 1!  (could now prefetch)
        }
    }
,
(startLine=641 endLine=686 srcPath=/root/NewExperiment/elasticsearchFilter/00091/modules/elasticsearch/src/main/java/org/elasticsearch/util/concurrent/highscalelib/NonBlockingHashMap.java)
    private static final Object get_impl(final NonBlockingHashMap topmap, final Object[] kvs, final Object key, final int fullhash) {
        final int len = len(kvs); // Count of key/value pairs, reads kvs.length
        final CHM chm = chm(kvs); // The CHM, for a volatile read below; reads slot 0 of kvs
        final int[] hashes = hashes(kvs); // The memoized hashes; reads slot 1 of kvs

        int idx = fullhash & (len - 1); // First key hash

        // Main spin/reprobe loop, looking for a Key hit
        int reprobe_cnt = 0;
        while (true) {
            // Probe table.  Each read of 'val' probably misses in cache in a big
            // table; hopefully the read of 'key' then hits in cache.
            final Object K = key(kvs, idx); // Get key   before volatile read, could be null
            final Object V = val(kvs, idx); // Get value before volatile read, could be null or Tombstone or Prime
            if (K == null) return null;   // A clear miss

            // We need a volatile-read here to preserve happens-before semantics on
            // newly inserted Keys.  If the Key body was written just before inserting
            // into the table a Key-compare here might read the uninitalized Key body.
            // Annoyingly this means we have to volatile-read before EACH key compare.
            // .
            // We also need a volatile-read between reading a newly inserted Value
            // and returning the Value (so the user might end up reading the stale
            // Value contents).  Same problem as with keys - and the one volatile
            // read covers both.
            final Object[] newkvs = chm._newkvs; // VOLATILE READ before key compare

            // Key-compare
            if (keyeq(K, key, hashes, idx, fullhash)) {
                // Key hit!  Check for no table-copy-in-progress
                if (!(V instanceof Prime)) // No copy?
                    return (V == TOMBSTONE) ? null : V; // Return the value
                // Key hit - but slot is (possibly partially) copied to the new table.
                // Finish the copy & retry in the new table.
                return get_impl(topmap, chm.copy_slot_and_check(topmap, kvs, idx, key), key, fullhash); // Retry in the new table
            }
            // get and put must have the same key lookup logic!  But only 'put'
            // needs to force a table-resize for a too-long key-reprobe sequence.
            // Check for too-many-reprobes on get - and flip to the new table.
            if (++reprobe_cnt >= reprobe_limit(len) || // too many probes
                    key == TOMBSTONE) // found a TOMBSTONE key, means no more keys in this table
                return newkvs == null ? null : get_impl(topmap, topmap.help_copy(newkvs), key, fullhash); // Retry in the new table

            idx = (idx + 1) & (len - 1);    // Reprobe by 1!  (could now prefetch)
        }
    }
,
>
, <(startLine=147 endLine=159 srcPath=/root/NewExperiment/elasticsearchFilter/01559/src/test/java/org/elasticsearch/common/compress/CompressedStreamTests.java)
            for (int j = 0; j < numLongs; j++) {
                if (r.nextInt(10) == 0) {
                    theValue = r.nextLong();
                }
                bos.write((byte) (theValue >>> 56));
                bos.write((byte) (theValue >>> 48));
                bos.write((byte) (theValue >>> 40));
                bos.write((byte) (theValue >>> 32));
                bos.write((byte) (theValue >>> 24));
                bos.write((byte) (theValue >>> 16));
                bos.write((byte) (theValue >>> 8));
                bos.write((byte) theValue);
            }
,
(startLine=181 endLine=193 srcPath=/root/NewExperiment/elasticsearchFilter/01559/src/test/java/org/elasticsearch/common/compress/CompressedStreamTests.java)
                            for (int j = 0; j < numLongs; j++) {
                                if (r.nextInt(10) == 0) {
                                    theValue = r.nextLong();
                                }
                                bos.write((byte) (theValue >>> 56));
                                bos.write((byte) (theValue >>> 48));
                                bos.write((byte) (theValue >>> 40));
                                bos.write((byte) (theValue >>> 32));
                                bos.write((byte) (theValue >>> 24));
                                bos.write((byte) (theValue >>> 16));
                                bos.write((byte) (theValue >>> 8));
                                bos.write((byte) theValue);
                            }
,
(startLine=315 endLine=328 srcPath=/root/NewExperiment/elasticsearchFilter/01559/src/test/java/org/elasticsearch/common/compress/CompressedStreamTests.java)
    private void addLong(Random r, long prev, ByteArrayOutputStream bos) {
        long theValue = prev;
        if (r.nextInt(10) != 0) {
            theValue = r.nextLong();
        }
        bos.write((byte) (theValue >>> 56));
        bos.write((byte) (theValue >>> 48));
        bos.write((byte) (theValue >>> 40));
        bos.write((byte) (theValue >>> 32));
        bos.write((byte) (theValue >>> 24));
        bos.write((byte) (theValue >>> 16));
        bos.write((byte) (theValue >>> 8));
        bos.write((byte) theValue);
    }
,
>
, <(startLine=120 endLine=147 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/hdr/AbstractInternalHDRPercentiles.java)
    public XContentBuilder doXContentBody(XContentBuilder builder, Params params) throws IOException {
        if (keyed) {
            builder.startObject(CommonFields.VALUES.getPreferredName());
            for(int i = 0; i < keys.length; ++i) {
                String key = String.valueOf(keys[i]);
                double value = value(keys[i]);
                builder.field(key, value);
                if (format != DocValueFormat.RAW) {
                    builder.field(key + "_as_string", format.format(value));
                }
            }
            builder.endObject();
        } else {
            builder.startArray(CommonFields.VALUES.getPreferredName());
            for (int i = 0; i < keys.length; i++) {
                double value = value(keys[i]);
                builder.startObject();
                builder.field(CommonFields.KEY.getPreferredName(), keys[i]);
                builder.field(CommonFields.VALUE.getPreferredName(), value);
                if (format != DocValueFormat.RAW) {
                    builder.field(CommonFields.VALUE_AS_STRING.getPreferredName(), format.format(value));
                }
                builder.endObject();
            }
            builder.endArray();
        }
        return builder;
    }
,
(startLine=103 endLine=130 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/AbstractInternalTDigestPercentiles.java)
    public XContentBuilder doXContentBody(XContentBuilder builder, Params params) throws IOException {
        if (keyed) {
            builder.startObject(CommonFields.VALUES.getPreferredName());
            for(int i = 0; i < keys.length; ++i) {
                String key = String.valueOf(keys[i]);
                double value = value(keys[i]);
                builder.field(key, value);
                if (format != DocValueFormat.RAW) {
                    builder.field(key + "_as_string", format.format(value));
                }
            }
            builder.endObject();
        } else {
            builder.startArray(CommonFields.VALUES.getPreferredName());
            for (int i = 0; i < keys.length; i++) {
                double value = value(keys[i]);
                builder.startObject();
                builder.field(CommonFields.KEY.getPreferredName(), keys[i]);
                builder.field(CommonFields.VALUE.getPreferredName(), value);
                if (format != DocValueFormat.RAW) {
                    builder.field(CommonFields.VALUE_AS_STRING.getPreferredName(), format.format(value));
                }
                builder.endObject();
            }
            builder.endArray();
        }
        return builder;
    }
,
>
, <(startLine=586 endLine=597 srcPath=/root/NewExperiment/elasticsearchFilter/00479/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    @Test public void testRangeQueryBuilder() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        Query parsedQuery = queryParser.parse(rangeQuery("age").from(23).to(54).includeLower(true).includeUpper(false)).query();
        // since age is automatically registered in data, we encode it as numeric
        assertThat(parsedQuery, instanceOf(NumericRangeQuery.class));
        NumericRangeQuery rangeQuery = (NumericRangeQuery) parsedQuery;
        assertThat(rangeQuery.getField(), equalTo("age"));
        assertThat(rangeQuery.getMin().intValue(), equalTo(23));
        assertThat(rangeQuery.getMax().intValue(), equalTo(54));
        assertThat(rangeQuery.includesMin(), equalTo(true));
        assertThat(rangeQuery.includesMax(), equalTo(false));
    }
,
(startLine=599 endLine=611 srcPath=/root/NewExperiment/elasticsearchFilter/00479/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    @Test public void testRangeQuery() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/range.json");
        Query parsedQuery = queryParser.parse(query).query();
        // since age is automatically registered in data, we encode it as numeric
        assertThat(parsedQuery, instanceOf(NumericRangeQuery.class));
        NumericRangeQuery rangeQuery = (NumericRangeQuery) parsedQuery;
        assertThat(rangeQuery.getField(), equalTo("age"));
        assertThat(rangeQuery.getMin().intValue(), equalTo(23));
        assertThat(rangeQuery.getMax().intValue(), equalTo(54));
        assertThat(rangeQuery.includesMin(), equalTo(true));
        assertThat(rangeQuery.includesMax(), equalTo(false));
    }
,
(startLine=613 endLine=625 srcPath=/root/NewExperiment/elasticsearchFilter/00479/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    @Test public void testRange2Query() throws IOException {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/range2.json");
        Query parsedQuery = queryParser.parse(query).query();
        // since age is automatically registered in data, we encode it as numeric
        assertThat(parsedQuery, instanceOf(NumericRangeQuery.class));
        NumericRangeQuery rangeQuery = (NumericRangeQuery) parsedQuery;
        assertThat(rangeQuery.getField(), equalTo("age"));
        assertThat(rangeQuery.getMin().intValue(), equalTo(23));
        assertThat(rangeQuery.getMax().intValue(), equalTo(54));
        assertThat(rangeQuery.includesMin(), equalTo(true));
        assertThat(rangeQuery.includesMax(), equalTo(false));
    }
,
>
, <(startLine=61 endLine=112 srcPath=/root/NewExperiment/elasticsearchFilter/01926/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ThrottlingAllocationTests.java)
    public void testPrimaryRecoveryThrottling() {

        TestGatewayAllocator gatewayAllocator = new TestGatewayAllocator();
        AllocationService strategy = createAllocationService(Settings.builder()
                .put("cluster.routing.allocation.node_concurrent_recoveries", 3)
                .put("cluster.routing.allocation.node_initial_primaries_recoveries", 3)
                .build(), gatewayAllocator);

        logger.info("Building initial routing table");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder("test").settings(settings(Version.CURRENT)).numberOfShards(10).numberOfReplicas(1))
                .build();

        ClusterState clusterState = createRecoveryStateAndInitalizeAllocations(metaData, gatewayAllocator);

        logger.info("start one node, do reroute, only 3 should initialize");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder().add(newNode("node1"))).build();
        clusterState = strategy.reroute(clusterState, "reroute");

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(17));

        logger.info("start initializing, another 3 should initialize");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(14));

        logger.info("start initializing, another 3 should initialize");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(6));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(11));

        logger.info("start initializing, another 1 should initialize");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(9));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(1));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(10));

        logger.info("start initializing, all primaries should be started");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(10));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(10));
    }
,
(startLine=114 endLine=173 srcPath=/root/NewExperiment/elasticsearchFilter/01926/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ThrottlingAllocationTests.java)
    public void testReplicaAndPrimaryRecoveryThrottling() {
        TestGatewayAllocator gatewayAllocator = new TestGatewayAllocator();
        AllocationService strategy = createAllocationService(Settings.builder()
                .put("cluster.routing.allocation.node_concurrent_recoveries", 3)
                .put("cluster.routing.allocation.concurrent_source_recoveries", 3)
                .put("cluster.routing.allocation.node_initial_primaries_recoveries", 3)
                .build(),
            gatewayAllocator);

        logger.info("Building initial routing table");

        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder("test").settings(settings(Version.CURRENT)).numberOfShards(5).numberOfReplicas(1))
                .build();

        ClusterState clusterState = createRecoveryStateAndInitalizeAllocations(metaData, gatewayAllocator);

        logger.info("with one node, do reroute, only 3 should initialize");
        clusterState = strategy.reroute(clusterState, "reroute");

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(7));

        logger.info("start initializing, another 2 should initialize");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(2));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(5));

        logger.info("start initializing, all primaries should be started");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(5));

        logger.info("start another node, replicas should start being allocated");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes()).add(newNode("node2"))).build();
        clusterState = strategy.reroute(clusterState, "reroute");

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(5));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(3));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(2));

        logger.info("start initializing replicas");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(8));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(2));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(0));

        logger.info("start initializing replicas, all should be started");
        clusterState = strategy.applyStartedShards(clusterState, clusterState.routingTable().shardsWithState(INITIALIZING));

        assertThat(clusterState.routingTable().shardsWithState(STARTED).size(), equalTo(10));
        assertThat(clusterState.routingTable().shardsWithState(INITIALIZING).size(), equalTo(0));
        assertThat(clusterState.routingTable().shardsWithState(UNASSIGNED).size(), equalTo(0));
    }
,
>
, <(startLine=424 endLine=438 srcPath=/root/NewExperiment/elasticsearchFilter/01782/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearch2xIT.java)
    public void testThatDisablingPositionIncrementsWorkForStopwords() throws Exception {
        // analyzer which removes stopwords... so may not be the simple one
        completionMappingBuilder.searchAnalyzer("classic").indexAnalyzer("classic").preservePositionIncrements(false);
        createIndexAndMapping(completionMappingBuilder);

        client().prepareIndex(INDEX, TYPE, "1").setSource(jsonBuilder()
            .startObject().startObject(FIELD)
            .startArray("input").value("The Beatles").endArray()
            .endObject().endObject()
        ).get();

        refresh();

        assertSuggestions("b", "The Beatles");
    }
,
(startLine=539 endLine=553 srcPath=/root/NewExperiment/elasticsearchFilter/01782/core/src/test/java/org/elasticsearch/search/suggest/CompletionSuggestSearchIT.java)
    public void testThatDisablingPositionIncrementsWorkForStopwords() throws Exception {
        // analyzer which removes stopwords... so may not be the simple one
        completionMappingBuilder.searchAnalyzer("classic").indexAnalyzer("classic").preservePositionIncrements(false);
        createIndexAndMapping(completionMappingBuilder);

        client().prepareIndex(INDEX, TYPE, "1").setSource(jsonBuilder()
                .startObject().startObject(FIELD)
                .startArray("input").value("The Beatles").endArray()
                .endObject().endObject()
        ).get();

        refresh();

        assertSuggestions("b", "The Beatles");
    }
,
>
, <(startLine=354 endLine=369 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/percolator/MultiPercolatorIT.java)
    void initNestedIndexAndPercolation() throws IOException {
        XContentBuilder mapping = XContentFactory.jsonBuilder();
        mapping.startObject().startObject("properties").startObject("companyname").field("type", "string").endObject()
                .startObject("employee").field("type", "nested").startObject("properties")
                .startObject("name").field("type", "string").endObject().endObject().endObject().endObject()
                .endObject();

        assertAcked(client().admin().indices().prepareCreate("nestedindex").addMapping("company", mapping));
        ensureGreen("nestedindex");

        client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode(ScoreMode.Avg)).endObject()).get();

        refresh();

    }
,
(startLine=1779 endLine=1794 srcPath=/root/NewExperiment/elasticsearchFilter/01748/core/src/test/java/org/elasticsearch/percolator/PercolatorIT.java)
    void initNestedIndexAndPercolation() throws IOException {
        XContentBuilder mapping = XContentFactory.jsonBuilder();
        mapping.startObject().startObject("properties").startObject("companyname").field("type", "string").endObject()
                .startObject("employee").field("type", "nested").startObject("properties")
                .startObject("name").field("type", "string").endObject().endObject().endObject().endObject()
                .endObject();

        assertAcked(client().admin().indices().prepareCreate("nestedindex").addMapping("company", mapping));
        ensureGreen("nestedindex");

        client().prepareIndex("nestedindex", PercolatorService.TYPE_NAME, "Q").setSource(jsonBuilder().startObject()
                .field("query", QueryBuilders.nestedQuery("employee", QueryBuilders.matchQuery("employee.name", "virginia potts").operator(Operator.AND)).scoreMode(ScoreMode.Avg)).endObject()).get();

        refresh();

    }
,
>
, <(startLine=81 endLine=93 srcPath=/root/NewExperiment/elasticsearchFilter/01994/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessLexer.java)
  static {
    tokenNames = new String[_SYMBOLIC_NAMES.length];
    for (int i = 0; i < tokenNames.length; i++) {
      tokenNames[i] = VOCABULARY.getLiteralName(i);
      if (tokenNames[i] == null) {
        tokenNames[i] = VOCABULARY.getSymbolicName(i);
      }

      if (tokenNames[i] == null) {
        tokenNames[i] = "<INVALID>";
      }
    }
  }
,
(startLine=80 endLine=92 srcPath=/root/NewExperiment/elasticsearchFilter/01994/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  static {
    tokenNames = new String[_SYMBOLIC_NAMES.length];
    for (int i = 0; i < tokenNames.length; i++) {
      tokenNames[i] = VOCABULARY.getLiteralName(i);
      if (tokenNames[i] == null) {
        tokenNames[i] = VOCABULARY.getSymbolicName(i);
      }

      if (tokenNames[i] == null) {
        tokenNames[i] = "<INVALID>";
      }
    }
  }
,
>
, <(startLine=65 endLine=102 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsBinaryIT.java)
    public void testAggregationsBinary() throws Exception {
        TermsBuilder termsBuilder = AggregationBuilders.terms("terms").field(STRING_FIELD_NAME);
        TermsBuilder subTerm = AggregationBuilders.terms("subterms").field(INT_FIELD_NAME);

        // Create an XContentBuilder from sub aggregation
        XContentBuilder subTermContentBuilder = JsonXContent.contentBuilder().startObject();
        subTerm.toXContent(subTermContentBuilder, ToXContent.EMPTY_PARAMS);
        subTermContentBuilder.endObject();

        // Add sub aggregation as a XContentBuilder (binary_aggregation)
        termsBuilder.subAggregation(subTermContentBuilder);

        SearchResponse response = client().prepareSearch("idx").setTypes("type").addAggregation(termsBuilder).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(5));

        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("val" + i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsString(), equalTo("val" + i));
            assertThat(bucket.getDocCount(), equalTo(1l));
            Aggregations subAggs = bucket.getAggregations();
            assertThat(subAggs, notNullValue());
            assertThat(subAggs.asList().size(), equalTo(1));
            Terms subTerms = subAggs.get("subterms");
            assertThat(subTerms, notNullValue());
            List<Bucket> subTermsBuckets = subTerms.getBuckets();
            assertThat(subTermsBuckets, notNullValue());
            assertThat(subTermsBuckets.size(), equalTo(1));
            assertThat(((Number) subTermsBuckets.get(0).getKey()).intValue(), equalTo(i));
            assertThat(subTermsBuckets.get(0).getDocCount(), equalTo(1l));
        }
    }
,
(startLine=105 endLine=144 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/AggregationsBinaryIT.java)
    public void testAggregationsBinarySameContentType() throws Exception {
        TermsBuilder termsBuilder = AggregationBuilders.terms("terms").field(STRING_FIELD_NAME);
        TermsBuilder subTerm = AggregationBuilders.terms("subterms").field(INT_FIELD_NAME);

        // Create an XContentBuilder from sub aggregation

        XContentBuilder subTermContentBuilder = XContentFactory.contentBuilder(Requests.CONTENT_TYPE);
        subTermContentBuilder.startObject();
        subTerm.toXContent(subTermContentBuilder, ToXContent.EMPTY_PARAMS);
        subTermContentBuilder.endObject();

        // Add sub aggregation as a XContentBuilder (binary_aggregation)
        termsBuilder.subAggregation(subTermContentBuilder);

        SearchResponse response = client().prepareSearch("idx").setTypes("type").addAggregation(termsBuilder).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(5));

        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("val" + i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsString(), equalTo("val" + i));
            assertThat(bucket.getDocCount(), equalTo(1l));
            Aggregations subAggs = bucket.getAggregations();
            assertThat(subAggs, notNullValue());
            assertThat(subAggs.asList().size(), equalTo(1));
            Terms subTerms = subAggs.get("subterms");
            assertThat(subTerms, notNullValue());
            List<Bucket> subTermsBuckets = subTerms.getBuckets();
            assertThat(subTermsBuckets, notNullValue());
            assertThat(subTermsBuckets.size(), equalTo(1));
            assertThat(((Number) subTermsBuckets.get(0).getKey()).intValue(), equalTo(i));
            assertThat(subTermsBuckets.get(0).getDocCount(), equalTo(1l));
        }
    }
,
>
, <(startLine=398 endLine=441 srcPath=/root/NewExperiment/elasticsearchFilter/01769/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramIT.java)
    public void testSingleValuedFieldWithSubAggregationInherited() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(dateHistogram("histo").field("date").interval(DateHistogramInterval.MONTH)
                        .subAggregation(max("max")))
                .execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat(buckets.size(), equalTo(3));

        DateTime key = new DateTime(2012, 1, 1, 0, 0, DateTimeZone.UTC);
        Histogram.Bucket bucket = buckets.get(0);
        assertThat(bucket, notNullValue());
        assertThat(bucket.getKeyAsString(), equalTo(getBucketKeyAsString(key)));
        assertThat(((DateTime) bucket.getKey()), equalTo(key));
        assertThat(bucket.getDocCount(), equalTo(1l));
        Max max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo((double) new DateTime(2012, 1, 2, 0, 0, DateTimeZone.UTC).getMillis()));

        key = new DateTime(2012, 2, 1, 0, 0, DateTimeZone.UTC);
        bucket = buckets.get(1);
        assertThat(bucket, notNullValue());
        assertThat(bucket.getKeyAsString(), equalTo(getBucketKeyAsString(key)));
        assertThat(((DateTime) bucket.getKey()), equalTo(key));
        assertThat(bucket.getDocCount(), equalTo(2l));
        max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo((double) new DateTime(2012, 2, 15, 0, 0, DateTimeZone.UTC).getMillis()));

        key = new DateTime(2012, 3, 1, 0, 0, DateTimeZone.UTC);
        bucket = buckets.get(2);
        assertThat(bucket, notNullValue());
        assertThat(bucket.getKeyAsString(), equalTo(getBucketKeyAsString(key)));
        assertThat(((DateTime) bucket.getKey()), equalTo(key));
        assertThat(bucket.getDocCount(), equalTo(3l));
        max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo((double) new DateTime(2012, 3, 23, 0, 0, DateTimeZone.UTC).getMillis()));
    }
,
(startLine=822 endLine=865 srcPath=/root/NewExperiment/elasticsearchFilter/01769/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramIT.java)
    public void testScriptSingleValueWithSubAggregatorInherited() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(dateHistogram("histo")
                        .script(new Script("date", ScriptType.INLINE, ExtractFieldScriptEngine.NAME, null)).interval(DateHistogramInterval.MONTH)
                        .subAggregation(max("max"))).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat(buckets.size(), equalTo(3));

        DateTime key = new DateTime(2012, 1, 1, 0, 0, DateTimeZone.UTC);
        Histogram.Bucket bucket = buckets.get(0);
        assertThat(bucket, notNullValue());
        assertThat(bucket.getKeyAsString(), equalTo(getBucketKeyAsString(key)));
        assertThat(((DateTime) bucket.getKey()), equalTo(key));
        assertThat(bucket.getDocCount(), equalTo(1l));
        Max max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo((double) new DateTime(2012, 1, 2, 0, 0, DateTimeZone.UTC).getMillis()));

        key = new DateTime(2012, 2, 1, 0, 0, DateTimeZone.UTC);
        bucket = buckets.get(1);
        assertThat(bucket, notNullValue());
        assertThat(bucket.getKeyAsString(), equalTo(getBucketKeyAsString(key)));
        assertThat(((DateTime) bucket.getKey()), equalTo(key));
        assertThat(bucket.getDocCount(), equalTo(2l));
        max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo((double) new DateTime(2012, 2, 15, 0, 0, DateTimeZone.UTC).getMillis()));

        key = new DateTime(2012, 3, 1, 0, 0, DateTimeZone.UTC);
        bucket = buckets.get(2);
        assertThat(bucket, notNullValue());
        assertThat(bucket.getKeyAsString(), equalTo(getBucketKeyAsString(key)));
        assertThat(((DateTime) bucket.getKey()), equalTo(key));
        assertThat(bucket.getDocCount(), equalTo(3l));
        max = bucket.getAggregations().get("max");
        assertThat(max, notNullValue());
        assertThat(max.getValue(), equalTo((double) new DateTime(2012, 3, 23, 0, 0, DateTimeZone.UTC).getMillis()));
    }
,
>
, <(startLine=207 endLine=221 srcPath=/root/NewExperiment/elasticsearchFilter/02265/core/src/test/java/org/elasticsearch/search/suggest/completion/GeoContextMappingTests.java)
    public void testParsingQueryContextBasic() throws Exception {
        XContentBuilder builder = jsonBuilder().value("ezs42e44yx96");
        XContentParser parser = createParser(JsonXContent.jsonXContent, builder.bytes());
        GeoContextMapping mapping = ContextBuilder.geo("geo").build();
        List<ContextMapping.InternalQueryContext> internalQueryContexts = mapping.parseQueryContext(parser);
        assertThat(internalQueryContexts.size(), equalTo(1 + 8));
        Collection<String> locations = new ArrayList<>();
        locations.add("ezs42e");
        addNeighbors("ezs42e", GeoContextMapping.DEFAULT_PRECISION, locations);
        for (ContextMapping.InternalQueryContext internalQueryContext : internalQueryContexts) {
            assertThat(internalQueryContext.context, isIn(locations));
            assertThat(internalQueryContext.boost, equalTo(1));
            assertThat(internalQueryContext.isPrefix, equalTo(false));
        }
    }
,
(startLine=223 endLine=240 srcPath=/root/NewExperiment/elasticsearchFilter/02265/core/src/test/java/org/elasticsearch/search/suggest/completion/GeoContextMappingTests.java)
    public void testParsingQueryContextGeoPoint() throws Exception {
        XContentBuilder builder = jsonBuilder().startObject()
                .field("lat", 23.654242)
                .field("lon", 90.047153)
                .endObject();
        XContentParser parser = createParser(JsonXContent.jsonXContent, builder.bytes());
        GeoContextMapping mapping = ContextBuilder.geo("geo").build();
        List<ContextMapping.InternalQueryContext> internalQueryContexts = mapping.parseQueryContext(parser);
        assertThat(internalQueryContexts.size(), equalTo(1 + 8));
        Collection<String> locations = new ArrayList<>();
        locations.add("wh0n94");
        addNeighbors("wh0n94", GeoContextMapping.DEFAULT_PRECISION, locations);
        for (ContextMapping.InternalQueryContext internalQueryContext : internalQueryContexts) {
            assertThat(internalQueryContext.context, isIn(locations));
            assertThat(internalQueryContext.boost, equalTo(1));
            assertThat(internalQueryContext.isPrefix, equalTo(false));
        }
    }
,
>
, <(startLine=67 endLine=94 srcPath=/root/NewExperiment/elasticsearchFilter/02179/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java)
    public void testSubmitPrioritizedExecutorWithRunnables() throws Exception {
        ExecutorService executor = EsExecutors.newSinglePrioritizing(getTestName(), EsExecutors.daemonThreadFactory(getTestName()), holder, null);
        List<Integer> results = new ArrayList<>(8);
        CountDownLatch awaitingLatch = new CountDownLatch(1);
        CountDownLatch finishedLatch = new CountDownLatch(8);
        executor.submit(new AwaitingJob(awaitingLatch));
        executor.submit(new Job(7, Priority.LANGUID, results, finishedLatch));
        executor.submit(new Job(5, Priority.LOW, results, finishedLatch));
        executor.submit(new Job(2, Priority.HIGH, results, finishedLatch));
        executor.submit(new Job(6, Priority.LOW, results, finishedLatch)); // will execute after the first LOW (fifo)
        executor.submit(new Job(1, Priority.URGENT, results, finishedLatch));
        executor.submit(new Job(4, Priority.NORMAL, results, finishedLatch));
        executor.submit(new Job(3, Priority.HIGH, results, finishedLatch)); // will execute after the first HIGH (fifo)
        executor.submit(new Job(0, Priority.IMMEDIATE, results, finishedLatch));
        awaitingLatch.countDown();
        finishedLatch.await();

        assertThat(results.size(), equalTo(8));
        assertThat(results.get(0), equalTo(0));
        assertThat(results.get(1), equalTo(1));
        assertThat(results.get(2), equalTo(2));
        assertThat(results.get(3), equalTo(3));
        assertThat(results.get(4), equalTo(4));
        assertThat(results.get(5), equalTo(5));
        assertThat(results.get(6), equalTo(6));
        assertThat(results.get(7), equalTo(7));
        terminate(executor);
    }
,
(startLine=96 endLine=123 srcPath=/root/NewExperiment/elasticsearchFilter/02179/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java)
    public void testExecutePrioritizedExecutorWithRunnables() throws Exception {
        ExecutorService executor = EsExecutors.newSinglePrioritizing(getTestName(), EsExecutors.daemonThreadFactory(getTestName()), holder, null);
        List<Integer> results = new ArrayList<>(8);
        CountDownLatch awaitingLatch = new CountDownLatch(1);
        CountDownLatch finishedLatch = new CountDownLatch(8);
        executor.execute(new AwaitingJob(awaitingLatch));
        executor.execute(new Job(7, Priority.LANGUID, results, finishedLatch));
        executor.execute(new Job(5, Priority.LOW, results, finishedLatch));
        executor.execute(new Job(2, Priority.HIGH, results, finishedLatch));
        executor.execute(new Job(6, Priority.LOW, results, finishedLatch)); // will execute after the first LOW (fifo)
        executor.execute(new Job(1, Priority.URGENT, results, finishedLatch));
        executor.execute(new Job(4, Priority.NORMAL, results, finishedLatch));
        executor.execute(new Job(3, Priority.HIGH, results, finishedLatch)); // will execute after the first HIGH (fifo)
        executor.execute(new Job(0, Priority.IMMEDIATE, results, finishedLatch));
        awaitingLatch.countDown();
        finishedLatch.await();

        assertThat(results.size(), equalTo(8));
        assertThat(results.get(0), equalTo(0));
        assertThat(results.get(1), equalTo(1));
        assertThat(results.get(2), equalTo(2));
        assertThat(results.get(3), equalTo(3));
        assertThat(results.get(4), equalTo(4));
        assertThat(results.get(5), equalTo(5));
        assertThat(results.get(6), equalTo(6));
        assertThat(results.get(7), equalTo(7));
        terminate(executor);
    }
,
(startLine=125 endLine=152 srcPath=/root/NewExperiment/elasticsearchFilter/02179/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java)
    public void testSubmitPrioritizedExecutorWithCallables() throws Exception {
        ExecutorService executor = EsExecutors.newSinglePrioritizing(getTestName(), EsExecutors.daemonThreadFactory(getTestName()), holder, null);
        List<Integer> results = new ArrayList<>(8);
        CountDownLatch awaitingLatch = new CountDownLatch(1);
        CountDownLatch finishedLatch = new CountDownLatch(8);
        executor.submit(new AwaitingJob(awaitingLatch));
        executor.submit(new CallableJob(7, Priority.LANGUID, results, finishedLatch));
        executor.submit(new CallableJob(5, Priority.LOW, results, finishedLatch));
        executor.submit(new CallableJob(2, Priority.HIGH, results, finishedLatch));
        executor.submit(new CallableJob(6, Priority.LOW, results, finishedLatch)); // will execute after the first LOW (fifo)
        executor.submit(new CallableJob(1, Priority.URGENT, results, finishedLatch));
        executor.submit(new CallableJob(4, Priority.NORMAL, results, finishedLatch));
        executor.submit(new CallableJob(3, Priority.HIGH, results, finishedLatch)); // will execute after the first HIGH (fifo)
        executor.submit(new CallableJob(0, Priority.IMMEDIATE, results, finishedLatch));
        awaitingLatch.countDown();
        finishedLatch.await();

        assertThat(results.size(), equalTo(8));
        assertThat(results.get(0), equalTo(0));
        assertThat(results.get(1), equalTo(1));
        assertThat(results.get(2), equalTo(2));
        assertThat(results.get(3), equalTo(3));
        assertThat(results.get(4), equalTo(4));
        assertThat(results.get(5), equalTo(5));
        assertThat(results.get(6), equalTo(6));
        assertThat(results.get(7), equalTo(7));
        terminate(executor);
    }
,
(startLine=154 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/02179/core/src/test/java/org/elasticsearch/common/util/concurrent/PrioritizedExecutorsTests.java)
    public void testSubmitPrioritizedExecutorWithMixed() throws Exception {
        ExecutorService executor = EsExecutors.newSinglePrioritizing(getTestName(), EsExecutors.daemonThreadFactory(getTestName()), holder, null);
        List<Integer> results = new ArrayList<>(8);
        CountDownLatch awaitingLatch = new CountDownLatch(1);
        CountDownLatch finishedLatch = new CountDownLatch(8);
        executor.submit(new AwaitingJob(awaitingLatch));
        executor.submit(new CallableJob(7, Priority.LANGUID, results, finishedLatch));
        executor.submit(new Job(5, Priority.LOW, results, finishedLatch));
        executor.submit(new CallableJob(2, Priority.HIGH, results, finishedLatch));
        executor.submit(new Job(6, Priority.LOW, results, finishedLatch)); // will execute after the first LOW (fifo)
        executor.submit(new CallableJob(1, Priority.URGENT, results, finishedLatch));
        executor.submit(new Job(4, Priority.NORMAL, results, finishedLatch));
        executor.submit(new CallableJob(3, Priority.HIGH, results, finishedLatch)); // will execute after the first HIGH (fifo)
        executor.submit(new Job(0, Priority.IMMEDIATE, results, finishedLatch));
        awaitingLatch.countDown();
        finishedLatch.await();

        assertThat(results.size(), equalTo(8));
        assertThat(results.get(0), equalTo(0));
        assertThat(results.get(1), equalTo(1));
        assertThat(results.get(2), equalTo(2));
        assertThat(results.get(3), equalTo(3));
        assertThat(results.get(4), equalTo(4));
        assertThat(results.get(5), equalTo(5));
        assertThat(results.get(6), equalTo(6));
        assertThat(results.get(7), equalTo(7));
        terminate(executor);
    }
,
>
, <(startLine=216 endLine=225 srcPath=/root/NewExperiment/elasticsearchFilter/01784/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java)
    public void testIllegalSettingsMissingAllRequired() {
        Settings nodeSettings = Settings.EMPTY;
        mock = new GceInstancesServiceMock(nodeSettings);
        try {
            buildDynamicNodes(mock, nodeSettings);
            fail("We expect an IllegalArgumentException for incomplete settings");
        } catch (IllegalArgumentException expected) {
            assertThat(expected.getMessage(), containsString("one or more gce discovery settings are missing."));
        }
    }
,
(startLine=227 endLine=238 srcPath=/root/NewExperiment/elasticsearchFilter/01784/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java)
    public void testIllegalSettingsMissingProject() {
        Settings nodeSettings = Settings.builder()
            .putArray(GceInstancesServiceImpl.ZONE_SETTING.getKey(), "us-central1-a", "us-central1-b")
            .build();
        mock = new GceInstancesServiceMock(nodeSettings);
        try {
            buildDynamicNodes(mock, nodeSettings);
            fail("We expect an IllegalArgumentException for incomplete settings");
        } catch (IllegalArgumentException expected) {
            assertThat(expected.getMessage(), containsString("one or more gce discovery settings are missing."));
        }
    }
,
(startLine=240 endLine=251 srcPath=/root/NewExperiment/elasticsearchFilter/01784/plugins/discovery-gce/src/test/java/org/elasticsearch/discovery/gce/GceDiscoveryTests.java)
    public void testIllegalSettingsMissingZone() {
        Settings nodeSettings = Settings.builder()
            .put(GceInstancesServiceImpl.PROJECT_SETTING.getKey(), projectName)
            .build();
        mock = new GceInstancesServiceMock(nodeSettings);
        try {
            buildDynamicNodes(mock, nodeSettings);
            fail("We expect an IllegalArgumentException for incomplete settings");
        } catch (IllegalArgumentException expected) {
            assertThat(expected.getMessage(), containsString("one or more gce discovery settings are missing."));
        }
    }
,
>
, <(startLine=830 endLine=855 srcPath=/root/NewExperiment/elasticsearchFilter/01099/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java)
                    if (flushNeeded || flush.force()) {
                        flushNeeded = false;
                        try {
                            long translogId = translogIdGenerator.incrementAndGet();
                            translog.newTransientTranslog(translogId);
                            indexWriter.setCommitData(MapBuilder.<String, String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY, Long.toString(translogId)).map());
                            indexWriter.commit();
                            refreshVersioningTable(threadPool.estimatedTimeInMillis());
                            // we need to move transient to current only after we refresh
                            // so items added to current will still be around for realtime get
                            // when tans overrides it
                            translog.makeTransientCurrent();
                        } catch (OutOfMemoryError e) {
                            translog.revertTransient();
                            failEngine(e);
                            throw new FlushFailedEngineException(shardId, e);
                        } catch (IllegalStateException e) {
                            if (e.getMessage().contains("OutOfMemoryError")) {
                                failEngine(e);
                            }
                            throw new FlushFailedEngineException(shardId, e);
                        } catch (Throwable e) {
                            translog.revertTransient();
                            throw new FlushFailedEngineException(shardId, e);
                        }
                    }
,
(startLine=859 endLine=888 srcPath=/root/NewExperiment/elasticsearchFilter/01099/src/main/java/org/elasticsearch/index/engine/robin/RobinEngine.java)
            } else if (flush.type() == Flush.Type.COMMIT) {
                // note, its ok to just commit without cleaning the translog, its perfectly fine to replay a
                // translog on an index that was opened on a committed point in time that is "in the future"
                // of that translog
                rwl.readLock().lock();
                try {
                    ensureOpen();
                    // we allow to *just* commit if there is an ongoing recovery happening...
                    // its ok to use this, only a flush will cause a new translogId, and we are locked here from
                    // other flushes use flushLock
                    try {
                        long translogId = translog.currentId();
                        indexWriter.setCommitData(MapBuilder.<String, String>newMapBuilder().put(Translog.TRANSLOG_ID_KEY, Long.toString(translogId)).map());
                        indexWriter.commit();
                    } catch (OutOfMemoryError e) {
                        translog.revertTransient();
                        failEngine(e);
                        throw new FlushFailedEngineException(shardId, e);
                    } catch (IllegalStateException e) {
                        if (e.getMessage().contains("OutOfMemoryError")) {
                            failEngine(e);
                        }
                        throw new FlushFailedEngineException(shardId, e);
                    } catch (Throwable e) {
                        throw new FlushFailedEngineException(shardId, e);
                    }
                } finally {
                    rwl.readLock().unlock();
                }
            } else {
,
>
, <(startLine=277 endLine=285 srcPath=/root/NewExperiment/elasticsearchFilter/01591/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java)
        while (true) {
            logger.debug("ClusterState: {}", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.routingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }
,
(startLine=333 endLine=341 srcPath=/root/NewExperiment/elasticsearchFilter/01591/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java)
        while (true) {
            logger.debug("ClusterState: {}", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.routingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }
,
(startLine=378 endLine=386 srcPath=/root/NewExperiment/elasticsearchFilter/01591/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java)
        while (true) {
            logger.debug("ClusterState: {}", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.routingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }
,
(startLine=424 endLine=432 srcPath=/root/NewExperiment/elasticsearchFilter/01591/src/test/java/org/elasticsearch/cluster/routing/allocation/AddIncrementallyTests.java)
        while (true) {
            logger.debug("ClusterState: {}", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.routingNodes();
            if (routingTable == prev)
                break;
            prev = routingTable;
        }
,
(startLine=298 endLine=308 srcPath=/root/NewExperiment/elasticsearchFilter/01591/src/test/java/org/elasticsearch/cluster/routing/allocation/NodeVersionAllocationDeciderTests.java)
        for (int i = 0; i < 1000; i++) {   // at most 200 iters - this should be enough for all tests
            logger.trace("RoutingNodes: {}", clusterState.getRoutingNodes().prettyPrint());
            routingTable = service.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
            clusterState = ClusterState.builder(clusterState).routingTable(routingTable).build();
            routingNodes = clusterState.routingNodes();
            if (stable = (routingTable == prev)) {
                break;
            }
            assertRecoveryNodeVersions(routingNodes);
            prev = routingTable;
        }
,
>
, <(startLine=79 endLine=88 srcPath=/root/NewExperiment/elasticsearchFilter/01551/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingTests.java)
    private void testNoConflictWhileMergingAndMappingChanged(XContentBuilder mapping, XContentBuilder mappingUpdate, XContentBuilder expectedMapping) throws IOException {
        IndexService indexService = createIndex("test", ImmutableSettings.settingsBuilder().build(), "type", mapping);
        // simulate like in MetaDataMappingService#putMapping
        DocumentMapper.MergeResult mergeResult = indexService.mapperService().documentMapper("type").merge(indexService.mapperService().parse("type", new CompressedString(mappingUpdate.bytes()), true), DocumentMapper.MergeFlags.mergeFlags().simulate(false));
        // assure we have no conflicts
        assertThat(mergeResult.conflicts().length, equalTo(0));
        // make sure mappings applied
        CompressedString mappingAfterUpdate = indexService.mapperService().documentMapper("type").mappingSource();
        assertThat(mappingAfterUpdate.toString(), equalTo(expectedMapping.string()));
    }
,
(startLine=102 endLine=112 srcPath=/root/NewExperiment/elasticsearchFilter/01551/src/test/java/org/elasticsearch/index/mapper/update/UpdateMappingTests.java)
    protected void testConflictWhileMergingAndMappingUnchanged(XContentBuilder mapping, XContentBuilder mappingUpdate) throws IOException {
        IndexService indexService = createIndex("test", ImmutableSettings.settingsBuilder().build(), "type", mapping);
        CompressedString mappingBeforeUpdate = indexService.mapperService().documentMapper("type").mappingSource();
        // simulate like in MetaDataMappingService#putMapping
        DocumentMapper.MergeResult mergeResult = indexService.mapperService().documentMapper("type").merge(indexService.mapperService().parse("type", new CompressedString(mappingUpdate.bytes()), true), DocumentMapper.MergeFlags.mergeFlags().simulate(true));
        // assure we have conflicts
        assertThat(mergeResult.conflicts().length, equalTo(1));
        // make sure simulate flag actually worked - no mappings applied
        CompressedString mappingAfterUpdate = indexService.mapperService().documentMapper("type").mappingSource();
        assertThat(mappingAfterUpdate, equalTo(mappingBeforeUpdate));
    }
,
>
, <(startLine=261 endLine=267 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (double) i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (double)i));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i));
            assertThat(bucket.getDocCount(), equalTo(1l));
        }
,
(startLine=288 endLine=294 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
        for (int i = 0; i < 20; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (double) i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (double) i));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i));
            assertThat(bucket.getDocCount(), equalTo(1l));
        }
,
(startLine=464 endLine=470 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (i + 1d));
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (i+1d)));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i + 1));
            assertThat(bucket.getDocCount(), equalTo(1l));
        }
,
(startLine=627 endLine=633 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (double) i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (double) i));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i));
            assertThat(bucket.getDocCount(), equalTo(1l));
        }
,
(startLine=790 endLine=796 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (double) i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (double) i));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i));
            assertThat(bucket.getDocCount(), equalTo(1l));
        }
,
(startLine=1217 endLine=1223 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DoubleTermsIT.java)
        for (int i = 0; i < 3; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (double) i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (double)i));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i));
            assertThat(bucket.getDocCount(), equalTo(i == 1 ? 3L : 1L));
        }
,
(startLine=463 endLine=469 srcPath=/root/NewExperiment/elasticsearchFilter/01753/core/src/test/java/org/elasticsearch/search/aggregations/bucket/LongTermsIT.java)
        for (int i = 0; i < 5; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("" + (i + 1d));
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("" + (i+1d)));
            assertThat(bucket.getKeyAsNumber().intValue(), equalTo(i+1));
            assertThat(bucket.getDocCount(), equalTo(1l));
        }
,
>
, <(startLine=301 endLine=307 srcPath=/root/NewExperiment/elasticsearchFilter/00923/src/test/java/org/elasticsearch/test/unit/index/query/SimpleIndexQueryParserTests.java)
    public void testMatchAllEmpty1() throws Exception {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/test/unit/index/query/match_all_empty1.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, equalTo(Queries.newMatchAllQuery()));
        assertThat(parsedQuery, not(sameInstance(Queries.newMatchAllQuery())));
    }
,
(startLine=310 endLine=317 srcPath=/root/NewExperiment/elasticsearchFilter/00923/src/test/java/org/elasticsearch/test/unit/index/query/SimpleIndexQueryParserTests.java)
    public void testMatchAllEmpty2() throws Exception {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/test/unit/index/query/match_all_empty2.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, equalTo(Queries.newMatchAllQuery()));
        assertThat(parsedQuery, not(sameInstance(Queries.newMatchAllQuery())));

    }
,
>
, <(startLine=49 endLine=54 srcPath=/root/NewExperiment/elasticsearchFilter/01749/core/src/test/java/org/elasticsearch/bootstrap/ESPolicyTests.java)
    public void testNullCodeSource() throws Exception {
        assumeTrue("test cannot run with security manager", System.getSecurityManager() == null);
        PermissionCollection noPermissions = new Permissions();
        ESPolicy policy = new ESPolicy(noPermissions);
        assertFalse(policy.implies(new ProtectionDomain(null, noPermissions), new FilePermission("foo", "read")));
    }
,
(startLine=61 endLine=66 srcPath=/root/NewExperiment/elasticsearchFilter/01749/core/src/test/java/org/elasticsearch/bootstrap/ESPolicyTests.java)
    public void testNullLocation() throws Exception {
        assumeTrue("test cannot run with security manager", System.getSecurityManager() == null);
        PermissionCollection noPermissions = new Permissions();
        ESPolicy policy = new ESPolicy(noPermissions);
        assertFalse(policy.implies(new ProtectionDomain(new CodeSource(null, (Certificate[])null), noPermissions), new FilePermission("foo", "read")));
    }
,
>
, <(startLine=1078 endLine=1107 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/DoubleTermsTests.java)
    private void assertMultiSortResponse(double[] expectedKeys, Terms.Order... order) {
        SearchResponse response = client()
                .prepareSearch("sort_idx")
                .setTypes("multi_sort_type")
                .addAggregation(
                        terms("terms").field(SINGLE_VALUED_FIELD_NAME).collectMode(randomFrom(SubAggCollectionMode.values()))
                                .order(Terms.Order.compound(order)).subAggregation(avg("avg_l").field("l"))
                                .subAggregation(sum("sum_d").field("d"))).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(expectedKeys.length));

        int i = 0;
        for (Terms.Bucket bucket : terms.getBuckets()) {
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo(String.valueOf(expectedKeys[i])));
            assertThat(bucket.getDocCount(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("_count")));
            Avg avg = bucket.getAggregations().get("avg_l");
            assertThat(avg, notNullValue());
            assertThat(avg.getValue(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("avg_l")));
            Sum sum = bucket.getAggregations().get("sum_d");
            assertThat(sum, notNullValue());
            assertThat(sum.getValue(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("sum_d")));
            i++;
        }
    }
,
(startLine=1052 endLine=1082 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/LongTermsTests.java)
    private void assertMultiSortResponse(long[] expectedKeys, Terms.Order... order) {
        SearchResponse response = client().prepareSearch("sort_idx").setTypes("multi_sort_type")
                .addAggregation(terms("terms")
                        .field(SINGLE_VALUED_FIELD_NAME)
                        .collectMode(randomFrom(SubAggCollectionMode.values()))
                        .order(Terms.Order.compound(order))
                        .subAggregation(avg("avg_l").field("l"))
                        .subAggregation(sum("sum_d").field("d"))
                ).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(expectedKeys.length));

        int i = 0;
        for (Terms.Bucket bucket : terms.getBuckets()) {
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo(String.valueOf(expectedKeys[i])));
            assertThat(bucket.getDocCount(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("_count")));
            Avg avg = bucket.getAggregations().get("avg_l");
            assertThat(avg, notNullValue());
            assertThat(avg.getValue(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("avg_l")));
            Sum sum = bucket.getAggregations().get("sum_d");
            assertThat(sum, notNullValue());
            assertThat(sum.getValue(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("sum_d")));
            i++;
        }
    }
,
(startLine=1404 endLine=1433 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/lang-groovy/src/test/java/org/elasticsearch/messy/tests/StringTermsTests.java)
    private void assertMultiSortResponse(String[] expectedKeys, Terms.Order... order) {
        SearchResponse response = client()
                .prepareSearch("sort_idx")
                .setTypes("multi_sort_type")
                .addAggregation(
                        terms("terms").executionHint(randomExecutionHint()).field(SINGLE_VALUED_FIELD_NAME)
                                .collectMode(randomFrom(SubAggCollectionMode.values())).order(Terms.Order.compound(order))
                                .subAggregation(avg("avg_l").field("l")).subAggregation(sum("sum_d").field("d"))).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(expectedKeys.length));

        int i = 0;
        for (Terms.Bucket bucket : terms.getBuckets()) {
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo(expectedKeys[i]));
            assertThat(bucket.getDocCount(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("_count")));
            Avg avg = bucket.getAggregations().get("avg_l");
            assertThat(avg, notNullValue());
            assertThat(avg.getValue(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("avg_l")));
            Sum sum = bucket.getAggregations().get("sum_d");
            assertThat(sum, notNullValue());
            assertThat(sum.getValue(), equalTo(expectedMultiSortBuckets.get(expectedKeys[i]).get("sum_d")));
            i++;
        }
    }
,
>
, <(startLine=479 endLine=487 srcPath=/root/NewExperiment/elasticsearchFilter/00051/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/json/SimpleJsonIndexQueryParserTests.java)
    @Test public void testFilteredQuery() throws IOException {
        IndexQueryParser queryParser = newQueryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/json/filtered-query.json");
        Query parsedQuery = queryParser.parse(query);
        assertThat(parsedQuery, instanceOf(FilteredQuery.class));
        FilteredQuery filteredQuery = (FilteredQuery) parsedQuery;
        assertThat(((TermQuery) filteredQuery.getQuery()).getTerm(), equalTo(new Term("name.first", "shay")));
        assertThat(((TermFilter) filteredQuery.getFilter()).getTerm(), equalTo(new Term("name.last", "banon")));
    }
,
(startLine=489 endLine=497 srcPath=/root/NewExperiment/elasticsearchFilter/00051/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/json/SimpleJsonIndexQueryParserTests.java)
    @Test public void testFilteredQuery2() throws IOException {
        IndexQueryParser queryParser = newQueryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/json/filtered-query2.json");
        Query parsedQuery = queryParser.parse(query);
        assertThat(parsedQuery, instanceOf(FilteredQuery.class));
        FilteredQuery filteredQuery = (FilteredQuery) parsedQuery;
        assertThat(((TermQuery) filteredQuery.getQuery()).getTerm(), equalTo(new Term("name.first", "shay")));
        assertThat(((TermFilter) filteredQuery.getFilter()).getTerm(), equalTo(new Term("name.last", "banon")));
    }
,
>
, <(startLine=329 endLine=350 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/test/java/org/elasticsearch/painless/MultiplicationTests.java)
    public void testCompoundAssignment() {
        // byte
        assertEquals((byte) 15, exec("byte x = 5; x *= 3; return x;"));
        assertEquals((byte) -5, exec("byte x = 5; x *= -1; return x;"));
        // short
        assertEquals((short) 15, exec("short x = 5; x *= 3; return x;"));
        assertEquals((short) -5, exec("short x = 5; x *= -1; return x;"));
        // char
        assertEquals((char) 15, exec("char x = 5; x *= 3; return x;"));
        // int
        assertEquals(15, exec("int x = 5; x *= 3; return x;"));
        assertEquals(-5, exec("int x = 5; x *= -1; return x;"));
        // long
        assertEquals(15L, exec("long x = 5; x *= 3; return x;"));
        assertEquals(-5L, exec("long x = 5; x *= -1; return x;"));
        // float
        assertEquals(15F, exec("float x = 5f; x *= 3; return x;"));
        assertEquals(-5F, exec("float x = 5f; x *= -1; return x;"));
        // double
        assertEquals(15D, exec("double x = 5.0; x *= 3; return x;"));
        assertEquals(-5D, exec("double x = 5.0; x *= -1; return x;"));
    }
,
(startLine=352 endLine=373 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/test/java/org/elasticsearch/painless/MultiplicationTests.java)
    public void testDefCompoundAssignment() {
        // byte
        assertEquals((byte) 15, exec("def x = (byte)5; x *= 3; return x;"));
        assertEquals((byte) -5, exec("def x = (byte)5; x *= -1; return x;"));
        // short
        assertEquals((short) 15, exec("def x = (short)5; x *= 3; return x;"));
        assertEquals((short) -5, exec("def x = (short)5; x *= -1; return x;"));
        // char
        assertEquals((char) 15, exec("def x = (char)5; x *= 3; return x;"));
        // int
        assertEquals(15, exec("def x = 5; x *= 3; return x;"));
        assertEquals(-5, exec("def x = 5; x *= -1; return x;"));
        // long
        assertEquals(15L, exec("def x = 5L; x *= 3; return x;"));
        assertEquals(-5L, exec("def x = 5L; x *= -1; return x;"));
        // float
        assertEquals(15F, exec("def x = 5f; x *= 3; return x;"));
        assertEquals(-5F, exec("def x = 5f; x *= -1; return x;"));
        // double
        assertEquals(15D, exec("def x = 5.0; x *= 3; return x;"));
        assertEquals(-5D, exec("def x = 5.0; x *= -1; return x;"));
    }
,
(startLine=359 endLine=381 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/test/java/org/elasticsearch/painless/SubtractionTests.java)
    public void testCompoundAssignment() {
        // byte
        assertEquals((byte) 15, exec("byte x = 5; x -= -10; return x;"));
        assertEquals((byte) -5, exec("byte x = 5; x -= 10; return x;"));
        // short
        assertEquals((short) 15, exec("short x = 5; x -= -10; return x;"));
        assertEquals((short) -5, exec("short x = 5; x -= 10; return x;"));
        // char
        assertEquals((char) 15, exec("char x = 5; x -= -10; return x;"));
        assertEquals((char) 5, exec("char x = 10; x -= 5; return x;"));
        // int
        assertEquals(15, exec("int x = 5; x -= -10; return x;"));
        assertEquals(-5, exec("int x = 5; x -= 10; return x;"));
        // long
        assertEquals(15L, exec("long x = 5; x -= -10; return x;"));
        assertEquals(-5L, exec("long x = 5; x -= 10; return x;"));
        // float
        assertEquals(15F, exec("float x = 5f; x -= -10; return x;"));
        assertEquals(-5F, exec("float x = 5f; x -= 10; return x;"));
        // double
        assertEquals(15D, exec("double x = 5.0; x -= -10; return x;"));
        assertEquals(-5D, exec("double x = 5.0; x -= 10; return x;"));
    }
,
(startLine=383 endLine=405 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/test/java/org/elasticsearch/painless/SubtractionTests.java)
    public void testDefCompoundAssignment() {
        // byte
        assertEquals((byte) 15, exec("def x = (byte)5; x -= -10; return x;"));
        assertEquals((byte) -5, exec("def x = (byte)5; x -= 10; return x;"));
        // short
        assertEquals((short) 15, exec("def x = (short)5; x -= -10; return x;"));
        assertEquals((short) -5, exec("def x = (short)5; x -= 10; return x;"));
        // char
        assertEquals((char) 15, exec("def x = (char)5; x -= -10; return x;"));
        assertEquals((char) 5, exec("def x = (char)10; x -= 5; return x;"));
        // int
        assertEquals(15, exec("def x = 5; x -= -10; return x;"));
        assertEquals(-5, exec("def x = 5; x -= 10; return x;"));
        // long
        assertEquals(15L, exec("def x = 5L; x -= -10; return x;"));
        assertEquals(-5L, exec("def x = 5L; x -= 10; return x;"));
        // float
        assertEquals(15F, exec("def x = 5f; x -= -10; return x;"));
        assertEquals(-5F, exec("def x = 5f; x -= 10; return x;"));
        // double
        assertEquals(15D, exec("def x = 5.0; x -= -10; return x;"));
        assertEquals(-5D, exec("def x = 5.0; x -= 10; return x;"));
    }
,
>
, <(startLine=148 endLine=155 srcPath=/root/NewExperiment/elasticsearchFilter/02116/core/src/main/java/org/elasticsearch/search/fetch/subphase/FetchSourceContext.java)
                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                            if (token == XContentParser.Token.VALUE_STRING) {
                                includesList.add(parser.text());
                            } else {
                                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token
                                        + " in [" + currentFieldName + "].", parser.getTokenLocation());
                            }
                        }
,
(startLine=159 endLine=166 srcPath=/root/NewExperiment/elasticsearchFilter/02116/core/src/main/java/org/elasticsearch/search/fetch/subphase/FetchSourceContext.java)
                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                            if (token == XContentParser.Token.VALUE_STRING) {
                                excludesList.add(parser.text());
                            } else {
                                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token
                                        + " in [" + currentFieldName + "].", parser.getTokenLocation());
                            }
                        }
,
>
, <(startLine=101 endLine=118 srcPath=/root/NewExperiment/elasticsearchFilter/00345/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/range/InternalRangeFacet.java)
    @Override public Facet aggregate(Iterable<Facet> facets) {
        InternalRangeFacet agg = null;
        for (Facet facet : facets) {
            if (!facet.name().equals(name)) {
                continue;
            }
            InternalRangeFacet geoDistanceFacet = (InternalRangeFacet) facet;
            if (agg == null) {
                agg = geoDistanceFacet;
            } else {
                for (int i = 0; i < geoDistanceFacet.entries.length; i++) {
                    agg.entries[i].count += geoDistanceFacet.entries[i].count;
                    agg.entries[i].total += geoDistanceFacet.entries[i].total;
                }
            }
        }
        return agg;
    }
,
(startLine=113 endLine=130 srcPath=/root/NewExperiment/elasticsearchFilter/00345/modules/elasticsearch/src/main/java/org/elasticsearch/search/facet/geodistance/InternalGeoDistanceFacet.java)
    @Override public Facet aggregate(Iterable<Facet> facets) {
        InternalGeoDistanceFacet agg = null;
        for (Facet facet : facets) {
            if (!facet.name().equals(name)) {
                continue;
            }
            InternalGeoDistanceFacet geoDistanceFacet = (InternalGeoDistanceFacet) facet;
            if (agg == null) {
                agg = geoDistanceFacet;
            } else {
                for (int i = 0; i < geoDistanceFacet.entries.length; i++) {
                    agg.entries[i].count += geoDistanceFacet.entries[i].count;
                    agg.entries[i].total += geoDistanceFacet.entries[i].total;
                }
            }
        }
        return agg;
    }
,
>
, <(startLine=75 endLine=84 srcPath=/root/NewExperiment/elasticsearchFilter/01658/src/test/java/org/elasticsearch/index/query/TemplateQueryTest.java)
    public void testTemplateInBody() throws IOException {
        Map<String, Object> vars = new HashMap<>();
        vars.put("template", "all");

        TemplateQueryBuilder builder = new TemplateQueryBuilder(
                "{\"match_{{template}}\": {}}\"", vars);
        SearchResponse sr = client().prepareSearch().setQuery(builder)
                .execute().actionGet();
        assertHitCount(sr, 2);
    }
,
(startLine=133 endLine=142 srcPath=/root/NewExperiment/elasticsearchFilter/01658/src/test/java/org/elasticsearch/index/query/TemplateQueryTest.java)
    public void testTemplateInFile() {
        Map<String, Object> vars = new HashMap<>();
        vars.put("template", "all");

        TemplateQueryBuilder builder = new TemplateQueryBuilder(
                "storedTemplate", ScriptService.ScriptType.FILE, vars);
        SearchResponse sr = client().prepareSearch().setQuery(builder)
                .execute().actionGet();
        assertHitCount(sr, 2);
    }
,
>
, <(startLine=156 endLine=195 srcPath=/root/NewExperiment/elasticsearchFilter/01808/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/ExtendedStatsBucketIT.java)
    public void testDocCountTopLevel() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(histogram("histo").field(SINGLE_VALUED_FIELD_NAME).interval(interval)
                        .extendedBounds(minRandomValue, maxRandomValue))
                .addAggregation(extendedStatsBucket("extended_stats_bucket", "histo>_count")).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat(buckets.size(), equalTo(numValueBuckets));

        double sum = 0;
        int count = 0;
        double min = Double.POSITIVE_INFINITY;
        double max = Double.NEGATIVE_INFINITY;
        double sumOfSquares = 0;
        for (int i = 0; i < numValueBuckets; ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) i * interval));
            assertThat(bucket.getDocCount(), equalTo(valueCounts[i]));
            count++;
            sum += bucket.getDocCount();
            min = Math.min(min, bucket.getDocCount());
            max = Math.max(max, bucket.getDocCount());
            sumOfSquares += bucket.getDocCount() * bucket.getDocCount();
        }

        double avgValue = count == 0 ? Double.NaN : (sum / count);
        ExtendedStatsBucket extendedStatsBucketValue = response.getAggregations().get("extended_stats_bucket");
        assertThat(extendedStatsBucketValue, notNullValue());
        assertThat(extendedStatsBucketValue.getName(), equalTo("extended_stats_bucket"));
        assertThat(extendedStatsBucketValue.getAvg(), equalTo(avgValue));
        assertThat(extendedStatsBucketValue.getMin(), equalTo(min));
        assertThat(extendedStatsBucketValue.getMax(), equalTo(max));
        assertThat(extendedStatsBucketValue.getSumOfSquares(), equalTo(sumOfSquares));
    }
,
(startLine=95 endLine=131 srcPath=/root/NewExperiment/elasticsearchFilter/01808/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/StatsBucketIT.java)
    public void testDocCountTopLevel() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(histogram("histo").field(SINGLE_VALUED_FIELD_NAME).interval(interval)
                        .extendedBounds(minRandomValue, maxRandomValue))
                .addAggregation(statsBucket("stats_bucket", "histo>_count")).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat(buckets.size(), equalTo(numValueBuckets));

        double sum = 0;
        int count = 0;
        double min = Double.POSITIVE_INFINITY;
        double max = Double.NEGATIVE_INFINITY;
        for (int i = 0; i < numValueBuckets; ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) i * interval));
            assertThat(bucket.getDocCount(), equalTo(valueCounts[i]));
            count++;
            sum += bucket.getDocCount();
            min = Math.min(min, bucket.getDocCount());
            max = Math.max(max, bucket.getDocCount());
        }

        double avgValue = count == 0 ? Double.NaN : (sum / count);
        StatsBucket statsBucketValue = response.getAggregations().get("stats_bucket");
        assertThat(statsBucketValue, notNullValue());
        assertThat(statsBucketValue.getName(), equalTo("stats_bucket"));
        assertThat(statsBucketValue.getAvg(), equalTo(avgValue));
        assertThat(statsBucketValue.getMin(), equalTo(min));
        assertThat(statsBucketValue.getMax(), equalTo(max));
    }
,
>
, <(startLine=106 endLine=129 srcPath=/root/NewExperiment/elasticsearchFilter/01727/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchDfsQueryThenFetchAction.java)
        void executeQuery(final int shardIndex, final DfsSearchResult dfsResult, final AtomicInteger counter, final QuerySearchRequest querySearchRequest, final DiscoveryNode node) {
            searchService.sendExecuteQuery(node, querySearchRequest, new ActionListener<QuerySearchResult>() {
                @Override
                public void onResponse(QuerySearchResult result) {
                    result.shardTarget(dfsResult.shardTarget());
                    queryResults.set(shardIndex, result);
                    if (counter.decrementAndGet() == 0) {
                        executeFetchPhase();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    try {
                        onQueryFailure(t, querySearchRequest, shardIndex, dfsResult, counter);
                    } finally {
                        // the query might not have been executed at all (for example because thread pool rejected execution)
                        // and the search context that was created in dfs phase might not be released.
                        // release it again to be in the safe side
                        sendReleaseSearchContext(querySearchRequest.id(), node);
                    }
                }
            });
        }
,
(startLine=96 endLine=119 srcPath=/root/NewExperiment/elasticsearchFilter/01727/core/src/main/java/org/elasticsearch/action/search/type/TransportSearchDfsQueryAndFetchAction.java)
        void executeSecondPhase(final int shardIndex, final DfsSearchResult dfsResult, final AtomicInteger counter, final DiscoveryNode node, final QuerySearchRequest querySearchRequest) {
            searchService.sendExecuteFetch(node, querySearchRequest, new ActionListener<QueryFetchSearchResult>() {
                @Override
                public void onResponse(QueryFetchSearchResult result) {
                    result.shardTarget(dfsResult.shardTarget());
                    queryFetchResults.set(shardIndex, result);
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }

                @Override
                public void onFailure(Throwable t) {
                    try {
                        onSecondPhaseFailure(t, querySearchRequest, shardIndex, dfsResult, counter);
                    } finally {
                        // the query might not have been executed at all (for example because thread pool rejected execution)
                        // and the search context that was created in dfs phase might not be released.
                        // release it again to be in the safe side
                        sendReleaseSearchContext(querySearchRequest.id(), node);
                    }
                }
            });
        }
,
>
, <(startLine=43 endLine=52 srcPath=/root/NewExperiment/elasticsearchFilter/02205/modules/lang-painless/src/test/java/org/elasticsearch/painless/MultiplicationTests.java)
    public void testIntConst() throws Exception {
        assertEquals(1*1, exec("return 1*1;"));
        assertEquals(2*3, exec("return 2*3;"));
        assertEquals(5*10, exec("return 5*10;"));
        assertEquals(1*1*2, exec("return 1*1*2;"));
        assertEquals((1*1)*2, exec("return (1*1)*2;"));
        assertEquals(1*(1*2), exec("return 1*(1*2);"));
        assertEquals(10*0, exec("return 10*0;"));
        assertEquals(0*0, exec("return 0*0;"));
    }
,
(startLine=42 endLine=51 srcPath=/root/NewExperiment/elasticsearchFilter/02205/modules/lang-painless/src/test/java/org/elasticsearch/painless/SubtractionTests.java)
    public void testIntConst() throws Exception {
        assertEquals(1-1, exec("return 1-1;"));
        assertEquals(2-3, exec("return 2-3;"));
        assertEquals(5-10, exec("return 5-10;"));
        assertEquals(1-1-2, exec("return 1-1-2;"));
        assertEquals((1-1)-2, exec("return (1-1)-2;"));
        assertEquals(1-(1-2), exec("return 1-(1-2);"));
        assertEquals(10-0, exec("return 10-0;"));
        assertEquals(0-0, exec("return 0-0;"));
    }
,
>
, <(startLine=418 endLine=430 srcPath=/root/NewExperiment/elasticsearchFilter/02012/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java)
                while (counter.get() < (numPhase1Docs + numPhase2Docs)) {
                    try {
                        final IndexResponse indexResponse = client().prepareIndex(IDX, "doc",
                                Integer.toString(counter.incrementAndGet())).setSource("foo", "bar").get();
                        assertEquals(DocWriteResponse.Result.CREATED, indexResponse.getResult());
                    } catch (Exception e) {
                        exceptions.add(e);
                    }
                    final int docCount = counter.get();
                    if (docCount == numPhase1Docs) {
                        phase1finished.countDown();
                    }
                }
,
(startLine=511 endLine=521 srcPath=/root/NewExperiment/elasticsearchFilter/02012/core/src/test/java/org/elasticsearch/index/IndexWithShadowReplicasIT.java)
                while (counter.get() < (numPhase1Docs + numPhase2Docs + numPhase3Docs)) {
                    final IndexResponse indexResponse = client().prepareIndex(IDX, "doc",
                            Integer.toString(counter.incrementAndGet())).setSource("foo", "bar").get();
                    assertEquals(DocWriteResponse.Result.CREATED, indexResponse.getResult());
                    final int docCount = counter.get();
                    if (docCount == numPhase1Docs) {
                        phase1finished.countDown();
                    } else if (docCount == (numPhase1Docs + numPhase2Docs)) {
                        phase2finished.countDown();
                    }
                }
,
>
, <(startLine=156 endLine=163 srcPath=/root/NewExperiment/elasticsearchFilter/00692/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java)
                if (result.topDocs() instanceof TopFieldDocs) {
                    ShardDoc[] docs = new ShardDoc[resultDocsSize];
                    for (int i = 0; i < resultDocsSize; i++) {
                        ScoreDoc scoreDoc = scoreDocs[result.from() + i];
                        docs[i] = new ShardFieldDoc(result.shardTarget(), scoreDoc.doc, scoreDoc.score, ((FieldDoc) scoreDoc).fields);
                    }
                    return docs;
                } else {
,
(startLine=163 endLine=170 srcPath=/root/NewExperiment/elasticsearchFilter/00692/src/main/java/org/elasticsearch/search/controller/SearchPhaseController.java)
                } else {
                    ShardDoc[] docs = new ShardDoc[resultDocsSize];
                    for (int i = 0; i < resultDocsSize; i++) {
                        ScoreDoc scoreDoc = scoreDocs[result.from() + i];
                        docs[i] = new ShardScoreDoc(result.shardTarget(), scoreDoc.doc, scoreDoc.score);
                    }
                    return docs;
                }
,
>
, <(startLine=752 endLine=762 srcPath=/root/NewExperiment/elasticsearchFilter/01218/src/main/java/jsr166e/ForkJoinTask.java)
        for (int i = last; i >= 0; --i) {
            ForkJoinTask<?> t = tasks[i];
            if (t == null) {
                if (ex == null)
                    ex = new NullPointerException();
            }
            else if (i != 0)
                t.fork();
            else if (t.doInvoke() < NORMAL && ex == null)
                ex = t.getException();
        }
,
(startLine=804 endLine=814 srcPath=/root/NewExperiment/elasticsearchFilter/01218/src/main/java/jsr166e/ForkJoinTask.java)
        for (int i = last; i >= 0; --i) {
            ForkJoinTask<?> t = ts.get(i);
            if (t == null) {
                if (ex == null)
                    ex = new NullPointerException();
            }
            else if (i != 0)
                t.fork();
            else if (t.doInvoke() < NORMAL && ex == null)
                ex = t.getException();
        }
,
(startLine=739 endLine=749 srcPath=/root/NewExperiment/elasticsearchFilter/01218/src/main/java/jsr166y/ForkJoinTask.java)
        for (int i = last; i >= 0; --i) {
            ForkJoinTask<?> t = tasks[i];
            if (t == null) {
                if (ex == null)
                    ex = new NullPointerException();
            }
            else if (i != 0)
                t.fork();
            else if (t.doInvoke() < NORMAL && ex == null)
                ex = t.getException();
        }
,
(startLine=790 endLine=800 srcPath=/root/NewExperiment/elasticsearchFilter/01218/src/main/java/jsr166y/ForkJoinTask.java)
        for (int i = last; i >= 0; --i) {
            ForkJoinTask<?> t = ts.get(i);
            if (t == null) {
                if (ex == null)
                    ex = new NullPointerException();
            }
            else if (i != 0)
                t.fork();
            else if (t.doInvoke() < NORMAL && ex == null)
                ex = t.getException();
        }
,
>
, <(startLine=143 endLine=157 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/support/IncludeExcludeTests.java)
    public void testExactIncludeValuesEquals() throws IOException {
        String[] incValues = { "a", "b" };
        String[] differentIncValues = { "a", "c" };
        IncludeExclude serialized = serialize(new IncludeExclude(incValues, null), IncludeExclude.INCLUDE_FIELD);
        assertFalse(serialized.isPartitionBased());
        assertFalse(serialized.isRegexBased());

        IncludeExclude same = new IncludeExclude(incValues, null);
        assertEquals(serialized, same);
        assertEquals(serialized.hashCode(), same.hashCode());

        IncludeExclude different = new IncludeExclude(differentIncValues, null);
        assertFalse(serialized.equals(different));
        assertTrue(serialized.hashCode() != different.hashCode());
    }
,
(startLine=159 endLine=173 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/support/IncludeExcludeTests.java)
    public void testExactExcludeValuesEquals() throws IOException {
        String[] excValues = { "a", "b" };
        String[] differentExcValues = { "a", "c" };
        IncludeExclude serialized = serialize(new IncludeExclude(null, excValues), IncludeExclude.EXCLUDE_FIELD);
        assertFalse(serialized.isPartitionBased());
        assertFalse(serialized.isRegexBased());

        IncludeExclude same = new IncludeExclude(null, excValues);
        assertEquals(serialized, same);
        assertEquals(serialized.hashCode(), same.hashCode());

        IncludeExclude different = new IncludeExclude(null, differentExcValues);
        assertFalse(serialized.equals(different));
        assertTrue(serialized.hashCode() != different.hashCode());
    }
,
(startLine=175 endLine=189 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/support/IncludeExcludeTests.java)
    public void testRegexInclude() throws IOException {
        String incRegex = "foo.*";
        String differentRegex = "bar.*";
        IncludeExclude serialized = serialize(new IncludeExclude(incRegex, null), IncludeExclude.INCLUDE_FIELD);
        assertFalse(serialized.isPartitionBased());
        assertTrue(serialized.isRegexBased());

        IncludeExclude same = new IncludeExclude(incRegex, null);
        assertEquals(serialized, same);
        assertEquals(serialized.hashCode(), same.hashCode());

        IncludeExclude different = new IncludeExclude(differentRegex, null);
        assertFalse(serialized.equals(different));
        assertTrue(serialized.hashCode() != different.hashCode());
    }
,
(startLine=191 endLine=205 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/support/IncludeExcludeTests.java)
    public void testRegexExclude() throws IOException {
        String excRegex = "foo.*";
        String differentRegex = "bar.*";
        IncludeExclude serialized = serialize(new IncludeExclude(null, excRegex), IncludeExclude.EXCLUDE_FIELD);
        assertFalse(serialized.isPartitionBased());
        assertTrue(serialized.isRegexBased());

        IncludeExclude same = new IncludeExclude(null, excRegex);
        assertEquals(serialized, same);
        assertEquals(serialized.hashCode(), same.hashCode());

        IncludeExclude different = new IncludeExclude(null, differentRegex);
        assertFalse(serialized.equals(different));
        assertTrue(serialized.hashCode() != different.hashCode());
    }
,
(startLine=235 endLine=250 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/support/IncludeExcludeTests.java)
    public void testRegexIncludeAndExclude() throws IOException {
        String incRegex = "foo.*";
        String excRegex = "football";
        String differentExcRegex = "foosball";
        IncludeExclude serialized = serializeMixedRegex(new IncludeExclude(incRegex, excRegex));
        assertFalse(serialized.isPartitionBased());
        assertTrue(serialized.isRegexBased());

        IncludeExclude same = new IncludeExclude(incRegex, excRegex);
        assertEquals(serialized, same);
        assertEquals(serialized.hashCode(), same.hashCode());

        IncludeExclude different = new IncludeExclude(incRegex, differentExcRegex);
        assertFalse(serialized.equals(different));
        assertTrue(serialized.hashCode() != different.hashCode());
    }
,
>
, <(startLine=80 endLine=88 srcPath=/root/NewExperiment/elasticsearchFilter/00259/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/xcontent/SimpleIndexQueryParserTests.java)
    @Test public void testQueryStringFields1Builder() throws Exception {
        IndexQueryParser queryParser = newQueryParser();
        Query parsedQuery = queryParser.parse(queryString("test").field("content").field("name").useDisMax(false)).query();
        assertThat(parsedQuery, instanceOf(BooleanQuery.class));
        BooleanQuery bQuery = (BooleanQuery) parsedQuery;
        assertThat(bQuery.clauses().size(), equalTo(2));
        assertThat(((TermQuery) bQuery.clauses().get(0).getQuery()).getTerm(), equalTo(new Term("content", "test")));
        assertThat(((TermQuery) bQuery.clauses().get(1).getQuery()).getTerm(), equalTo(new Term("name", "test")));
    }
,
(startLine=90 endLine=99 srcPath=/root/NewExperiment/elasticsearchFilter/00259/modules/elasticsearch/src/test/java/org/elasticsearch/index/query/xcontent/SimpleIndexQueryParserTests.java)
    @Test public void testQueryStringFields1() throws Exception {
        IndexQueryParser queryParser = newQueryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/xcontent/query-fields1.json");
        Query parsedQuery = queryParser.parse(query).query();
        assertThat(parsedQuery, instanceOf(BooleanQuery.class));
        BooleanQuery bQuery = (BooleanQuery) parsedQuery;
        assertThat(bQuery.clauses().size(), equalTo(2));
        assertThat(((TermQuery) bQuery.clauses().get(0).getQuery()).getTerm(), equalTo(new Term("content", "test")));
        assertThat(((TermQuery) bQuery.clauses().get(1).getQuery()).getTerm(), equalTo(new Term("name", "test")));
    }
,
>
, <(startLine=650 endLine=667 srcPath=/root/NewExperiment/elasticsearchFilter/01716/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreTests.java)
    public void testParsingExceptionIfFieldTypeDoesNotMatch() throws Exception {
        assertAcked(prepareCreate("test").addMapping(
                "type",
                jsonBuilder().startObject().startObject("type").startObject("properties").startObject("test").field("type", "string")
                        .endObject().startObject("num").field("type", "string").endObject().endObject().endObject().endObject()));
        ensureYellow();
        client().index(
                indexRequest("test").type("type").source(
                        jsonBuilder().startObject().field("test", "value").field("num", Integer.toString(1)).endObject())).actionGet();
        refresh();
        // so, we indexed a string field, but now we try to score a num field
        ActionFuture<SearchResponse> response = client().search(
                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                        searchSource().query(
                                functionScoreQuery(termQuery("test", "value")).add(new MatchAllQueryBuilder(),
                                        linearDecayFunction("num", 1.0, 0.5)).scoreMode("multiply"))));
        response.actionGet();
    }
,
(startLine=670 endLine=687 srcPath=/root/NewExperiment/elasticsearchFilter/01716/core/src/test/java/org/elasticsearch/search/functionscore/DecayFunctionScoreTests.java)
    public void testNoQueryGiven() throws Exception {
        assertAcked(prepareCreate("test").addMapping(
                "type",
                jsonBuilder().startObject().startObject("type").startObject("properties").startObject("test").field("type", "string")
                        .endObject().startObject("num").field("type", "double").endObject().endObject().endObject().endObject()));
        ensureYellow();
        client().index(
                indexRequest("test").type("type").source(jsonBuilder().startObject().field("test", "value").field("num", 1.0).endObject()))
                .actionGet();
        refresh();
        // so, we indexed a string field, but now we try to score a num field
        ActionFuture<SearchResponse> response = client().search(
                searchRequest().searchType(SearchType.QUERY_THEN_FETCH).source(
                        searchSource().query(
                                functionScoreQuery().add(new MatchAllQueryBuilder(), linearDecayFunction("num", 1, 0.5)).scoreMode(
                                        "multiply"))));
        response.actionGet();
    }
,
>
, <(startLine=1341 endLine=1408 srcPath=/root/NewExperiment/elasticsearchFilter/01026/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java)
    public void testNumericRangeFilter_2826() throws Exception {
        client().admin().indices().prepareCreate("test").setSettings(
                ImmutableSettings.settingsBuilder()
                        .put("index.number_of_shards", 1)
                        .put("index.number_of_replicas", 0)
        )
                .addMapping("type1", jsonBuilder().startObject().startObject("type1").startObject("properties")
                        .startObject("num_byte").field("type", "byte").endObject()
                        .startObject("num_short").field("type", "short").endObject()
                        .startObject("num_integer").field("type", "integer").endObject()
                        .startObject("num_long").field("type", "long").endObject()
                        .startObject("num_float").field("type", "float").endObject()
                        .startObject("num_double").field("type", "double").endObject()
                        .endObject().endObject().endObject())
                .execute().actionGet();
        ensureGreen();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 1)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 2)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 3)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 4)
                .endObject())
                .execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();
        SearchResponse response = client().prepareSearch("test").setFilter(
                FilterBuilders.boolFilter()
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4))
        ).execute().actionGet();
        assertThat(response.getHits().totalHits(), equalTo(4l));

        // This made 2826 fail! (only with bit based filters)
        response = client().prepareSearch("test").setFilter(
                FilterBuilders.boolFilter()
                        .should(FilterBuilders.numericRangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.numericRangeFilter("num_long").from(3).to(4))
        ).execute().actionGet();

        assertThat(response.getHits().totalHits(), equalTo(4l));

        // This made #2979 fail!
        response = client().prepareSearch("test").setFilter(
                FilterBuilders.boolFilter()
                        .must(FilterBuilders.termFilter("field1", "test1"))
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4))
        ).execute().actionGet();

        assertThat(response.getHits().totalHits(), equalTo(2l));
    }
,
(startLine=990 endLine=1057 srcPath=/root/NewExperiment/elasticsearchFilter/01026/src/test/java/org/elasticsearch/count/query/SimpleQueryTests.java)
    public void testNumericRangeFilter_2826() throws Exception {
                client().admin().indices().prepareCreate("test").setSettings(
                ImmutableSettings.settingsBuilder()
                        .put("index.number_of_shards", 1)
                        .put("index.number_of_replicas", 0)
        )
                .addMapping("type1", jsonBuilder().startObject().startObject("type1").startObject("properties")
                        .startObject("num_byte").field("type", "byte").endObject()
                        .startObject("num_short").field("type", "short").endObject()
                        .startObject("num_integer").field("type", "integer").endObject()
                        .startObject("num_long").field("type", "long").endObject()
                        .startObject("num_float").field("type", "float").endObject()
                        .startObject("num_double").field("type", "double").endObject()
                        .endObject().endObject().endObject())
                .execute().actionGet();
        ensureGreen();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 1)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 2)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 3)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 4)
                .endObject())
                .execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();
        CountResponse response = client().prepareCount("test").setQuery(
                filteredQuery(matchAllQuery(), FilterBuilders.boolFilter()
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4)))
        ).execute().actionGet();
        assertHitCount(response, 4l);

        // This made 2826 fail! (only with bit based filters)
        response = client().prepareCount("test").setQuery(
                filteredQuery(matchAllQuery(), FilterBuilders.boolFilter()
                        .should(FilterBuilders.numericRangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.numericRangeFilter("num_long").from(3).to(4)))
        ).execute().actionGet();

        assertHitCount(response, 4l);

        // This made #2979 fail!
        response = client().prepareCount("test").setQuery(
                filteredQuery(matchAllQuery(), FilterBuilders.boolFilter()
                        .must(FilterBuilders.termFilter("field1", "test1"))
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4)))
        ).execute().actionGet();

        assertHitCount(response, 2l);
    }
,
>
, <(startLine=44 endLine=59 srcPath=/root/NewExperiment/elasticsearchFilter/01752/plugins/discovery-azure/src/test/java/org/elasticsearch/discovery/azure/AzureTwoStartedNodesTests.java)
    public void two_nodes_should_run_using_private_ip() {
        Settings.Builder settings = Settings.settingsBuilder()
                .put(Management.SERVICE_NAME, "dummy")
                .put(Discovery.HOST_TYPE, "private_ip");

        logger.info("--> start first node");
        internalCluster().startNode(settings);
        assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout("1s").execute().actionGet().getState().nodes().masterNodeId(), notNullValue());

        logger.info("--> start another node");
        internalCluster().startNode(settings);
        assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout("1s").execute().actionGet().getState().nodes().masterNodeId(), notNullValue());

        // We expect having 2 nodes as part of the cluster, let's test that
        checkNumberOfNodes(2);
    }
,
(startLine=63 endLine=78 srcPath=/root/NewExperiment/elasticsearchFilter/01752/plugins/discovery-azure/src/test/java/org/elasticsearch/discovery/azure/AzureTwoStartedNodesTests.java)
    public void two_nodes_should_run_using_public_ip() {
        Settings.Builder settings = Settings.settingsBuilder()
                .put(Management.SERVICE_NAME, "dummy")
                .put(Discovery.HOST_TYPE, "public_ip");

        logger.info("--> start first node");
        internalCluster().startNode(settings);
        assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout("1s").execute().actionGet().getState().nodes().masterNodeId(), notNullValue());

        logger.info("--> start another node");
        internalCluster().startNode(settings);
        assertThat(client().admin().cluster().prepareState().setMasterNodeTimeout("1s").execute().actionGet().getState().nodes().masterNodeId(), notNullValue());

        // We expect having 2 nodes as part of the cluster, let's test that
        checkNumberOfNodes(2);
    }
,
>
, <(startLine=58 endLine=67 srcPath=/root/NewExperiment/elasticsearchFilter/01333/src/test/java/org/elasticsearch/common/collect/UpdateInPlaceMapTests.java)
        for (i = 0; i < switchSize; i++) {
            UpdateInPlaceMap<String, String>.Mutator mutator = map.mutator();
            String key = "key" + i;
            String value = "value" + i;
            mutator.put(key, value);
            assertThat(mutator.get(key), equalTo(value));
            assertThat(map.get(key), nullValue());
            mutator.close();
            assertThat(map.get(key), equalTo(value));
        }
,
(startLine=69 endLine=78 srcPath=/root/NewExperiment/elasticsearchFilter/01333/src/test/java/org/elasticsearch/common/collect/UpdateInPlaceMapTests.java)
        for (; i < countAfter; i++) {
            UpdateInPlaceMap<String, String>.Mutator mutator = map.mutator();
            String key = "key" + i;
            String value = "value" + i;
            mutator.put(key, value);
            assertThat(mutator.get(key), equalTo(value));
            assertThat(map.get(key), equalTo(value));
            mutator.close();
            assertThat(map.get(key), equalTo(value));
        }
,
>
, <(startLine=1116 endLine=1212 srcPath=/root/NewExperiment/elasticsearchFilter/01501/src/test/java/org/elasticsearch/search/query/SimpleQueryTests.java)
    public void testTermsLookupFilter() throws Exception {
        assertAcked(prepareCreate("lookup").addMapping("type", "terms","type=string", "other", "type=string"));
        assertAcked(prepareCreate("lookup2").addMapping("type",
                jsonBuilder().startObject().startObject("type").startObject("properties")
                        .startObject("arr").startObject("properties").startObject("term").field("type", "string")
                        .endObject().endObject().endObject().endObject().endObject().endObject()));
        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));

        ensureGreen();

        indexRandom(true,
                client().prepareIndex("lookup", "type", "1").setSource("terms", new String[]{"1", "3"}),
                client().prepareIndex("lookup", "type", "2").setSource("terms", new String[]{"2"}),
                client().prepareIndex("lookup", "type", "3").setSource("terms", new String[]{"2", "4"}),
                client().prepareIndex("lookup", "type", "4").setSource("other", "value"),
                client().prepareIndex("lookup2", "type", "1").setSource(XContentFactory.jsonBuilder().startObject()
                        .startArray("arr")
                        .startObject().field("term", "1").endObject()
                        .startObject().field("term", "3").endObject()
                        .endArray()
                        .endObject()),
                client().prepareIndex("lookup2", "type", "2").setSource(XContentFactory.jsonBuilder().startObject()
                        .startArray("arr")
                        .startObject().field("term", "2").endObject()
                        .endArray()
                        .endObject()),
                client().prepareIndex("lookup2", "type", "3").setSource(XContentFactory.jsonBuilder().startObject()
                        .startArray("arr")
                        .startObject().field("term", "2").endObject()
                        .startObject().field("term", "4").endObject()
                        .endArray()
                        .endObject()),
                client().prepareIndex("test", "type", "1").setSource("term", "1"),
                client().prepareIndex("test", "type", "2").setSource("term", "2"),
                client().prepareIndex("test", "type", "3").setSource("term", "3"),
                client().prepareIndex("test", "type", "4").setSource("term", "4") );

        SearchResponse searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("1").lookupPath("terms"))
                ).get();
        assertHitCount(searchResponse, 2l);
        assertSearchHits(searchResponse, "1", "3");

        // same as above, just on the _id...
        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("_id").lookupIndex("lookup").lookupType("type").lookupId("1").lookupPath("terms"))
                ).get();
        assertHitCount(searchResponse, 2l);
        assertSearchHits(searchResponse, "1", "3");

        // another search with same parameters...
        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("1").lookupPath("terms"))
                ).get();
        assertHitCount(searchResponse, 2l);
        assertSearchHits(searchResponse, "1", "3");

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("2").lookupPath("terms"))
                ).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId("2"));

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("3").lookupPath("terms"))
                ).get();
        assertHitCount(searchResponse, 2l);
        assertSearchHits(searchResponse, "2", "4");

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("4").lookupPath("terms"))
                ).get();
        assertHitCount(searchResponse, 0l);

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup2").lookupType("type").lookupId("1").lookupPath("arr.term"))
                ).get();
        assertHitCount(searchResponse, 2l);
        assertSearchHits(searchResponse, "1", "3");

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup2").lookupType("type").lookupId("2").lookupPath("arr.term"))
                ).get();
        assertHitCount(searchResponse, 1l);
        assertFirstHit(searchResponse, hasId("2"));

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup2").lookupType("type").lookupId("3").lookupPath("arr.term"))
                ).get();
        assertHitCount(searchResponse, 2l);
        assertSearchHits(searchResponse, "2", "4");

        searchResponse = client().prepareSearch("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("not_exists").lookupIndex("lookup2").lookupType("type").lookupId("3").lookupPath("arr.term"))
                ).get();
        assertHitCount(searchResponse, 0l);
    }
,
(startLine=598 endLine=676 srcPath=/root/NewExperiment/elasticsearchFilter/01501/src/test/java/org/elasticsearch/count/query/SimpleQueryTests.java)
    public void testTermsLookupFilter() throws Exception {
        assertAcked(prepareCreate("lookup").addMapping("type", "terms", "type=string", "other", "type=string"));
        assertAcked(prepareCreate("lookup2").addMapping("type",
                jsonBuilder().startObject().startObject("type").startObject("properties")
                        .startObject("arr").startObject("properties").startObject("term").field("type", "string")
                        .endObject().endObject().endObject().endObject().endObject().endObject()));
        assertAcked(prepareCreate("test").addMapping("type", "term", "type=string"));
        ensureGreen();

        indexRandom(true, client().prepareIndex("lookup", "type", "1").setSource("terms", new String[]{"1", "3"}),
                client().prepareIndex("lookup", "type", "2").setSource("terms", new String[]{"2"}),
                client().prepareIndex("lookup", "type", "3").setSource("terms", new String[]{"2", "4"}),
                client().prepareIndex("lookup", "type", "4").setSource("other", "value"),
                client().prepareIndex("lookup2", "type", "1").setSource(XContentFactory.jsonBuilder().startObject()
                        .startArray("arr")
                        .startObject().field("term", "1").endObject()
                        .startObject().field("term", "3").endObject()
                        .endArray()
                        .endObject()),
                client().prepareIndex("lookup2", "type", "2").setSource(XContentFactory.jsonBuilder().startObject()
                        .startArray("arr")
                        .startObject().field("term", "2").endObject()
                        .endArray()
                        .endObject()),
                client().prepareIndex("lookup2", "type", "3").setSource(XContentFactory.jsonBuilder().startObject()
                        .startArray("arr")
                        .startObject().field("term", "2").endObject()
                        .startObject().field("term", "4").endObject()
                        .endArray()
                        .endObject()),
                client().prepareIndex("test", "type", "1").setSource("term", "1"),
                client().prepareIndex("test", "type", "2").setSource("term", "2"),
                client().prepareIndex("test", "type", "3").setSource("term", "3"),
                client().prepareIndex("test", "type", "4").setSource("term", "4"));

        CountResponse countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("1").lookupPath("terms"))).get();
        assertHitCount(countResponse, 2l);

        // same as above, just on the _id...
        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("_id").lookupIndex("lookup").lookupType("type").lookupId("1").lookupPath("terms"))).get();
        assertHitCount(countResponse, 2l);

        // another search with same parameters...
        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("1").lookupPath("terms"))).get();
        assertHitCount(countResponse, 2l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("2").lookupPath("terms"))).get();
        assertHitCount(countResponse, 1l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("3").lookupPath("terms"))
                ).get();
        assertNoFailures(countResponse);
        assertHitCount(countResponse, 2l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup").lookupType("type").lookupId("4").lookupPath("terms"))).get();
        assertHitCount(countResponse, 0l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup2").lookupType("type").lookupId("1").lookupPath("arr.term"))).get();
        assertHitCount(countResponse, 2l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup2").lookupType("type").lookupId("2").lookupPath("arr.term"))).get();
        assertHitCount(countResponse, 1l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("term").lookupIndex("lookup2").lookupType("type").lookupId("3").lookupPath("arr.term"))).get();
        assertHitCount(countResponse, 2l);

        countResponse = client().prepareCount("test")
                .setQuery(filteredQuery(matchAllQuery(), termsLookupFilter("not_exists").lookupIndex("lookup2").lookupType("type").lookupId("3").lookupPath("arr.term"))).get();
        assertHitCount(countResponse, 0l);
    }
,
>
, <(startLine=45 endLine=118 srcPath=/root/NewExperiment/elasticsearchFilter/01197/src/test/java/org/elasticsearch/index/mapper/multifield/merge/JavaMultiFieldMergeTests.java)
    public void testMergeMultiField() throws Exception {
        String mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json");
        DocumentMapperParser parser = MapperTestUtils.newParser();

        DocumentMapper docMapper = parser.parse(mapping);

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed"), nullValue());

        BytesReference json = new BytesArray(copyToBytesFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-data.json"));
        Document doc = docMapper.parse(json).rootDoc();
        IndexableField f = doc.getField("name");
        assertThat(f, notNullValue());
        f = doc.getField("name.indexed");
        assertThat(f, nullValue());


        mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-mapping2.json");
        DocumentMapper docMapper2 = parser.parse(mapping);

        DocumentMapper.MergeResult mergeResult = docMapper.merge(docMapper2, mergeFlags().simulate(true));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(false));

        docMapper.merge(docMapper2, mergeFlags().simulate(false));

        assertThat(docMapper.mappers().name("name").mapper().fieldType().indexed(), equalTo(true));

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed2"), nullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed3"), nullValue());

        json = new BytesArray(copyToBytesFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-data.json"));
        doc = docMapper.parse(json).rootDoc();
        f = doc.getField("name");
        assertThat(f, notNullValue());
        f = doc.getField("name.indexed");
        assertThat(f, notNullValue());

        mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-mapping3.json");
        DocumentMapper docMapper3 = parser.parse(mapping);

        mergeResult = docMapper.merge(docMapper3, mergeFlags().simulate(true));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(false));

        docMapper.merge(docMapper3, mergeFlags().simulate(false));

        assertThat(docMapper.mappers().name("name").mapper().fieldType().indexed(), equalTo(true));

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed2").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed3"), nullValue());


        mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-mapping4.json");
        DocumentMapper docMapper4 = parser.parse(mapping);


        mergeResult = docMapper.merge(docMapper4, mergeFlags().simulate(true));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(false));

        docMapper.merge(docMapper4, mergeFlags().simulate(false));

        assertThat(docMapper.mappers().name("name").mapper().fieldType().indexed(), equalTo(true));

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed2").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed3").mapper(), notNullValue());
    }
,
(startLine=121 endLine=198 srcPath=/root/NewExperiment/elasticsearchFilter/01197/src/test/java/org/elasticsearch/index/mapper/multifield/merge/JavaMultiFieldMergeTests.java)
    public void testUpgradeFromMultiFieldTypeToMultiFields() throws Exception {
        String mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-mapping1.json");
        DocumentMapperParser parser = MapperTestUtils.newParser();

        DocumentMapper docMapper = parser.parse(mapping);

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed"), nullValue());

        BytesReference json = new BytesArray(copyToBytesFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-data.json"));
        Document doc = docMapper.parse(json).rootDoc();
        IndexableField f = doc.getField("name");
        assertThat(f, notNullValue());
        f = doc.getField("name.indexed");
        assertThat(f, nullValue());


        mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/upgrade1.json");
        DocumentMapper docMapper2 = parser.parse(mapping);

        DocumentMapper.MergeResult mergeResult = docMapper.merge(docMapper2, mergeFlags().simulate(true));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(false));

        docMapper.merge(docMapper2, mergeFlags().simulate(false));

        assertThat(docMapper.mappers().name("name").mapper().fieldType().indexed(), equalTo(true));

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed2"), nullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed3"), nullValue());

        json = new BytesArray(copyToBytesFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/test-data.json"));
        doc = docMapper.parse(json).rootDoc();
        f = doc.getField("name");
        assertThat(f, notNullValue());
        f = doc.getField("name.indexed");
        assertThat(f, notNullValue());

        mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/upgrade2.json");
        DocumentMapper docMapper3 = parser.parse(mapping);

        mergeResult = docMapper.merge(docMapper3, mergeFlags().simulate(true));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(false));

        docMapper.merge(docMapper3, mergeFlags().simulate(false));

        assertThat(docMapper.mappers().name("name").mapper().fieldType().indexed(), equalTo(true));

        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed2").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed3"), nullValue());


        mapping = copyToStringFromClasspath("/org/elasticsearch/index/mapper/multifield/merge/upgrade3.json");
        DocumentMapper docMapper4 = parser.parse(mapping);
        mergeResult = docMapper.merge(docMapper4, mergeFlags().simulate(true));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(true));
        assertThat(mergeResult.conflicts()[0], equalTo("mapper [name] has different index values"));
        assertThat(mergeResult.conflicts()[1], equalTo("mapper [name] has different store values"));

        mergeResult = docMapper.merge(docMapper4, mergeFlags().simulate(false));
        assertThat(Arrays.toString(mergeResult.conflicts()), mergeResult.hasConflicts(), equalTo(true));

        assertThat(docMapper.mappers().name("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(mergeResult.conflicts()[0], equalTo("mapper [name] has different index values"));
        assertThat(mergeResult.conflicts()[1], equalTo("mapper [name] has different store values"));

        // There are conflicts, but the `name.not_indexed3` has been added, b/c that field has no conflicts
        assertThat(docMapper.mappers().fullName("name").mapper().fieldType().indexed(), equalTo(true));
        assertThat(docMapper.mappers().fullName("name.indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed2").mapper(), notNullValue());
        assertThat(docMapper.mappers().fullName("name.not_indexed3").mapper(), notNullValue());
    }
,
>
, <(startLine=35 endLine=42 srcPath=/root/NewExperiment/elasticsearchFilter/00989/src/test/java/org/elasticsearch/index/analysis/CJKFilterFactoryTests.java)
    public void testDefault() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromClassPath(RESOURCE);
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("cjk_bigram");
        String source = "多くの学生が試験に落ちた。";
        String[] expected = new String[]{"多く", "くの", "の学", "学生", "生が", "が試", "試験", "験に", "に落", "落ち", "ちた" };
        Tokenizer tokenizer = new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
(startLine=45 endLine=52 srcPath=/root/NewExperiment/elasticsearchFilter/00989/src/test/java/org/elasticsearch/index/analysis/CJKFilterFactoryTests.java)
    public void testNoFlags() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromClassPath(RESOURCE);
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("cjk_no_flags");
        String source = "多くの学生が試験に落ちた。";
        String[] expected = new String[]{"多く", "くの", "の学", "学生", "生が", "が試", "試験", "験に", "に落", "落ち", "ちた" };
        Tokenizer tokenizer = new StandardTokenizer(TEST_VERSION_CURRENT, new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
>
, <(startLine=194 endLine=249 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/index/query/MatchPhrasePrefixQueryBuilder.java)
    public static MatchPhrasePrefixQueryBuilder fromXContent(XContentParser parser) throws IOException {
        String fieldName = null;
        Object value = null;
        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
        String analyzer = null;
        int slop = MatchQuery.DEFAULT_PHRASE_SLOP;
        int maxExpansion = FuzzyQuery.defaultMaxExpansions;
        String queryName = null;
        XContentParser.Token token;
        String currentFieldName = null;
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                throwParsingExceptionOnMultipleFields(NAME, parser.getTokenLocation(), fieldName, currentFieldName);
                fieldName = currentFieldName;
                while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                    if (token == XContentParser.Token.FIELD_NAME) {
                        currentFieldName = parser.currentName();
                    } else if (token.isValue()) {
                        if (MatchQueryBuilder.QUERY_FIELD.match(currentFieldName)) {
                            value = parser.objectText();
                        } else if (MatchQueryBuilder.ANALYZER_FIELD.match(currentFieldName)) {
                            analyzer = parser.text();
                        } else if (AbstractQueryBuilder.BOOST_FIELD.match(currentFieldName)) {
                            boost = parser.floatValue();
                        } else if (MatchPhraseQueryBuilder.SLOP_FIELD.match(currentFieldName)) {
                            slop = parser.intValue();
                        } else if (MAX_EXPANSIONS_FIELD.match(currentFieldName)) {
                            maxExpansion = parser.intValue();
                        } else if (AbstractQueryBuilder.NAME_FIELD.match(currentFieldName)) {
                            queryName = parser.text();
                        } else {
                            throw new ParsingException(parser.getTokenLocation(),
                                    "[" + NAME + "] query does not support [" + currentFieldName + "]");
                        }
                    } else {
                        throw new ParsingException(parser.getTokenLocation(),
                                "[" + NAME + "] unknown token [" + token + "] after [" + currentFieldName + "]");
                    }
                }
            } else {
                throwParsingExceptionOnMultipleFields(NAME, parser.getTokenLocation(), fieldName, parser.currentName());
                fieldName = parser.currentName();
                value = parser.objectText();
            }
        }

        MatchPhrasePrefixQueryBuilder matchQuery = new MatchPhrasePrefixQueryBuilder(fieldName, value);
        matchQuery.analyzer(analyzer);
        matchQuery.slop(slop);
        matchQuery.maxExpansions(maxExpansion);
        matchQuery.queryName(queryName);
        matchQuery.boost(boost);
        return matchQuery;
    }
,
(startLine=166 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/index/query/MatchPhraseQueryBuilder.java)
    public static MatchPhraseQueryBuilder fromXContent(XContentParser parser) throws IOException {
        String fieldName = null;
        Object value = null;
        float boost = AbstractQueryBuilder.DEFAULT_BOOST;
        String analyzer = null;
        int slop = MatchQuery.DEFAULT_PHRASE_SLOP;
        String queryName = null;
        String currentFieldName = null;
        XContentParser.Token token;
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                throwParsingExceptionOnMultipleFields(NAME, parser.getTokenLocation(), fieldName, currentFieldName);
                fieldName = currentFieldName;
                while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
                    if (token == XContentParser.Token.FIELD_NAME) {
                        currentFieldName = parser.currentName();
                    } else if (token.isValue()) {
                        if (MatchQueryBuilder.QUERY_FIELD.match(currentFieldName)) {
                            value = parser.objectText();
                        } else if (MatchQueryBuilder.ANALYZER_FIELD.match(currentFieldName)) {
                            analyzer = parser.text();
                        } else if (AbstractQueryBuilder.BOOST_FIELD.match(currentFieldName)) {
                            boost = parser.floatValue();
                        } else if (SLOP_FIELD.match(currentFieldName)) {
                            slop = parser.intValue();
                        } else if (AbstractQueryBuilder.NAME_FIELD.match(currentFieldName)) {
                            queryName = parser.text();
                        } else {
                            throw new ParsingException(parser.getTokenLocation(),
                                    "[" + NAME + "] query does not support [" + currentFieldName + "]");
                        }
                    } else {
                        throw new ParsingException(parser.getTokenLocation(),
                                "[" + NAME + "] unknown token [" + token + "] after [" + currentFieldName + "]");
                    }
                }
            } else {
                throwParsingExceptionOnMultipleFields(NAME, parser.getTokenLocation(), fieldName, parser.currentName());
                fieldName = parser.currentName();
                value = parser.objectText();
            }
        }

        MatchPhraseQueryBuilder matchQuery = new MatchPhraseQueryBuilder(fieldName, value);
        matchQuery.analyzer(analyzer);
        matchQuery.slop(slop);
        matchQuery.queryName(queryName);
        matchQuery.boost(boost);
        return matchQuery;
    }
,
>
, <(startLine=96 endLine=111 srcPath=/root/NewExperiment/elasticsearchFilter/00593/src/main/java/org/elasticsearch/common/lucene/docset/OrDocIdSet.java)
            while (true) {
                DocIdSetIterator topIter = top.iter;
                int docid;
                if ((docid = topIter.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
                    top.doc = docid;
                    heapAdjust();
                } else {
                    heapRemoveRoot();
                    if (_size == 0) return (_curDoc = DocIdSetIterator.NO_MORE_DOCS);
                }
                top = _heap[0];
                int topDoc = top.doc;
                if (topDoc > _curDoc) {
                    return (_curDoc = topDoc);
                }
            }
,
(startLine=121 endLine=136 srcPath=/root/NewExperiment/elasticsearchFilter/00593/src/main/java/org/elasticsearch/common/lucene/docset/OrDocIdSet.java)
            while (true) {
                DocIdSetIterator topIter = top.iter;
                int docid;
                if ((docid = topIter.advance(target)) != DocIdSetIterator.NO_MORE_DOCS) {
                    top.doc = docid;
                    heapAdjust();
                } else {
                    heapRemoveRoot();
                    if (_size == 0) return (_curDoc = DocIdSetIterator.NO_MORE_DOCS);
                }
                top = _heap[0];
                int topDoc = top.doc;
                if (topDoc >= target) {
                    return (_curDoc = topDoc);
                }
            }
,
(startLine=121 endLine=136 srcPath=/root/NewExperiment/elasticsearchFilter/00593/src/main/java/org/elasticsearch/common/lucene/docset/OrDocSet.java)
            while (true) {
                DocIdSetIterator topIter = top.iter;
                int docid;
                if ((docid = topIter.nextDoc()) != DocIdSetIterator.NO_MORE_DOCS) {
                    top.doc = docid;
                    heapAdjust();
                } else {
                    heapRemoveRoot();
                    if (_size == 0) return (_curDoc = DocIdSetIterator.NO_MORE_DOCS);
                }
                top = _heap[0];
                int topDoc = top.doc;
                if (topDoc > _curDoc) {
                    return (_curDoc = topDoc);
                }
            }
,
(startLine=146 endLine=161 srcPath=/root/NewExperiment/elasticsearchFilter/00593/src/main/java/org/elasticsearch/common/lucene/docset/OrDocSet.java)
            while (true) {
                DocIdSetIterator topIter = top.iter;
                int docid;
                if ((docid = topIter.advance(target)) != DocIdSetIterator.NO_MORE_DOCS) {
                    top.doc = docid;
                    heapAdjust();
                } else {
                    heapRemoveRoot();
                    if (_size == 0) return (_curDoc = DocIdSetIterator.NO_MORE_DOCS);
                }
                top = _heap[0];
                int topDoc = top.doc;
                if (topDoc >= target) {
                    return (_curDoc = topDoc);
                }
            }
,
>
, <(startLine=95 endLine=109 srcPath=/root/NewExperiment/elasticsearchFilter/00209/modules/elasticsearch/src/main/java/org/elasticsearch/indices/memory/IndicesMemoryCleaner.java)
    public void fullMemoryClean() {
        for (IndexService indexService : indicesService) {
            for (IndexShard indexShard : indexService) {
                try {
                    indexShard.flush(new Engine.Flush().full(true));
                } catch (FlushNotAllowedEngineException e) {
                    // ignore this one, its temporal
                } catch (IllegalIndexShardStateException e) {
                    // ignore this one as well
                } catch (Exception e) {
                    logger.warn(indexShard.shardId() + ": Failed to force flush in order to clean memory", e);
                }
            }
        }
    }
,
(startLine=111 endLine=127 srcPath=/root/NewExperiment/elasticsearchFilter/00209/modules/elasticsearch/src/main/java/org/elasticsearch/indices/memory/IndicesMemoryCleaner.java)
    public void forceCleanMemory(Set<ShardId> shardsToIgnore) {
        for (IndexService indexService : indicesService) {
            for (IndexShard indexShard : indexService) {
                if (!shardsToIgnore.contains(indexShard.shardId())) {
                    try {
                        indexShard.flush(new Engine.Flush().full(false));
                    } catch (FlushNotAllowedEngineException e) {
                        // ignore this one, its temporal
                    } catch (IllegalIndexShardStateException e) {
                        // ignore this one as well
                    } catch (Exception e) {
                        logger.warn(indexShard.shardId() + ": Failed to force flush in order to clean memory", e);
                    }
                }
            }
        }
    }
,
>
, <(startLine=1155 endLine=1180 srcPath=/root/NewExperiment/elasticsearchFilter/01410/src/main/java/org/apache/lucene/expressions/js/XJavascriptLexer.java)
                    while (true) {
                        int alt11=2;
                        int LA11_0 = input.LA(1);
                        if ( ((LA11_0 >= '0' && LA11_0 <= '9')) ) {
                            alt11=1;
                        }

                        switch (alt11) {
                            case 1 :
                                // src/java/org/apache/lucene/expressions/js/Javascript.g:
                            {
                                if ( (input.LA(1) >= '0' && input.LA(1) <= '9') ) {
                                    input.consume();
                                }
                                else {
                                    MismatchedSetException mse = new MismatchedSetException(null,input);
                                    recover(mse);
                                    throw mse;
                                }
                            }
                            break;

                            default :
                                break loop11;
                        }
                    }
,
(startLine=1476 endLine=1507 srcPath=/root/NewExperiment/elasticsearchFilter/01410/src/main/java/org/apache/lucene/expressions/js/XJavascriptLexer.java)
                {
                    matchRange('1','9');
                    // src/java/org/apache/lucene/expressions/js/Javascript.g:395:16: ( DECIMALDIGIT )*
                    loop20:
                    while (true) {
                        int alt20=2;
                        int LA20_0 = input.LA(1);
                        if ( ((LA20_0 >= '0' && LA20_0 <= '9')) ) {
                            alt20=1;
                        }

                        switch (alt20) {
                            case 1 :
                                // src/java/org/apache/lucene/expressions/js/Javascript.g:
                            {
                                if ( (input.LA(1) >= '0' && input.LA(1) <= '9') ) {
                                    input.consume();
                                }
                                else {
                                    MismatchedSetException mse = new MismatchedSetException(null,input);
                                    recover(mse);
                                    throw mse;
                                }
                            }
                            break;

                            default :
                                break loop20;
                        }
                    }

                }
,
>
, <(startLine=67 endLine=77 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregationBuilder.java)
    public BucketScriptPipelineAggregationBuilder(StreamInput in) throws IOException {
        super(in, NAME);
        int mapSize = in.readVInt();
        bucketsPathsMap = new HashMap<>(mapSize);
        for (int i = 0; i < mapSize; i++) {
            bucketsPathsMap.put(in.readString(), in.readString());
        }
        script = new Script(in);
        format = in.readOptionalString();
        gapPolicy = GapPolicy.readFrom(in);
    }
,
(startLine=64 endLine=73 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketselector/BucketSelectorPipelineAggregationBuilder.java)
    public BucketSelectorPipelineAggregationBuilder(StreamInput in) throws IOException {
        super(in, NAME);
        int mapSize = in.readVInt();
        bucketsPathsMap = new HashMap<>(mapSize);
        for (int i = 0; i < mapSize; i++) {
            bucketsPathsMap.put(in.readString(), in.readString());
        }
        script = new Script(in);
        gapPolicy = GapPolicy.readFrom(in);
    }
,
>
, <(startLine=47 endLine=64 srcPath=/root/NewExperiment/elasticsearchFilter/02086/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java)
    public Decision canRebalance(ShardRouting shardRouting, RoutingAllocation allocation) {
        Decision.Multi ret = new Decision.Multi();
        for (AllocationDecider allocationDecider : allocations) {
            Decision decision = allocationDecider.canRebalance(shardRouting, allocation);
            // short track if a NO is returned.
            if (decision == Decision.NO) {
                if (!allocation.debugDecision()) {
                    return decision;
                } else {
                    ret.add(decision);
                }
            } else if (decision != Decision.ALWAYS
                        && (allocation.getDebugMode() != EXCLUDE_YES_DECISIONS || decision.type() != Decision.Type.YES)) {
                ret.add(decision);
            }
        }
        return ret;
    }
,
(startLine=125 endLine=142 srcPath=/root/NewExperiment/elasticsearchFilter/02086/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java)
    public Decision canAllocate(IndexMetaData indexMetaData, RoutingNode node, RoutingAllocation allocation) {
        Decision.Multi ret = new Decision.Multi();
        for (AllocationDecider allocationDecider : allocations) {
            Decision decision = allocationDecider.canAllocate(indexMetaData, node, allocation);
            // short track if a NO is returned.
            if (decision == Decision.NO) {
                if (!allocation.debugDecision()) {
                    return decision;
                } else {
                    ret.add(decision);
                }
            } else if (decision != Decision.ALWAYS
                        && (allocation.getDebugMode() != EXCLUDE_YES_DECISIONS || decision.type() != Decision.Type.YES)) {
                ret.add(decision);
            }
        }
        return ret;
    }
,
(startLine=145 endLine=162 srcPath=/root/NewExperiment/elasticsearchFilter/02086/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java)
    public Decision canAllocate(ShardRouting shardRouting, RoutingAllocation allocation) {
        Decision.Multi ret = new Decision.Multi();
        for (AllocationDecider allocationDecider : allocations) {
            Decision decision = allocationDecider.canAllocate(shardRouting, allocation);
            // short track if a NO is returned.
            if (decision == Decision.NO) {
                if (!allocation.debugDecision()) {
                    return decision;
                } else {
                    ret.add(decision);
                }
            } else if (decision != Decision.ALWAYS
                        && (allocation.getDebugMode() != EXCLUDE_YES_DECISIONS || decision.type() != Decision.Type.YES)) {
                ret.add(decision);
            }
        }
        return ret;
    }
,
(startLine=165 endLine=182 srcPath=/root/NewExperiment/elasticsearchFilter/02086/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java)
    public Decision canAllocate(RoutingNode node, RoutingAllocation allocation) {
        Decision.Multi ret = new Decision.Multi();
        for (AllocationDecider allocationDecider : allocations) {
            Decision decision = allocationDecider.canAllocate(node, allocation);
            // short track if a NO is returned.
            if (decision == Decision.NO) {
                if (!allocation.debugDecision()) {
                    return decision;
                } else {
                    ret.add(decision);
                }
            } else if (decision != Decision.ALWAYS
                        && (allocation.getDebugMode() != EXCLUDE_YES_DECISIONS || decision.type() != Decision.Type.YES)) {
                ret.add(decision);
            }
        }
        return ret;
    }
,
(startLine=185 endLine=202 srcPath=/root/NewExperiment/elasticsearchFilter/02086/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/AllocationDeciders.java)
    public Decision canRebalance(RoutingAllocation allocation) {
        Decision.Multi ret = new Decision.Multi();
        for (AllocationDecider allocationDecider : allocations) {
            Decision decision = allocationDecider.canRebalance(allocation);
            // short track if a NO is returned.
            if (decision == Decision.NO) {
                if (!allocation.debugDecision()) {
                    return decision;
                } else {
                    ret.add(decision);
                }
            } else if (decision != Decision.ALWAYS
                        && (allocation.getDebugMode() != EXCLUDE_YES_DECISIONS || decision.type() != Decision.Type.YES)) {
                ret.add(decision);
            }
        }
        return ret;
    }
,
>
, <(startLine=1035 endLine=1071 srcPath=/root/NewExperiment/elasticsearchFilter/02318/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  public final BlockContext block() throws RecognitionException {
    BlockContext _localctx = new BlockContext(_ctx, getState());
    enterRule(_localctx, 10, RULE_block);
    int _la;
    try {
      enterOuterAlt(_localctx, 1);
      {
      setState(191);
      match(LBRACK);
      setState(195);
      _errHandler.sync(this);
      _la = _input.LA(1);
      while ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << LBRACE) | (1L << LP) | (1L << IF) | (1L << WHILE) | (1L << DO) | (1L << FOR) | (1L << CONTINUE) | (1L << BREAK) | (1L << RETURN) | (1L << NEW) | (1L << TRY) | (1L << THROW) | (1L << BOOLNOT) | (1L << BWNOT) | (1L << ADD) | (1L << SUB) | (1L << INCR) | (1L << DECR))) != 0) || ((((_la - 72)) & ~0x3f) == 0 && ((1L << (_la - 72)) & ((1L << (OCTAL - 72)) | (1L << (HEX - 72)) | (1L << (INTEGER - 72)) | (1L << (DECIMAL - 72)) | (1L << (STRING - 72)) | (1L << (REGEX - 72)) | (1L << (TRUE - 72)) | (1L << (FALSE - 72)) | (1L << (NULL - 72)) | (1L << (TYPE - 72)) | (1L << (ID - 72)))) != 0)) {
        {
        {
        setState(192);
        statement();
        }
        }
        setState(197);
        _errHandler.sync(this);
        _la = _input.LA(1);
      }
      setState(198);
      match(RBRACK);
      }
    }
    catch (RecognitionException re) {
      _localctx.exception = re;
      _errHandler.reportError(this, re);
      _errHandler.recover(this, re);
    }
    finally {
      exitRule();
    }
    return _localctx;
  }
,
(startLine=3178 endLine=3227 srcPath=/root/NewExperiment/elasticsearchFilter/02318/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  public final ArgumentsContext arguments() throws RecognitionException {
    ArgumentsContext _localctx = new ArgumentsContext(_ctx, getState());
    enterRule(_localctx, 54, RULE_arguments);
    int _la;
    try {
      enterOuterAlt(_localctx, 1);
      {
      {
      setState(449);
      match(LP);
      setState(458);
      _la = _input.LA(1);
      if ((((_la) & ~0x3f) == 0 && ((1L << _la) & ((1L << LBRACE) | (1L << LP) | (1L << NEW) | (1L << THIS) | (1L << BOOLNOT) | (1L << BWNOT) | (1L << ADD) | (1L << SUB) | (1L << INCR) | (1L << DECR))) != 0) || ((((_la - 72)) & ~0x3f) == 0 && ((1L << (_la - 72)) & ((1L << (OCTAL - 72)) | (1L << (HEX - 72)) | (1L << (INTEGER - 72)) | (1L << (DECIMAL - 72)) | (1L << (STRING - 72)) | (1L << (REGEX - 72)) | (1L << (TRUE - 72)) | (1L << (FALSE - 72)) | (1L << (NULL - 72)) | (1L << (TYPE - 72)) | (1L << (ID - 72)))) != 0)) {
        {
        setState(450);
        argument();
        setState(455);
        _errHandler.sync(this);
        _la = _input.LA(1);
        while (_la==COMMA) {
          {
          {
          setState(451);
          match(COMMA);
          setState(452);
          argument();
          }
          }
          setState(457);
          _errHandler.sync(this);
          _la = _input.LA(1);
        }
        }
      }

      setState(460);
      match(RP);
      }
      }
    }
    catch (RecognitionException re) {
      _localctx.exception = re;
      _errHandler.reportError(this, re);
      _errHandler.recover(this, re);
    }
    finally {
      exitRule();
    }
    return _localctx;
  }
,
>
, <(startLine=518 endLine=537 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/moving/avg/MovAvgTests.java)
    public void testSizeZeroWindow() {
        try {
            client()
                    .prepareSearch("idx").setTypes("type")
                    .addAggregation(
                            histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                    .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                    .subAggregation(randomMetric("the_metric", VALUE_FIELD))
                                    .subAggregation(movingAvg("movavg_counts")
                                            .window(0)
                                            .modelBuilder(new SimpleModel.SimpleModelBuilder())
                                            .gapPolicy(gapPolicy)
                                            .setBucketsPaths("the_metric"))
                    ).execute().actionGet();
            fail("MovingAvg should not accept a window that is zero");

        } catch (SearchPhaseExecutionException exception) {
           // All good
        }
    }
,
(startLine=561 endLine=582 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/moving/avg/MovAvgTests.java)
    public void testNegativeWindow() {
        try {
            client()
                    .prepareSearch("idx").setTypes("type")
                    .addAggregation(
                            histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                    .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                    .subAggregation(randomMetric("the_metric", VALUE_FIELD))
                                    .subAggregation(movingAvg("movavg_counts")
                                            .window(-10)
                                            .modelBuilder(new SimpleModel.SimpleModelBuilder())
                                            .gapPolicy(gapPolicy)
                                            .setBucketsPaths("_count"))
                    ).execute().actionGet();
            fail("MovingAvg should not accept a window that is negative");

        } catch (SearchPhaseExecutionException exception) {
            //Throwable rootCause = exception.unwrapCause();
            //assertThat(rootCause, instanceOf(SearchParseException.class));
            //assertThat("[window] value must be a positive, non-zero integer.  Value supplied was [0] in [movingAvg].", equalTo(exception.getMessage()));
        }
    }
,
(startLine=636 endLine=656 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/moving/avg/MovAvgTests.java)
    public void testZeroPrediction() {
        try {
            client()
                    .prepareSearch("idx").setTypes("type")
                    .addAggregation(
                            histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                    .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                    .subAggregation(randomMetric("the_metric", VALUE_FIELD))
                                    .subAggregation(movingAvg("movavg_counts")
                                            .window(windowSize)
                                            .modelBuilder(randomModelBuilder())
                                            .gapPolicy(gapPolicy)
                                            .predict(0)
                                            .setBucketsPaths("the_metric"))
                    ).execute().actionGet();
            fail("MovingAvg should not accept a prediction size that is zero");

        } catch (SearchPhaseExecutionException exception) {
            // All Good
        }
    }
,
(startLine=659 endLine=679 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/moving/avg/MovAvgTests.java)
    public void testNegativePrediction() {
        try {
            client()
                    .prepareSearch("idx").setTypes("type")
                    .addAggregation(
                            histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                    .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                    .subAggregation(randomMetric("the_metric", VALUE_FIELD))
                                    .subAggregation(movingAvg("movavg_counts")
                                            .window(windowSize)
                                            .modelBuilder(randomModelBuilder())
                                            .gapPolicy(gapPolicy)
                                            .predict(-10)
                                            .setBucketsPaths("the_metric"))
                    ).execute().actionGet();
            fail("MovingAvg should not accept a prediction size that is negative");

        } catch (SearchPhaseExecutionException exception) {
            // All Good
        }
    }
,
>
, <(startLine=217 endLine=309 srcPath=/root/NewExperiment/elasticsearchFilter/00594/src/test/java/org/elasticsearch/test/integration/search/child/SimpleChildQuerySearchTests.java)
    public void simpleChildQueryWithFlush() throws Exception {
        client.admin().indices().prepareDelete().execute().actionGet();

        client.admin().indices().prepareCreate("test").setSettings(ImmutableSettings.settingsBuilder().put("index.number_of_shards", 1)).execute().actionGet();
        client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();
        client.admin().indices().preparePutMapping("test").setType("child").setSource(XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("_parent").field("type", "parent").endObject()
                .endObject().endObject()).execute().actionGet();

        // index simple data with flushes, so we have many segments
        client.prepareIndex("test", "parent", "p1").setSource("p_field", "p_value1").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c1").setSource("c_field", "red").setParent("p1").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c2").setSource("c_field", "yellow").setParent("p1").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "parent", "p2").setSource("p_field", "p_value2").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c3").setSource("c_field", "blue").setParent("p2").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c4").setSource("c_field", "red").setParent("p2").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();

        client.admin().indices().prepareRefresh().execute().actionGet();

        // TOP CHILDREN QUERY

        SearchResponse searchResponse = client.prepareSearch("test").setQuery(topChildrenQuery("child", termQuery("c_field", "yellow"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p1"));

        searchResponse = client.prepareSearch("test").setQuery(topChildrenQuery("child", termQuery("c_field", "blue"))).execute().actionGet();
        if (searchResponse.failedShards() > 0) {
            logger.warn("Failed shards:");
            for (ShardSearchFailure shardSearchFailure : searchResponse.shardFailures()) {
                logger.warn("-> {}", shardSearchFailure);
            }
        }
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p2"));

        searchResponse = client.prepareSearch("test").setQuery(topChildrenQuery("child", termQuery("c_field", "red"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(2l));
        assertThat(searchResponse.hits().getAt(0).id(), anyOf(equalTo("p2"), equalTo("p1")));
        assertThat(searchResponse.hits().getAt(1).id(), anyOf(equalTo("p2"), equalTo("p1")));

        // HAS CHILD QUERY

        searchResponse = client.prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "yellow"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p1"));

        searchResponse = client.prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "blue"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p2"));

        searchResponse = client.prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "red"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(2l));
        assertThat(searchResponse.hits().getAt(0).id(), anyOf(equalTo("p2"), equalTo("p1")));
        assertThat(searchResponse.hits().getAt(1).id(), anyOf(equalTo("p2"), equalTo("p1")));

        // HAS CHILD FILTER

        searchResponse = client.prepareSearch("test").setQuery(constantScoreQuery(hasChildFilter("child", termQuery("c_field", "yellow")))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p1"));

        searchResponse = client.prepareSearch("test").setQuery(constantScoreQuery(hasChildFilter("child", termQuery("c_field", "blue")))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p2"));

        searchResponse = client.prepareSearch("test").setQuery(constantScoreQuery(hasChildFilter("child", termQuery("c_field", "red")))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(2l));
        assertThat(searchResponse.hits().getAt(0).id(), anyOf(equalTo("p2"), equalTo("p1")));
        assertThat(searchResponse.hits().getAt(1).id(), anyOf(equalTo("p2"), equalTo("p1")));
    }
,
(startLine=312 endLine=404 srcPath=/root/NewExperiment/elasticsearchFilter/00594/src/test/java/org/elasticsearch/test/integration/search/child/SimpleChildQuerySearchTests.java)
    public void simpleChildQueryWithFlushAnd3Shards() throws Exception {
        client.admin().indices().prepareDelete().execute().actionGet();

        client.admin().indices().prepareCreate("test").setSettings(ImmutableSettings.settingsBuilder().put("index.number_of_shards", 3)).execute().actionGet();
        client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();
        client.admin().indices().preparePutMapping("test").setType("child").setSource(XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("_parent").field("type", "parent").endObject()
                .endObject().endObject()).execute().actionGet();

        // index simple data with flushes, so we have many segments
        client.prepareIndex("test", "parent", "p1").setSource("p_field", "p_value1").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c1").setSource("c_field", "red").setParent("p1").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c2").setSource("c_field", "yellow").setParent("p1").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "parent", "p2").setSource("p_field", "p_value2").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c3").setSource("c_field", "blue").setParent("p2").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();
        client.prepareIndex("test", "child", "c4").setSource("c_field", "red").setParent("p2").execute().actionGet();
        client.admin().indices().prepareFlush().execute().actionGet();

        client.admin().indices().prepareRefresh().execute().actionGet();

        // TOP CHILDREN QUERY

        SearchResponse searchResponse = client.prepareSearch("test").setQuery(topChildrenQuery("child", termQuery("c_field", "yellow"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p1"));

        searchResponse = client.prepareSearch("test").setQuery(topChildrenQuery("child", termQuery("c_field", "blue"))).execute().actionGet();
        if (searchResponse.failedShards() > 0) {
            logger.warn("Failed shards:");
            for (ShardSearchFailure shardSearchFailure : searchResponse.shardFailures()) {
                logger.warn("-> {}", shardSearchFailure);
            }
        }
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p2"));

        searchResponse = client.prepareSearch("test").setQuery(topChildrenQuery("child", termQuery("c_field", "red"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(2l));
        assertThat(searchResponse.hits().getAt(0).id(), anyOf(equalTo("p2"), equalTo("p1")));
        assertThat(searchResponse.hits().getAt(1).id(), anyOf(equalTo("p2"), equalTo("p1")));

        // HAS CHILD QUERY

        searchResponse = client.prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "yellow"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p1"));

        searchResponse = client.prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "blue"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p2"));

        searchResponse = client.prepareSearch("test").setQuery(hasChildQuery("child", termQuery("c_field", "red"))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(2l));
        assertThat(searchResponse.hits().getAt(0).id(), anyOf(equalTo("p2"), equalTo("p1")));
        assertThat(searchResponse.hits().getAt(1).id(), anyOf(equalTo("p2"), equalTo("p1")));

        // HAS CHILD FILTER

        searchResponse = client.prepareSearch("test").setQuery(constantScoreQuery(hasChildFilter("child", termQuery("c_field", "yellow")))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p1"));

        searchResponse = client.prepareSearch("test").setQuery(constantScoreQuery(hasChildFilter("child", termQuery("c_field", "blue")))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(1l));
        assertThat(searchResponse.hits().getAt(0).id(), equalTo("p2"));

        searchResponse = client.prepareSearch("test").setQuery(constantScoreQuery(hasChildFilter("child", termQuery("c_field", "red")))).execute().actionGet();
        assertThat("Failures " + Arrays.toString(searchResponse.shardFailures()), searchResponse.shardFailures().length, equalTo(0));
        assertThat(searchResponse.failedShards(), equalTo(0));
        assertThat(searchResponse.hits().totalHits(), equalTo(2l));
        assertThat(searchResponse.hits().getAt(0).id(), anyOf(equalTo("p2"), equalTo("p1")));
        assertThat(searchResponse.hits().getAt(1).id(), anyOf(equalTo("p2"), equalTo("p1")));
    }
,
>
, <(startLine=157 endLine=167 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/main/java/org/elasticsearch/index/fielddata/plain/GeoPointCompressedAtomicFieldData.java)
        public MultiGeoPointValues getGeoPointValues() {
            final GeoPoint point = new GeoPoint();
            final GeoPointValues values = new GeoPointValues() {
                @Override
                public GeoPoint get(int docID) {
                    encoding.decode(lat.get(docID), lon.get(docID), point);
                    return point;
                }
            };
            return FieldData.singleton(values, set);
        }
,
(startLine=148 endLine=158 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/main/java/org/elasticsearch/index/fielddata/plain/GeoPointDoubleArrayAtomicFieldData.java)
        public MultiGeoPointValues getGeoPointValues() {
            final GeoPoint point = new GeoPoint();
            final GeoPointValues values = new GeoPointValues() {
                @Override
                public GeoPoint get(int docID) {
                    point.reset(lat.get(docID), lon.get(docID));
                    return point;
                }
            };
            return FieldData.singleton(values, set);
        }
,
>
, <(startLine=86 endLine=109 srcPath=/root/NewExperiment/elasticsearchFilter/01739/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java)
    public void assertMapMultiBinding(Module module, Class to, Class theClass) {
        List<Element> elements = Elements.getElements(module);
        Set<Type> bindings = new HashSet<>();
        boolean providerFound = false;
        for (Element element : elements) {
            if (element instanceof LinkedKeyBinding) {
                LinkedKeyBinding binding = (LinkedKeyBinding) element;
                if (to.equals(binding.getKey().getTypeLiteral().getType())) {
                    bindings.add(binding.getLinkedKey().getTypeLiteral().getType());
                }
            } else if (element instanceof ProviderInstanceBinding) {
                ProviderInstanceBinding binding = (ProviderInstanceBinding) element;
                String setType = binding.getKey().getTypeLiteral().getType().toString();
                if (setType.equals("java.util.Map<java.lang.String, " + to.getName() + ">")) {
                    providerFound = true;
                }
            }
        }

        if (bindings.contains(theClass) == false) {
            fail("Expected to find " + theClass.getName() + " as binding to " + to.getName() + ", found these classes:\n" + bindings);
        }
        assertTrue("Did not find provider for map of " + to.getName(), providerFound);
    }
,
(startLine=117 endLine=142 srcPath=/root/NewExperiment/elasticsearchFilter/01739/core/src/test/java/org/elasticsearch/common/inject/ModuleTestCase.java)
    public void assertSetMultiBinding(Module module, Class to, Class... classes) {
        List<Element> elements = Elements.getElements(module);
        Set<Type> bindings = new HashSet<>();
        boolean providerFound = false;
        for (Element element : elements) {
            if (element instanceof LinkedKeyBinding) {
                LinkedKeyBinding binding = (LinkedKeyBinding) element;
                if (to.equals(binding.getKey().getTypeLiteral().getType())) {
                    bindings.add(binding.getLinkedKey().getTypeLiteral().getType());
                }
            } else if (element instanceof ProviderInstanceBinding) {
                ProviderInstanceBinding binding = (ProviderInstanceBinding) element;
                String setType = binding.getKey().getTypeLiteral().getType().toString();
                if (setType.equals("java.util.Set<" + to.getName() + ">")) {
                    providerFound = true;
                }
            }
        }

        for (Class clazz : classes) {
            if (bindings.contains(clazz) == false) {
                fail("Expected to find " + clazz.getName() + " as set binding to " + to.getName() + ", found these classes:\n" + bindings);
            }
        }
        assertTrue("Did not find provider for set of " + to.getName(), providerFound);
    }
,
>
, <(startLine=4868 endLine=4887 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final Fun<? super K, ? extends U> transformer;
            final Action<? super U> action;
            if ((transformer = this.transformer) != null &&
                (action = this.action) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    addToPendingCount(1);
                    new ForEachTransformedKeyTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         transformer, action).fork();
                }
                for (Node<K,V> p; (p = advance()) != null; ) {
                    U u;
                    if ((u = transformer.apply(p.key)) != null)
                        action.apply(u);
                }
                propagateCompletion();
            }
        }
,
(startLine=4901 endLine=4920 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final Fun<? super V, ? extends U> transformer;
            final Action<? super U> action;
            if ((transformer = this.transformer) != null &&
                (action = this.action) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    addToPendingCount(1);
                    new ForEachTransformedValueTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         transformer, action).fork();
                }
                for (Node<K,V> p; (p = advance()) != null; ) {
                    U u;
                    if ((u = transformer.apply(p.val)) != null)
                        action.apply(u);
                }
                propagateCompletion();
            }
        }
,
(startLine=4934 endLine=4953 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final Fun<Map.Entry<K,V>, ? extends U> transformer;
            final Action<? super U> action;
            if ((transformer = this.transformer) != null &&
                (action = this.action) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    addToPendingCount(1);
                    new ForEachTransformedEntryTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         transformer, action).fork();
                }
                for (Node<K,V> p; (p = advance()) != null; ) {
                    U u;
                    if ((u = transformer.apply(p)) != null)
                        action.apply(u);
                }
                propagateCompletion();
            }
        }
,
(startLine=4968 endLine=4987 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final BiFun<? super K, ? super V, ? extends U> transformer;
            final Action<? super U> action;
            if ((transformer = this.transformer) != null &&
                (action = this.action) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    addToPendingCount(1);
                    new ForEachTransformedMappingTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         transformer, action).fork();
                }
                for (Node<K,V> p; (p = advance()) != null; ) {
                    U u;
                    if ((u = transformer.apply(p.key, p.val)) != null)
                        action.apply(u);
                }
                propagateCompletion();
            }
        }
,
>
, <(startLine=39 endLine=60 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortStrings() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<String> fieldValue = new ArrayList<>(numItems);
        List<String> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            String value = randomAlphaOfLengthBetween(1, 10);
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=76 endLine=97 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortIntegers() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<Integer> fieldValue = new ArrayList<>(numItems);
        List<Integer> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            Integer value = randomIntBetween(1, 100);
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=99 endLine=120 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortShorts() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<Short> fieldValue = new ArrayList<>(numItems);
        List<Short> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            Short value = randomShort();
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=122 endLine=143 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortDoubles() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<Double> fieldValue = new ArrayList<>(numItems);
        List<Double> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            Double value = randomDoubleBetween(0.0, 100.0, true);
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=145 endLine=166 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortFloats() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<Float> fieldValue = new ArrayList<>(numItems);
        List<Float> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            Float value = randomFloat();
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=168 endLine=189 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortBytes() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<Byte> fieldValue = new ArrayList<>(numItems);
        List<Byte> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            Byte value = randomByte();
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=191 endLine=212 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortBooleans() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<Boolean> fieldValue = new ArrayList<>(numItems);
        List<Boolean> expectedResult = new ArrayList<>(numItems);
        for (int j = 0; j < numItems; j++) {
            Boolean value = randomBoolean();
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
(startLine=214 endLine=240 srcPath=/root/NewExperiment/elasticsearchFilter/02013/modules/ingest-common/src/test/java/org/elasticsearch/ingest/common/SortProcessorTests.java)
    public void testSortMixedStrings() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        int numItems = randomIntBetween(1, 10);
        List<String> fieldValue = new ArrayList<>(numItems);
        List<String> expectedResult = new ArrayList<>(numItems);
        String value;
        for (int j = 0; j < numItems; j++) {
            if (randomBoolean()) {
                value = String.valueOf(randomIntBetween(0, 100));
            } else {
                value = randomAlphaOfLengthBetween(1, 10);
            }
            fieldValue.add(value);
            expectedResult.add(value);
        }
        Collections.sort(expectedResult);

        SortOrder order = randomBoolean() ? SortOrder.ASCENDING : SortOrder.DESCENDING;
        if (order.equals(SortOrder.DESCENDING)) {
            Collections.reverse(expectedResult);
        }

        String fieldName = RandomDocumentPicks.addRandomField(random(), ingestDocument, fieldValue);
        Processor processor = new SortProcessor(randomAlphaOfLength(10), fieldName, order);
        processor.execute(ingestDocument);
        assertEquals(ingestDocument.getFieldValue(fieldName, List.class), expectedResult);
    }
,
>
, <(startLine=336 endLine=342 srcPath=/root/NewExperiment/elasticsearchFilter/01217/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchTests.java)
        for (int i = 0; i < HEROS.length; i++) {
            client().prepareIndex(INDEX, TYPE, "" + i)
                    .setSource(
                            jsonBuilder().startObject().field("category", Integer.toString(i % 3)).startObject(FIELD).startArray("input")
                                    .value(HEROS[i]).endArray().startObject("context").endObject().field("payload", Integer.toString(i % 3))
                                    .endObject().endObject()).execute().actionGet();
        }
,
(startLine=363 endLine=369 srcPath=/root/NewExperiment/elasticsearchFilter/01217/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchTests.java)
        for (int i = 0; i < HEROS.length; i++) {
            client().prepareIndex(INDEX, TYPE, "" + i)
                    .setSource(
                            jsonBuilder().startObject().startArray("category").value(Integer.toString(i % 3)).value("other").endArray()
                                    .startObject(FIELD).startArray("input").value(HEROS[i]).endArray().startObject("context").endObject()
                                    .field("payload", Integer.toString(i % 3)).endObject().endObject()).execute().actionGet();
        }
,
>
, <(startLine=129 endLine=148 srcPath=/root/NewExperiment/elasticsearchFilter/01770/core/src/test/java/org/elasticsearch/transport/NettyTransportServiceHandshakeTests.java)
    public void testMismatchedClusterName() {
        Settings settings = Settings.EMPTY;

        NetworkHandle handleA = startServices("TS_A", settings, Version.CURRENT, new ClusterName("a"));
        NetworkHandle handleB = startServices("TS_B", settings, Version.CURRENT, new ClusterName("b"));

        try {
            handleA.transportService.connectToNodeLightAndHandshake(
                    new DiscoveryNode(
                            "",
                            handleB.discoveryNode.getAddress(),
                            emptyMap(),
                            emptySet(),
                            Version.CURRENT.minimumCompatibilityVersion()),
                    timeout);
            fail("expected handshake to fail from mismatched cluster names");
        } catch (ConnectTransportException e) {
            assertThat(e.getMessage(), containsString("handshake failed, mismatched cluster name [Cluster [b]]"));
        }
    }
,
(startLine=150 endLine=171 srcPath=/root/NewExperiment/elasticsearchFilter/01770/core/src/test/java/org/elasticsearch/transport/NettyTransportServiceHandshakeTests.java)
    public void testIncompatibleVersions() {
        Settings settings = Settings.EMPTY;

        ClusterName test = new ClusterName("test");
        NetworkHandle handleA = startServices("TS_A", settings, Version.CURRENT, test);
        NetworkHandle handleB =
                startServices("TS_B", settings, VersionUtils.getPreviousVersion(Version.CURRENT.minimumCompatibilityVersion()), test);

        try {
            handleA.transportService.connectToNodeLightAndHandshake(
                    new DiscoveryNode(
                            "",
                            handleB.discoveryNode.getAddress(),
                            emptyMap(),
                            emptySet(),
                            Version.CURRENT.minimumCompatibilityVersion()),
                    timeout);
            fail("expected handshake to fail from incompatible versions");
        } catch (ConnectTransportException e) {
            assertThat(e.getMessage(), containsString("handshake failed, incompatible version"));
        }
    }
,
>
, <(startLine=619 endLine=625 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/HistogramIT.java)
        for (int i = 0; i < numBuckets; i++) {
            Histogram.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            int key = ((2 / interval) + i) * interval;
            assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) key));
            assertThat(bucket.getDocCount(), equalTo(counts[key / interval]));
        }
,
(startLine=700 endLine=706 srcPath=/root/NewExperiment/elasticsearchFilter/01755/core/src/test/java/org/elasticsearch/search/aggregations/bucket/HistogramIT.java)
        for (int i = 0; i < numBuckets; i++) {
            Histogram.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            int key = ((2 / interval) + i) * interval;
            assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) key));
            assertThat(bucket.getDocCount(), equalTo(counts[key / interval]));
        }
,
>
, <(startLine=213 endLine=223 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/CancelAllocationCommand.java)
    public boolean equals(Object obj) {
        if (obj == null || getClass() != obj.getClass()) {
            return false;
        }
        CancelAllocationCommand other = (CancelAllocationCommand) obj;
        // Override equals and hashCode for testing
        return Objects.equals(index, other.index) &&
                Objects.equals(shardId, other.shardId) &&
                Objects.equals(node, other.node) &&
                Objects.equals(allowPrimary, other.allowPrimary);
    }
,
(startLine=201 endLine=211 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/cluster/routing/allocation/command/MoveAllocationCommand.java)
    public boolean equals(Object obj) {
        if (obj == null || getClass() != obj.getClass()) {
            return false;
        }
        MoveAllocationCommand other = (MoveAllocationCommand) obj;
        // Override equals and hashCode for testing
        return Objects.equals(index, other.index) &&
                Objects.equals(shardId, other.shardId) &&
                Objects.equals(fromNode, other.fromNode) &&
                Objects.equals(toNode, other.toNode);
    }
,
>
, <(startLine=55 endLine=94 srcPath=/root/NewExperiment/elasticsearchFilter/00785/src/test/java/org/elasticsearch/test/unit/index/query/plugin/IndexQueryParserPlugin2Tests.java)
    public void testCustomInjection() {
        Settings settings = ImmutableSettings.Builder.EMPTY_SETTINGS;

        IndexQueryParserModule queryParserModule = new IndexQueryParserModule(settings);
        queryParserModule.addQueryParser("my", PluginJsonQueryParser.class);
        queryParserModule.addFilterParser("my", PluginJsonFilterParser.class);

        Index index = new Index("test");
        Injector injector = new ModulesBuilder().add(
                new CodecModule(settings),
                new SettingsModule(settings),
                new ThreadPoolModule(settings),
                new IndicesQueriesModule(),
                new ScriptModule(settings),
                new IndexSettingsModule(index, settings),
                new IndexCacheModule(settings),
                new AnalysisModule(settings),
                new IndexEngineModule(settings),
                new SimilarityModule(settings),
                queryParserModule,
                new IndexNameModule(index),
                new AbstractModule() {
                    @Override
                    protected void configure() {
                        bind(ClusterService.class).toProvider(Providers.of((ClusterService) null));
                    }
                }
        ).createInjector();

        IndexQueryParserService indexQueryParserService = injector.getInstance(IndexQueryParserService.class);

        PluginJsonQueryParser myJsonQueryParser = (PluginJsonQueryParser) indexQueryParserService.queryParser("my");

        assertThat(myJsonQueryParser.names()[0], equalTo("my"));

        PluginJsonFilterParser myJsonFilterParser = (PluginJsonFilterParser) indexQueryParserService.filterParser("my");
        assertThat(myJsonFilterParser.names()[0], equalTo("my"));

        injector.getInstance(ThreadPool.class).shutdownNow();
    }
,
(startLine=55 endLine=103 srcPath=/root/NewExperiment/elasticsearchFilter/00785/src/test/java/org/elasticsearch/test/unit/index/query/plugin/IndexQueryParserPluginTests.java)
    public void testCustomInjection() {
        Settings settings = ImmutableSettings.Builder.EMPTY_SETTINGS;

        IndexQueryParserModule queryParserModule = new IndexQueryParserModule(settings);
        queryParserModule.addProcessor(new IndexQueryParserModule.QueryParsersProcessor() {
            @Override
            public void processXContentQueryParsers(XContentQueryParsersBindings bindings) {
                bindings.processXContentQueryParser("my", PluginJsonQueryParser.class);
            }

            @Override
            public void processXContentFilterParsers(XContentFilterParsersBindings bindings) {
                bindings.processXContentQueryFilter("my", PluginJsonFilterParser.class);
            }
        });

        Index index = new Index("test");
        Injector injector = new ModulesBuilder().add(
                new SettingsModule(settings),
                new ThreadPoolModule(settings),
                new IndicesQueriesModule(),
                new ScriptModule(settings),
                new IndexSettingsModule(index, settings),
                new IndexCacheModule(settings),
                new AnalysisModule(settings),
                new IndexEngineModule(settings),
                new SimilarityModule(settings),
                queryParserModule,
                new IndexNameModule(index),
                new CodecModule(settings),
                new AbstractModule() {
                    @Override
                    protected void configure() {
                        bind(ClusterService.class).toProvider(Providers.of((ClusterService) null));
                    }
                }
        ).createInjector();

        IndexQueryParserService indexQueryParserService = injector.getInstance(IndexQueryParserService.class);

        PluginJsonQueryParser myJsonQueryParser = (PluginJsonQueryParser) indexQueryParserService.queryParser("my");

        assertThat(myJsonQueryParser.names()[0], equalTo("my"));

        PluginJsonFilterParser myJsonFilterParser = (PluginJsonFilterParser) indexQueryParserService.filterParser("my");
        assertThat(myJsonFilterParser.names()[0], equalTo("my"));

        injector.getInstance(ThreadPool.class).shutdownNow();
    }
,
>
, <(startLine=250 endLine=266 srcPath=/root/NewExperiment/elasticsearchFilter/00766/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java)
        public int nextDoc() throws IOException {
            while (true) {
                currentChildDoc = childrenIterator.nextDoc();
                if (currentChildDoc == DocIdSetIterator.NO_MORE_DOCS) {
                    return currentChildDoc;
                }

                BytesReference uid = typeCache.parentIdByDoc(currentChildDoc);
                if (uid == null) {
                    continue;
                }
                currentScore = uidToScore.get(uid);
                if (currentScore != 0) {
                    return currentChildDoc;
                }
            }
        }
,
(startLine=269 endLine=283 srcPath=/root/NewExperiment/elasticsearchFilter/00766/src/main/java/org/elasticsearch/index/search/child/ParentQuery.java)
        public int advance(int target) throws IOException {
            currentChildDoc = childrenIterator.advance(target);
            if (currentChildDoc == DocIdSetIterator.NO_MORE_DOCS) {
                return currentChildDoc;
            }
            BytesReference uid = typeCache.idByDoc(currentChildDoc);
            if (uid == null) {
                return nextDoc();
            }
            currentScore = uidToScore.get(uid);
            if (currentScore == 0) {
                return nextDoc();
            }
            return currentChildDoc;
        }
,
>
, <(startLine=50 endLine=63 srcPath=/root/NewExperiment/elasticsearchFilter/00917/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/ShortValuesComparatorSource.java)
    public FieldComparator<?> newComparator(String fieldname, int numHits, int sortPos, boolean reversed) throws IOException {
        assert fieldname.equals(indexFieldData.getFieldNames().indexName());

        short dMissingValue;
        if (missingValue == null || "_last".equals(missingValue)) {
            dMissingValue = reversed ? Short.MIN_VALUE : Short.MAX_VALUE;
        } else if ("_first".equals(missingValue)) {
            dMissingValue = reversed ? Short.MAX_VALUE : Short.MIN_VALUE;
        } else {
            dMissingValue = missingValue instanceof Number ? ((Number) missingValue).shortValue() : Short.parseShort(missingValue.toString());
        }

        return new ShortValuesComparator(indexFieldData, dMissingValue, numHits, sortMode);
    }
,
(startLine=50 endLine=63 srcPath=/root/NewExperiment/elasticsearchFilter/00917/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/LongValuesComparatorSource.java)
    public FieldComparator<?> newComparator(String fieldname, int numHits, int sortPos, boolean reversed) throws IOException {
        assert fieldname.equals(indexFieldData.getFieldNames().indexName());

        long dMissingValue;
        if (missingValue == null || "_last".equals(missingValue)) {
            dMissingValue = reversed ? Long.MIN_VALUE : Long.MAX_VALUE;
        } else if ("_first".equals(missingValue)) {
            dMissingValue = reversed ? Long.MAX_VALUE : Long.MIN_VALUE;
        } else {
            dMissingValue = missingValue instanceof Number ? ((Number) missingValue).longValue() : Long.parseLong(missingValue.toString());
        }

        return new LongValuesComparator(indexFieldData, dMissingValue, numHits, sortMode);
    }
,
(startLine=50 endLine=63 srcPath=/root/NewExperiment/elasticsearchFilter/00917/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/ByteValuesComparatorSource.java)
    public FieldComparator<?> newComparator(String fieldname, int numHits, int sortPos, boolean reversed) throws IOException {
        assert fieldname.equals(indexFieldData.getFieldNames().indexName());

        byte dMissingValue;
        if (missingValue == null || "_last".equals(missingValue)) {
            dMissingValue = reversed ? Byte.MIN_VALUE : Byte.MAX_VALUE;
        } else if ("_first".equals(missingValue)) {
            dMissingValue = reversed ? Byte.MAX_VALUE : Byte.MIN_VALUE;
        } else {
            dMissingValue = missingValue instanceof Number ? ((Number) missingValue).byteValue() : Byte.parseByte(missingValue.toString());
        }

        return new ByteValuesComparator(indexFieldData, dMissingValue, numHits, sortMode);
    }
,
(startLine=50 endLine=63 srcPath=/root/NewExperiment/elasticsearchFilter/00917/src/main/java/org/elasticsearch/index/fielddata/fieldcomparator/IntValuesComparatorSource.java)
    public FieldComparator<?> newComparator(String fieldname, int numHits, int sortPos, boolean reversed) throws IOException {
        assert fieldname.equals(indexFieldData.getFieldNames().indexName());

        int dMissingValue;
        if (missingValue == null || "_last".equals(missingValue)) {
            dMissingValue = reversed ? Integer.MIN_VALUE : Integer.MAX_VALUE;
        } else if ("_first".equals(missingValue)) {
            dMissingValue = reversed ? Integer.MAX_VALUE : Integer.MIN_VALUE;
        } else {
            dMissingValue = missingValue instanceof Number ? ((Number) missingValue).intValue() : Integer.parseInt(missingValue.toString());
        }

        return new IntValuesComparator(indexFieldData, dMissingValue, numHits, sortMode);
    }
,
>
, <(startLine=220 endLine=373 srcPath=/root/NewExperiment/elasticsearchFilter/00473/modules/elasticsearch/src/main/java/org/elasticsearch/common/compress/bzip2/CBZip2OutputStream.java)
                                            int alphaSize, int maxLen) {
        /*
         * Nodes and heap entries run from 1. Entry 0 for both the heap and
         * nodes is a sentinel.
         */
        final int[] heap = new int[MAX_ALPHA_SIZE * 2];
        final int[] weight = new int[MAX_ALPHA_SIZE * 2];
        final int[] parent = new int[MAX_ALPHA_SIZE * 2];

        for (int i = alphaSize; --i >= 0;) {
            weight[i + 1] = (freq[i] == 0 ? 1 : freq[i]) << 8;
        }

        for (boolean tooLong = true; tooLong;) {
            tooLong = false;

            int nNodes = alphaSize;
            int nHeap = 0;
            heap[0] = 0;
            weight[0] = 0;
            parent[0] = -2;

            for (int i = 1; i <= alphaSize; i++) {
                parent[i] = -1;
                nHeap++;
                heap[nHeap] = i;

                int zz = nHeap;
                int tmp = heap[zz];
                while (weight[tmp] < weight[heap[zz >> 1]]) {
                    heap[zz] = heap[zz >> 1];
                    zz >>= 1;
                }
                heap[zz] = tmp;
            }

            // assert (nHeap < (MAX_ALPHA_SIZE + 2)) : nHeap;

            while (nHeap > 1) {
                int n1 = heap[1];
                heap[1] = heap[nHeap];
                nHeap--;

                int yy = 0;
                int zz = 1;
                int tmp = heap[1];

                while (true) {
                    yy = zz << 1;

                    if (yy > nHeap) {
                        break;
                    }

                    if ((yy < nHeap)
                            && (weight[heap[yy + 1]] < weight[heap[yy]])) {
                        yy++;
                    }

                    if (weight[tmp] < weight[heap[yy]]) {
                        break;
                    }

                    heap[zz] = heap[yy];
                    zz = yy;
                }

                heap[zz] = tmp;

                int n2 = heap[1];
                heap[1] = heap[nHeap];
                nHeap--;

                yy = 0;
                zz = 1;
                tmp = heap[1];

                while (true) {
                    yy = zz << 1;

                    if (yy > nHeap) {
                        break;
                    }

                    if ((yy < nHeap)
                            && (weight[heap[yy + 1]] < weight[heap[yy]])) {
                        yy++;
                    }

                    if (weight[tmp] < weight[heap[yy]]) {
                        break;
                    }

                    heap[zz] = heap[yy];
                    zz = yy;
                }

                heap[zz] = tmp;
                nNodes++;
                parent[n1] = parent[n2] = nNodes;

                final int weight_n1 = weight[n1];
                final int weight_n2 = weight[n2];
                weight[nNodes] = (((weight_n1 & 0xffffff00)
                        + (weight_n2 & 0xffffff00))
                        |
                        (1 + (((weight_n1 & 0x000000ff)
                                > (weight_n2 & 0x000000ff))
                                ? (weight_n1 & 0x000000ff)
                                : (weight_n2 & 0x000000ff))
                        ));

                parent[nNodes] = -1;
                nHeap++;
                heap[nHeap] = nNodes;

                tmp = 0;
                zz = nHeap;
                tmp = heap[zz];
                final int weight_tmp = weight[tmp];
                while (weight_tmp < weight[heap[zz >> 1]]) {
                    heap[zz] = heap[zz >> 1];
                    zz >>= 1;
                }
                heap[zz] = tmp;

            }

            // assert (nNodes < (MAX_ALPHA_SIZE * 2)) : nNodes;

            for (int i = 1; i <= alphaSize; i++) {
                int j = 0;
                int k = i;

                for (int parent_k; (parent_k = parent[k]) >= 0;) {
                    k = parent_k;
                    j++;
                }

                len[i - 1] = (char) j;
                if (j > maxLen) {
                    tooLong = true;
                }
            }

            if (tooLong) {
                for (int i = 1; i < alphaSize; i++) {
                    int j = weight[i] >> 8;
                    j = 1 + (j >> 1);
                    weight[i] = j << 8;
                }
            }
        }
    }
,
(startLine=377 endLine=524 srcPath=/root/NewExperiment/elasticsearchFilter/00473/modules/elasticsearch/src/main/java/org/elasticsearch/common/compress/bzip2/CBZip2OutputStream.java)
                                          final int maxLen) {
        /*
         * Nodes and heap entries run from 1. Entry 0 for both the heap and
         * nodes is a sentinel.
         */
        final int[] heap = dat.heap;
        final int[] weight = dat.weight;
        final int[] parent = dat.parent;

        for (int i = alphaSize; --i >= 0;) {
            weight[i + 1] = (freq[i] == 0 ? 1 : freq[i]) << 8;
        }

        for (boolean tooLong = true; tooLong;) {
            tooLong = false;

            int nNodes = alphaSize;
            int nHeap = 0;
            heap[0] = 0;
            weight[0] = 0;
            parent[0] = -2;

            for (int i = 1; i <= alphaSize; i++) {
                parent[i] = -1;
                nHeap++;
                heap[nHeap] = i;

                int zz = nHeap;
                int tmp = heap[zz];
                while (weight[tmp] < weight[heap[zz >> 1]]) {
                    heap[zz] = heap[zz >> 1];
                    zz >>= 1;
                }
                heap[zz] = tmp;
            }

            while (nHeap > 1) {
                int n1 = heap[1];
                heap[1] = heap[nHeap];
                nHeap--;

                int yy = 0;
                int zz = 1;
                int tmp = heap[1];

                while (true) {
                    yy = zz << 1;

                    if (yy > nHeap) {
                        break;
                    }

                    if ((yy < nHeap)
                            && (weight[heap[yy + 1]] < weight[heap[yy]])) {
                        yy++;
                    }

                    if (weight[tmp] < weight[heap[yy]]) {
                        break;
                    }

                    heap[zz] = heap[yy];
                    zz = yy;
                }

                heap[zz] = tmp;

                int n2 = heap[1];
                heap[1] = heap[nHeap];
                nHeap--;

                yy = 0;
                zz = 1;
                tmp = heap[1];

                while (true) {
                    yy = zz << 1;

                    if (yy > nHeap) {
                        break;
                    }

                    if ((yy < nHeap)
                            && (weight[heap[yy + 1]] < weight[heap[yy]])) {
                        yy++;
                    }

                    if (weight[tmp] < weight[heap[yy]]) {
                        break;
                    }

                    heap[zz] = heap[yy];
                    zz = yy;
                }

                heap[zz] = tmp;
                nNodes++;
                parent[n1] = parent[n2] = nNodes;

                final int weight_n1 = weight[n1];
                final int weight_n2 = weight[n2];
                weight[nNodes] = ((weight_n1 & 0xffffff00)
                        + (weight_n2 & 0xffffff00))
                        | (1 + (((weight_n1 & 0x000000ff)
                        > (weight_n2 & 0x000000ff))
                        ? (weight_n1 & 0x000000ff)
                        : (weight_n2 & 0x000000ff)));

                parent[nNodes] = -1;
                nHeap++;
                heap[nHeap] = nNodes;

                tmp = 0;
                zz = nHeap;
                tmp = heap[zz];
                final int weight_tmp = weight[tmp];
                while (weight_tmp < weight[heap[zz >> 1]]) {
                    heap[zz] = heap[zz >> 1];
                    zz >>= 1;
                }
                heap[zz] = tmp;

            }

            for (int i = 1; i <= alphaSize; i++) {
                int j = 0;
                int k = i;

                for (int parent_k; (parent_k = parent[k]) >= 0;) {
                    k = parent_k;
                    j++;
                }

                len[i - 1] = (byte) j;
                if (j > maxLen) {
                    tooLong = true;
                }
            }

            if (tooLong) {
                for (int i = 1; i < alphaSize; i++) {
                    int j = weight[i] >> 8;
                    j = 1 + (j >> 1);
                    weight[i] = j << 8;
                }
            }
        }
    }
,
>
, <(startLine=154 endLine=164 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/action/admin/cluster/snapshots/SnapshotBlocksIT.java)
    public void testGetSnapshotWithBlocks() {
        // This test checks that the Get Snapshot operation is never blocked, even if the cluster is read only.
        try {
            setClusterReadOnly(true);
            GetSnapshotsResponse response = client().admin().cluster().prepareGetSnapshots(REPOSITORY_NAME).execute().actionGet();
            assertThat(response.getSnapshots(), hasSize(1));
            assertThat(response.getSnapshots().get(0).snapshotId().getName(), equalTo(SNAPSHOT_NAME));
        } finally {
            setClusterReadOnly(false);
        }
    }
,
(startLine=166 endLine=178 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/action/admin/cluster/snapshots/SnapshotBlocksIT.java)
    public void testSnapshotStatusWithBlocks() {
        // This test checks that the Snapshot Status operation is never blocked, even if the cluster is read only.
        try {
            setClusterReadOnly(true);
            SnapshotsStatusResponse response = client().admin().cluster().prepareSnapshotStatus(REPOSITORY_NAME)
                    .setSnapshots(SNAPSHOT_NAME)
                    .execute().actionGet();
            assertThat(response.getSnapshots(), hasSize(1));
            assertThat(response.getSnapshots().get(0).getState().completed(), equalTo(true));
        } finally {
            setClusterReadOnly(false);
        }
    }
,
>
, <(startLine=78 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/00558/src/test/java/org/elasticsearch/index/mapper/dynamic/DynamicMappingTests.java)
    @Test public void testDynamicStrict() throws IOException {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .field("dynamic", "strict")
                .startObject("properties")
                .startObject("field1").field("type", "string").endObject()
                .endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTests.newParser().parse(mapping);

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .field("field1", "value1")
                    .field("field2", "value2")
                    .copiedBytes());
            assert false;
        } catch (StrictDynamicMappingException e) {
            // all is well
        }
    }
,
(startLine=123 endLine=146 srcPath=/root/NewExperiment/elasticsearchFilter/00558/src/test/java/org/elasticsearch/index/mapper/dynamic/DynamicMappingTests.java)
    @Test public void testDynamicStrictWithInnerObjectButDynamicSetOnRoot() throws IOException {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .field("dynamic", "strict")
                .startObject("properties")
                .startObject("obj1").startObject("properties")
                .startObject("field1").field("type", "string").endObject()
                .endObject().endObject()
                .endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTests.newParser().parse(mapping);

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject().startObject("obj1")
                    .field("field1", "value1")
                    .field("field2", "value2")
                    .endObject()
                    .copiedBytes());
            assert false;
        } catch (StrictDynamicMappingException e) {
            // all is well
        }
    }
,
>
, <(startLine=793 endLine=827 srcPath=/root/NewExperiment/elasticsearchFilter/01178/src/main/java/jsr166e/CompletableFuture.java)
                compareAndSet(0, 1)) {
                if (r instanceof AltResult) {
                    ex = ((AltResult)r).ex;
                    t = null;
                }
                else {
                    ex = null;
                    @SuppressWarnings("unchecked") T tr = (T) r;
                    t = tr;
                }
                if (ex != null)
                    u = null;
                else if (s instanceof AltResult) {
                    ex = ((AltResult)s).ex;
                    u = null;
                }
                else {
                    @SuppressWarnings("unchecked") U us = (U) s;
                    u = us;
                }
                Executor e = executor;
                V v = null;
                if (ex == null) {
                    try {
                        if (e != null)
                            e.execute(new AsyncCombine<T,U,V>(t, u, fn, dst));
                        else
                            v = fn.apply(t, u);
                    } catch (Throwable rex) {
                        ex = rex;
                    }
                }
                if (e == null || ex != null)
                    dst.internalComplete(v, ex);
            }
,
(startLine=859 endLine=892 srcPath=/root/NewExperiment/elasticsearchFilter/01178/src/main/java/jsr166e/CompletableFuture.java)
                compareAndSet(0, 1)) {
                if (r instanceof AltResult) {
                    ex = ((AltResult)r).ex;
                    t = null;
                }
                else {
                    ex = null;
                    @SuppressWarnings("unchecked") T tr = (T) r;
                    t = tr;
                }
                if (ex != null)
                    u = null;
                else if (s instanceof AltResult) {
                    ex = ((AltResult)s).ex;
                    u = null;
                }
                else {
                    @SuppressWarnings("unchecked") U us = (U) s;
                    u = us;
                }
                Executor e = executor;
                if (ex == null) {
                    try {
                        if (e != null)
                            e.execute(new AsyncAcceptBoth<T,U>(t, u, fn, dst));
                        else
                            fn.accept(t, u);
                    } catch (Throwable rex) {
                        ex = rex;
                    }
                }
                if (e == null || ex != null)
                    dst.internalComplete(null, ex);
            }
,
(startLine=2040 endLine=2074 srcPath=/root/NewExperiment/elasticsearchFilter/01178/src/main/java/jsr166e/CompletableFuture.java)
        if (r != null && s != null && (d == null || d.compareAndSet(0, 1))) {
            T t; U u; Throwable ex;
            if (r instanceof AltResult) {
                ex = ((AltResult)r).ex;
                t = null;
            }
            else {
                ex = null;
                @SuppressWarnings("unchecked") T tr = (T) r;
                t = tr;
            }
            if (ex != null)
                u = null;
            else if (s instanceof AltResult) {
                ex = ((AltResult)s).ex;
                u = null;
            }
            else {
                @SuppressWarnings("unchecked") U us = (U) s;
                u = us;
            }
            V v = null;
            if (ex == null) {
                try {
                    if (e != null)
                        e.execute(new AsyncCombine<T,U,V>(t, u, fn, dst));
                    else
                        v = fn.apply(t, u);
                } catch (Throwable rex) {
                    ex = rex;
                }
            }
            if (e == null || ex != null)
                dst.internalComplete(v, ex);
        }
,
(startLine=2178 endLine=2211 srcPath=/root/NewExperiment/elasticsearchFilter/01178/src/main/java/jsr166e/CompletableFuture.java)
        if (r != null && s != null && (d == null || d.compareAndSet(0, 1))) {
            T t; U u; Throwable ex;
            if (r instanceof AltResult) {
                ex = ((AltResult)r).ex;
                t = null;
            }
            else {
                ex = null;
                @SuppressWarnings("unchecked") T tr = (T) r;
                t = tr;
            }
            if (ex != null)
                u = null;
            else if (s instanceof AltResult) {
                ex = ((AltResult)s).ex;
                u = null;
            }
            else {
                @SuppressWarnings("unchecked") U us = (U) s;
                u = us;
            }
            if (ex == null) {
                try {
                    if (e != null)
                        e.execute(new AsyncAcceptBoth<T,U>(t, u, fn, dst));
                    else
                        fn.accept(t, u);
                } catch (Throwable rex) {
                    ex = rex;
                }
            }
            if (e == null || ex != null)
                dst.internalComplete(null, ex);
        }
,
>
, <(startLine=5003 endLine=5031 srcPath=/root/NewExperiment/elasticsearchFilter/01317/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final Fun<? super K, ? extends U> searchFunction;
            final AtomicReference<U> result;
            if ((searchFunction = this.searchFunction) != null &&
                (result = this.result) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    if (result.get() != null)
                        return;
                    addToPendingCount(1);
                    new SearchKeysTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         searchFunction, result).fork();
                }
                while (result.get() == null) {
                    U u;
                    Node<K,V> p;
                    if ((p = advance()) == null) {
                        propagateCompletion();
                        break;
                    }
                    if ((u = searchFunction.apply(p.key)) != null) {
                        if (result.compareAndSet(null, u))
                            quietlyCompleteRoot();
                        break;
                    }
                }
            }
        }
,
(startLine=5047 endLine=5075 srcPath=/root/NewExperiment/elasticsearchFilter/01317/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final Fun<? super V, ? extends U> searchFunction;
            final AtomicReference<U> result;
            if ((searchFunction = this.searchFunction) != null &&
                (result = this.result) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    if (result.get() != null)
                        return;
                    addToPendingCount(1);
                    new SearchValuesTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         searchFunction, result).fork();
                }
                while (result.get() == null) {
                    U u;
                    Node<K,V> p;
                    if ((p = advance()) == null) {
                        propagateCompletion();
                        break;
                    }
                    if ((u = searchFunction.apply(p.val)) != null) {
                        if (result.compareAndSet(null, u))
                            quietlyCompleteRoot();
                        break;
                    }
                }
            }
        }
,
(startLine=5091 endLine=5119 srcPath=/root/NewExperiment/elasticsearchFilter/01317/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final Fun<Entry<K,V>, ? extends U> searchFunction;
            final AtomicReference<U> result;
            if ((searchFunction = this.searchFunction) != null &&
                (result = this.result) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    if (result.get() != null)
                        return;
                    addToPendingCount(1);
                    new SearchEntriesTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         searchFunction, result).fork();
                }
                while (result.get() == null) {
                    U u;
                    Node<K,V> p;
                    if ((p = advance()) == null) {
                        propagateCompletion();
                        break;
                    }
                    if ((u = searchFunction.apply(p)) != null) {
                        if (result.compareAndSet(null, u))
                            quietlyCompleteRoot();
                        return;
                    }
                }
            }
        }
,
(startLine=5135 endLine=5163 srcPath=/root/NewExperiment/elasticsearchFilter/01317/src/main/java/jsr166e/ConcurrentHashMapV8.java)
        public final void compute() {
            final BiFun<? super K, ? super V, ? extends U> searchFunction;
            final AtomicReference<U> result;
            if ((searchFunction = this.searchFunction) != null &&
                (result = this.result) != null) {
                for (int i = baseIndex, f, h; batch > 0 &&
                         (h = ((f = baseLimit) + i) >>> 1) > i;) {
                    if (result.get() != null)
                        return;
                    addToPendingCount(1);
                    new SearchMappingsTask<K,V,U>
                        (this, batch >>>= 1, baseLimit = h, f, tab,
                         searchFunction, result).fork();
                }
                while (result.get() == null) {
                    U u;
                    Node<K,V> p;
                    if ((p = advance()) == null) {
                        propagateCompletion();
                        break;
                    }
                    if ((u = searchFunction.apply(p.key, p.val)) != null) {
                        if (result.compareAndSet(null, u))
                            quietlyCompleteRoot();
                        break;
                    }
                }
            }
        }
,
>
, <(startLine=50 endLine=61 srcPath=/root/NewExperiment/elasticsearchFilter/01090/src/main/java/jsr166e/LongMaxUpdater.java)
    public void update(long x) {
        Cell[] as; long b, v; HashCode hc; Cell a; int n;
        if ((as = cells) != null ||
            (b = base) < x && !casBase(b, x)) {
            boolean uncontended = true;
            int h = (hc = threadHashCode.get()).code;
            if (as == null || (n = as.length) < 1 ||
                (a = as[(n - 1) & h]) == null ||
                ((v = a.value) < x && !(uncontended = a.cas(v, x))))
                retryUpdate(x, hc, uncontended);
        }
    }
,
(startLine=58 endLine=71 srcPath=/root/NewExperiment/elasticsearchFilter/01090/src/main/java/jsr166e/DoubleMaxUpdater.java)
    public void update(double x) {
        long lx = Double.doubleToRawLongBits(x);
        Cell[] as; long b, v; HashCode hc; Cell a; int n;
        if ((as = cells) != null ||
            (Double.longBitsToDouble(b = base) < x && !casBase(b, lx))) {
            boolean uncontended = true;
            int h = (hc = threadHashCode.get()).code;
            if (as == null || (n = as.length) < 1 ||
                (a = as[(n - 1) & h]) == null ||
                (Double.longBitsToDouble(v = a.value) < x &&
                 !(uncontended = a.cas(v, lx))))
                retryUpdate(lx, hc, uncontended);
        }
    }
,
(startLine=61 endLine=76 srcPath=/root/NewExperiment/elasticsearchFilter/01090/src/main/java/jsr166e/DoubleAdder.java)
    public void add(double x) {
        Cell[] as; long b, v; HashCode hc; Cell a; int n;
        if ((as = cells) != null ||
            !casBase(b = base,
                     Double.doubleToRawLongBits
                     (Double.longBitsToDouble(b) + x))) {
            boolean uncontended = true;
            int h = (hc = threadHashCode.get()).code;
            if (as == null || (n = as.length) < 1 ||
                (a = as[(n - 1) & h]) == null ||
                !(uncontended = a.cas(v = a.value,
                                      Double.doubleToRawLongBits
                                      (Double.longBitsToDouble(v) + x))))
                retryUpdate(Double.doubleToRawLongBits(x), hc, uncontended);
        }
    }
,
(startLine=57 endLine=67 srcPath=/root/NewExperiment/elasticsearchFilter/01090/src/main/java/jsr166e/LongAdder.java)
    public void add(long x) {
        Cell[] as; long b, v; HashCode hc; Cell a; int n;
        if ((as = cells) != null || !casBase(b = base, b + x)) {
            boolean uncontended = true;
            int h = (hc = threadHashCode.get()).code;
            if (as == null || (n = as.length) < 1 ||
                (a = as[(n - 1) & h]) == null ||
                !(uncontended = a.cas(v = a.value, v + x)))
                retryUpdate(x, hc, uncontended);
        }
    }
,
>
, <(startLine=222 endLine=279 srcPath=/root/NewExperiment/elasticsearchFilter/00132/modules/elasticsearch/src/main/java/org/elasticsearch/util/gnu/trove/TByteHash.java)
    protected int insertionIndex(byte val) {
        int hash, probe, index, length;

        final byte[] states = _states;
        final byte[] set = _set;
        length = states.length;
        hash = _hashingStrategy.computeHashCode(val) & 0x7fffffff;
        index = hash % length;

        if (states[index] == FREE) {
            return index;       // empty, all done
        } else if (states[index] == FULL && set[index] == val) {
            return -index - 1;   // already stored
        } else {                // already FULL or REMOVED, must probe
            // compute the double hash
            probe = 1 + (hash % (length - 2));

            // if the slot we landed on is FULL (but not removed), probe
            // until we find an empty slot, a REMOVED slot, or an element
            // equal to the one we are trying to insert.
            // finding an empty slot means that the value is not present
            // and that we should use that slot as the insertion point;
            // finding a REMOVED slot means that we need to keep searching,
            // however we want to remember the offset of that REMOVED slot
            // so we can reuse it in case a "new" insertion (i.e. not an update)
            // is possible.
            // finding a matching value means that we've found that our desired
            // key is already in the table

            if (states[index] != REMOVED) {
                // starting at the natural offset, probe until we find an
                // offset that isn't full.
                do {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                } while (states[index] == FULL && set[index] != val);
            }

            // if the index we found was removed: continue probing until we
            // locate a free location or an element which equal()s the
            // one we have.
            if (states[index] == REMOVED) {
                int firstRemoved = index;
                while (states[index] != FREE &&
                        (states[index] == REMOVED || set[index] != val)) {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                }
                return states[index] == FULL ? -index - 1 : firstRemoved;
            }
            // if it's full, the key is already stored
            return states[index] == FULL ? -index - 1 : index;
        }
    }
,
(startLine=222 endLine=279 srcPath=/root/NewExperiment/elasticsearchFilter/00132/modules/elasticsearch/src/main/java/org/elasticsearch/util/gnu/trove/TLongHash.java)
    protected int insertionIndex(long val) {
        int hash, probe, index, length;

        final byte[] states = _states;
        final long[] set = _set;
        length = states.length;
        hash = _hashingStrategy.computeHashCode(val) & 0x7fffffff;
        index = hash % length;

        if (states[index] == FREE) {
            return index;       // empty, all done
        } else if (states[index] == FULL && set[index] == val) {
            return -index - 1;   // already stored
        } else {                // already FULL or REMOVED, must probe
            // compute the double hash
            probe = 1 + (hash % (length - 2));

            // if the slot we landed on is FULL (but not removed), probe
            // until we find an empty slot, a REMOVED slot, or an element
            // equal to the one we are trying to insert.
            // finding an empty slot means that the value is not present
            // and that we should use that slot as the insertion point;
            // finding a REMOVED slot means that we need to keep searching,
            // however we want to remember the offset of that REMOVED slot
            // so we can reuse it in case a "new" insertion (i.e. not an update)
            // is possible.
            // finding a matching value means that we've found that our desired
            // key is already in the table

            if (states[index] != REMOVED) {
                // starting at the natural offset, probe until we find an
                // offset that isn't full.
                do {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                } while (states[index] == FULL && set[index] != val);
            }

            // if the index we found was removed: continue probing until we
            // locate a free location or an element which equal()s the
            // one we have.
            if (states[index] == REMOVED) {
                int firstRemoved = index;
                while (states[index] != FREE &&
                        (states[index] == REMOVED || set[index] != val)) {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                }
                return states[index] == FULL ? -index - 1 : firstRemoved;
            }
            // if it's full, the key is already stored
            return states[index] == FULL ? -index - 1 : index;
        }
    }
,
(startLine=222 endLine=279 srcPath=/root/NewExperiment/elasticsearchFilter/00132/modules/elasticsearch/src/main/java/org/elasticsearch/util/gnu/trove/TIntHash.java)
    protected int insertionIndex(int val) {
        int hash, probe, index, length;

        final byte[] states = _states;
        final int[] set = _set;
        length = states.length;
        hash = _hashingStrategy.computeHashCode(val) & 0x7fffffff;
        index = hash % length;

        if (states[index] == FREE) {
            return index;       // empty, all done
        } else if (states[index] == FULL && set[index] == val) {
            return -index - 1;   // already stored
        } else {                // already FULL or REMOVED, must probe
            // compute the double hash
            probe = 1 + (hash % (length - 2));

            // if the slot we landed on is FULL (but not removed), probe
            // until we find an empty slot, a REMOVED slot, or an element
            // equal to the one we are trying to insert.
            // finding an empty slot means that the value is not present
            // and that we should use that slot as the insertion point;
            // finding a REMOVED slot means that we need to keep searching,
            // however we want to remember the offset of that REMOVED slot
            // so we can reuse it in case a "new" insertion (i.e. not an update)
            // is possible.
            // finding a matching value means that we've found that our desired
            // key is already in the table

            if (states[index] != REMOVED) {
                // starting at the natural offset, probe until we find an
                // offset that isn't full.
                do {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                } while (states[index] == FULL && set[index] != val);
            }

            // if the index we found was removed: continue probing until we
            // locate a free location or an element which equal()s the
            // one we have.
            if (states[index] == REMOVED) {
                int firstRemoved = index;
                while (states[index] != FREE &&
                        (states[index] == REMOVED || set[index] != val)) {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                }
                return states[index] == FULL ? -index - 1 : firstRemoved;
            }
            // if it's full, the key is already stored
            return states[index] == FULL ? -index - 1 : index;
        }
    }
,
(startLine=222 endLine=279 srcPath=/root/NewExperiment/elasticsearchFilter/00132/modules/elasticsearch/src/main/java/org/elasticsearch/util/gnu/trove/TDoubleHash.java)
    protected int insertionIndex(double val) {
        int hash, probe, index, length;

        final byte[] states = _states;
        final double[] set = _set;
        length = states.length;
        hash = _hashingStrategy.computeHashCode(val) & 0x7fffffff;
        index = hash % length;

        if (states[index] == FREE) {
            return index;       // empty, all done
        } else if (states[index] == FULL && set[index] == val) {
            return -index - 1;   // already stored
        } else {                // already FULL or REMOVED, must probe
            // compute the double hash
            probe = 1 + (hash % (length - 2));

            // if the slot we landed on is FULL (but not removed), probe
            // until we find an empty slot, a REMOVED slot, or an element
            // equal to the one we are trying to insert.
            // finding an empty slot means that the value is not present
            // and that we should use that slot as the insertion point;
            // finding a REMOVED slot means that we need to keep searching,
            // however we want to remember the offset of that REMOVED slot
            // so we can reuse it in case a "new" insertion (i.e. not an update)
            // is possible.
            // finding a matching value means that we've found that our desired
            // key is already in the table

            if (states[index] != REMOVED) {
                // starting at the natural offset, probe until we find an
                // offset that isn't full.
                do {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                } while (states[index] == FULL && set[index] != val);
            }

            // if the index we found was removed: continue probing until we
            // locate a free location or an element which equal()s the
            // one we have.
            if (states[index] == REMOVED) {
                int firstRemoved = index;
                while (states[index] != FREE &&
                        (states[index] == REMOVED || set[index] != val)) {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                }
                return states[index] == FULL ? -index - 1 : firstRemoved;
            }
            // if it's full, the key is already stored
            return states[index] == FULL ? -index - 1 : index;
        }
    }
,
(startLine=222 endLine=279 srcPath=/root/NewExperiment/elasticsearchFilter/00132/modules/elasticsearch/src/main/java/org/elasticsearch/util/gnu/trove/TShortHash.java)
    protected int insertionIndex(short val) {
        int hash, probe, index, length;

        final byte[] states = _states;
        final short[] set = _set;
        length = states.length;
        hash = _hashingStrategy.computeHashCode(val) & 0x7fffffff;
        index = hash % length;

        if (states[index] == FREE) {
            return index;       // empty, all done
        } else if (states[index] == FULL && set[index] == val) {
            return -index - 1;   // already stored
        } else {                // already FULL or REMOVED, must probe
            // compute the double hash
            probe = 1 + (hash % (length - 2));

            // if the slot we landed on is FULL (but not removed), probe
            // until we find an empty slot, a REMOVED slot, or an element
            // equal to the one we are trying to insert.
            // finding an empty slot means that the value is not present
            // and that we should use that slot as the insertion point;
            // finding a REMOVED slot means that we need to keep searching,
            // however we want to remember the offset of that REMOVED slot
            // so we can reuse it in case a "new" insertion (i.e. not an update)
            // is possible.
            // finding a matching value means that we've found that our desired
            // key is already in the table

            if (states[index] != REMOVED) {
                // starting at the natural offset, probe until we find an
                // offset that isn't full.
                do {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                } while (states[index] == FULL && set[index] != val);
            }

            // if the index we found was removed: continue probing until we
            // locate a free location or an element which equal()s the
            // one we have.
            if (states[index] == REMOVED) {
                int firstRemoved = index;
                while (states[index] != FREE &&
                        (states[index] == REMOVED || set[index] != val)) {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                }
                return states[index] == FULL ? -index - 1 : firstRemoved;
            }
            // if it's full, the key is already stored
            return states[index] == FULL ? -index - 1 : index;
        }
    }
,
(startLine=222 endLine=279 srcPath=/root/NewExperiment/elasticsearchFilter/00132/modules/elasticsearch/src/main/java/org/elasticsearch/util/gnu/trove/TFloatHash.java)
    protected int insertionIndex(float val) {
        int hash, probe, index, length;

        final byte[] states = _states;
        final float[] set = _set;
        length = states.length;
        hash = _hashingStrategy.computeHashCode(val) & 0x7fffffff;
        index = hash % length;

        if (states[index] == FREE) {
            return index;       // empty, all done
        } else if (states[index] == FULL && set[index] == val) {
            return -index - 1;   // already stored
        } else {                // already FULL or REMOVED, must probe
            // compute the double hash
            probe = 1 + (hash % (length - 2));

            // if the slot we landed on is FULL (but not removed), probe
            // until we find an empty slot, a REMOVED slot, or an element
            // equal to the one we are trying to insert.
            // finding an empty slot means that the value is not present
            // and that we should use that slot as the insertion point;
            // finding a REMOVED slot means that we need to keep searching,
            // however we want to remember the offset of that REMOVED slot
            // so we can reuse it in case a "new" insertion (i.e. not an update)
            // is possible.
            // finding a matching value means that we've found that our desired
            // key is already in the table

            if (states[index] != REMOVED) {
                // starting at the natural offset, probe until we find an
                // offset that isn't full.
                do {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                } while (states[index] == FULL && set[index] != val);
            }

            // if the index we found was removed: continue probing until we
            // locate a free location or an element which equal()s the
            // one we have.
            if (states[index] == REMOVED) {
                int firstRemoved = index;
                while (states[index] != FREE &&
                        (states[index] == REMOVED || set[index] != val)) {
                    index -= probe;
                    if (index < 0) {
                        index += length;
                    }
                }
                return states[index] == FULL ? -index - 1 : firstRemoved;
            }
            // if it's full, the key is already stored
            return states[index] == FULL ? -index - 1 : index;
        }
    }
,
>
, <(startLine=70 endLine=77 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/test/java/org/elasticsearch/percolator/PercolatorFacetsAndAggregationsIT.java)
        for (int i = 0; i < numQueries; i++) {
            String value = values[i % numUniqueQueries];
            expectedCount[i % numUniqueQueries]++;
            QueryBuilder queryBuilder = matchQuery("field1", value);
            client().prepareIndex("test", PercolatorService.TYPE_NAME, Integer.toString(i))
                    .setSource(jsonBuilder().startObject().field("query", queryBuilder).field("field2", "b").endObject()).execute()
                    .actionGet();
        }
,
(startLine=133 endLine=140 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/test/java/org/elasticsearch/percolator/PercolatorFacetsAndAggregationsIT.java)
        for (int i = 0; i < numQueries; i++) {
            String value = values[i % numUniqueQueries];
            expectedCount[i % numUniqueQueries]++;
            QueryBuilder queryBuilder = matchQuery("field1", value);
            client().prepareIndex("test", PercolatorService.TYPE_NAME, Integer.toString(i))
                    .setSource(jsonBuilder().startObject().field("query", queryBuilder).field("field2", "b").endObject()).execute()
                    .actionGet();
        }
,
(startLine=211 endLine=218 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/test/java/org/elasticsearch/percolator/PercolatorFacetsAndAggregationsIT.java)
        for (int i = 0; i < numQueries; i++) {
            String value = "value0";
            QueryBuilder queryBuilder = matchQuery("field1", value);
            client().prepareIndex("test", PercolatorService.TYPE_NAME, Integer.toString(i))
                    .setSource(jsonBuilder().startObject().field("query", queryBuilder).field("field2", i % 3 == 0 ? "b" : "a").endObject())
                    .execute()
                    .actionGet();
        }
,
>
, <(startLine=179 endLine=188 srcPath=/root/NewExperiment/elasticsearchFilter/01709/core/src/test/java/org/elasticsearch/stresstest/rollingrestart/RollingRestartStressTest.java)
            try {
                ClusterHealthResponse clusterHealth = client.client().admin().cluster().prepareHealth()
                        .setWaitForGreenStatus()
                        .setWaitForNodes(Integer.toString(numberOfNodes + 0 /* client node*/))
                        .setWaitForRelocatingShards(0)
                        .setTimeout("10m").execute().actionGet();
                if (clusterHealth.isTimedOut()) {
                    logger.warn("timed out waiting for green status....");
                }
            } catch (Exception e) {
,
(startLine=196 endLine=205 srcPath=/root/NewExperiment/elasticsearchFilter/01709/core/src/test/java/org/elasticsearch/stresstest/rollingrestart/RollingRestartStressTest.java)
            try {
                ClusterHealthResponse clusterHealth = client.client().admin().cluster().prepareHealth()
                        .setWaitForGreenStatus()
                        .setWaitForNodes(Integer.toString(numberOfNodes + 1 /* client node*/))
                        .setWaitForRelocatingShards(0)
                        .setTimeout("10m").execute().actionGet();
                if (clusterHealth.isTimedOut()) {
                    logger.warn("timed out waiting for green status....");
                }
            } catch (Exception e) {
,
>
, <(startLine=242 endLine=275 srcPath=/root/NewExperiment/elasticsearchFilter/01273/src/test/java/org/elasticsearch/index/mapper/multifield/MultiFieldsIntegrationTests.java)
    private XContentBuilder createTypeSource() throws IOException {
        if (randomBoolean()) {
            return XContentFactory.jsonBuilder().startObject().startObject("my-type")
                    .startObject("properties")
                    .startObject("title")
                    .field("type", "string")
                    .startObject("fields")
                    .startObject("not_analyzed")
                    .field("type", "string")
                    .field("index", "not_analyzed")
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject().endObject();
        } else {
            return XContentFactory.jsonBuilder().startObject().startObject("my-type")
                    .startObject("properties")
                    .startObject("title")
                    .field("type", "multi_field")
                    .startObject("fields")
                    .startObject("title")
                    .field("type", "string")
                    .endObject()
                    .startObject("not_analyzed")
                    .field("type", "string")
                    .field("index", "not_analyzed")
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject().endObject();
        }
    }
,
(startLine=277 endLine=307 srcPath=/root/NewExperiment/elasticsearchFilter/01273/src/test/java/org/elasticsearch/index/mapper/multifield/MultiFieldsIntegrationTests.java)
    private XContentBuilder createPutMappingSource() throws IOException {
        if (randomBoolean()) {
            return XContentFactory.jsonBuilder().startObject().startObject("my-type")
                    .startObject("properties")
                    .startObject("title")
                    .field("type", "string")
                    .startObject("fields")
                    .startObject("uncased")
                    .field("type", "string")
                    .field("analyzer", "whitespace")
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject().endObject();
        } else {
            return XContentFactory.jsonBuilder().startObject().startObject("my-type")
                    .startObject("properties")
                    .startObject("title")
                    .field("type", "multi_field")
                    .startObject("fields")
                    .startObject("uncased")
                    .field("type", "string")
                    .field("analyzer", "whitespace")
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject()
                    .endObject().endObject();
        }
    }
,
>
, <(startLine=153 endLine=183 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/MinBucketTests.java)
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> minKeys = new ArrayList<>();
            double minValue = Double.POSITIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                if (bucket.getDocCount() < minValue) {
                    minValue = bucket.getDocCount();
                    minKeys = new ArrayList<>();
                    minKeys.add(bucket.getKeyAsString());
                } else if (bucket.getDocCount() == minValue) {
                    minKeys.add(bucket.getKeyAsString());
                }
            }

            InternalBucketMetricValue minBucketValue = termsBucket.getAggregations().get("min_bucket");
            assertThat(minBucketValue, notNullValue());
            assertThat(minBucketValue.getName(), equalTo("min_bucket"));
            assertThat(minBucketValue.value(), equalTo(minValue));
            assertThat(minBucketValue.keys(), equalTo(minKeys.toArray(new String[minKeys.size()])));
        }
,
(startLine=248 endLine=282 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/MinBucketTests.java)
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> minKeys = new ArrayList<>();
            double minValue = Double.POSITIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                if (bucket.getDocCount() != 0) {
                    Sum sum = bucket.getAggregations().get("sum");
                    assertThat(sum, notNullValue());
                    if (sum.value() < minValue) {
                        minValue = sum.value();
                        minKeys = new ArrayList<>();
                        minKeys.add(bucket.getKeyAsString());
                    } else if (sum.value() == minValue) {
                        minKeys.add(bucket.getKeyAsString());
                    }
                }
            }

            InternalBucketMetricValue minBucketValue = termsBucket.getAggregations().get("min_bucket");
            assertThat(minBucketValue, notNullValue());
            assertThat(minBucketValue.getName(), equalTo("min_bucket"));
            assertThat(minBucketValue.value(), equalTo(minValue));
            assertThat(minBucketValue.keys(), equalTo(minKeys.toArray(new String[minKeys.size()])));
        }
,
(startLine=308 endLine=340 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/MinBucketTests.java)
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> minKeys = new ArrayList<>();
            double minValue = Double.POSITIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                Sum sum = bucket.getAggregations().get("sum");
                assertThat(sum, notNullValue());
                if (sum.value() < minValue) {
                    minValue = sum.value();
                    minKeys = new ArrayList<>();
                    minKeys.add(bucket.getKeyAsString());
                } else if (sum.value() == minValue) {
                    minKeys.add(bucket.getKeyAsString());
                }
            }

            InternalBucketMetricValue minBucketValue = termsBucket.getAggregations().get("min_bucket");
            assertThat(minBucketValue, notNullValue());
            assertThat(minBucketValue.getName(), equalTo("min_bucket"));
            assertThat(minBucketValue.value(), equalTo(minValue));
            assertThat(minBucketValue.keys(), equalTo(minKeys.toArray(new String[minKeys.size()])));
        }
,
(startLine=153 endLine=183 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/MaxBucketTests.java)
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> maxKeys = new ArrayList<>();
            double maxValue = Double.NEGATIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                if (bucket.getDocCount() > maxValue) {
                    maxValue = bucket.getDocCount();
                    maxKeys = new ArrayList<>();
                    maxKeys.add(bucket.getKeyAsString());
                } else if (bucket.getDocCount() == maxValue) {
                    maxKeys.add(bucket.getKeyAsString());
                }
            }

            InternalBucketMetricValue maxBucketValue = termsBucket.getAggregations().get("max_bucket");
            assertThat(maxBucketValue, notNullValue());
            assertThat(maxBucketValue.getName(), equalTo("max_bucket"));
            assertThat(maxBucketValue.value(), equalTo(maxValue));
            assertThat(maxBucketValue.keys(), equalTo(maxKeys.toArray(new String[maxKeys.size()])));
        }
,
(startLine=248 endLine=282 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/MaxBucketTests.java)
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> maxKeys = new ArrayList<>();
            double maxValue = Double.NEGATIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                if (bucket.getDocCount() != 0) {
                    Sum sum = bucket.getAggregations().get("sum");
                    assertThat(sum, notNullValue());
                    if (sum.value() > maxValue) {
                        maxValue = sum.value();
                        maxKeys = new ArrayList<>();
                        maxKeys.add(bucket.getKeyAsString());
                    } else if (sum.value() == maxValue) {
                        maxKeys.add(bucket.getKeyAsString());
                    }
                }
            }

            InternalBucketMetricValue maxBucketValue = termsBucket.getAggregations().get("max_bucket");
            assertThat(maxBucketValue, notNullValue());
            assertThat(maxBucketValue.getName(), equalTo("max_bucket"));
            assertThat(maxBucketValue.value(), equalTo(maxValue));
            assertThat(maxBucketValue.keys(), equalTo(maxKeys.toArray(new String[maxKeys.size()])));
        }
,
(startLine=308 endLine=340 srcPath=/root/NewExperiment/elasticsearchFilter/01704/src/test/java/org/elasticsearch/search/aggregations/reducers/MaxBucketTests.java)
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> maxKeys = new ArrayList<>();
            double maxValue = Double.NEGATIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                Sum sum = bucket.getAggregations().get("sum");
                assertThat(sum, notNullValue());
                if (sum.value() > maxValue) {
                    maxValue = sum.value();
                    maxKeys = new ArrayList<>();
                    maxKeys.add(bucket.getKeyAsString());
                } else if (sum.value() == maxValue) {
                    maxKeys.add(bucket.getKeyAsString());
                }
            }

            InternalBucketMetricValue maxBucketValue = termsBucket.getAggregations().get("max_bucket");
            assertThat(maxBucketValue, notNullValue());
            assertThat(maxBucketValue.getName(), equalTo("max_bucket"));
            assertThat(maxBucketValue.value(), equalTo(maxValue));
            assertThat(maxBucketValue.keys(), equalTo(maxKeys.toArray(new String[maxKeys.size()])));
        }
,
>
, <(startLine=74 endLine=129 srcPath=/root/NewExperiment/elasticsearchFilter/01776/core/src/test/java/org/elasticsearch/search/aggregations/bucket/range/BinaryRangeAggregatorTests.java)
    private void doTestSortedSetRangeLeafCollector(int maxNumValuesPerDoc) throws Exception {
        final Set<BytesRef> termSet = new HashSet<>();
        final int numTerms = TestUtil.nextInt(random(), maxNumValuesPerDoc, 100);
        while (termSet.size() < numTerms) {
            termSet.add(new BytesRef(TestUtil.randomSimpleString(random(), randomInt(2))));
        }
        final BytesRef[] terms = termSet.toArray(new BytesRef[0]);
        Arrays.sort(terms);

        final int numRanges = randomIntBetween(1, 10);
        BinaryRangeAggregator.Range[] ranges = new BinaryRangeAggregator.Range[numRanges];
        for (int i = 0; i < numRanges; ++i) {
            ranges[i] = new BinaryRangeAggregator.Range(Integer.toString(i),
                    randomBoolean() ? null : new BytesRef(TestUtil.randomSimpleString(random(), randomInt(2))),
                    randomBoolean() ? null : new BytesRef(TestUtil.randomSimpleString(random(), randomInt(2))));
        }
        Arrays.sort(ranges, BinaryRangeAggregator.RANGE_COMPARATOR);

        FakeSortedSetDocValues values = new FakeSortedSetDocValues(terms);
        final int[] counts = new int[ranges.length];
        SortedSetRangeLeafCollector collector = new SortedSetRangeLeafCollector(values, ranges, null) {
            @Override
            protected void doCollect(LeafBucketCollector sub, int doc, long bucket) throws IOException {
                counts[(int) bucket]++;
            }
        };

        final int[] expectedCounts = new int[ranges.length];
        final int maxDoc = randomIntBetween(5, 10);
        for (int doc = 0; doc < maxDoc; ++doc) {
            LongHashSet ordinalSet = new LongHashSet();
            final int numValues = randomInt(maxNumValuesPerDoc);
            while (ordinalSet.size() < numValues) {
                ordinalSet.add(random().nextInt(terms.length));
            }
            final long[] ords = ordinalSet.toArray();
            Arrays.sort(ords);
            values.ords = ords;

            // simulate aggregation
            collector.collect(doc);

            // now do it the naive way
            for (int i = 0; i < ranges.length; ++i) {
                for (long ord : ords) {
                    BytesRef term = terms[(int) ord];
                    if ((ranges[i].from == null || ranges[i].from.compareTo(term) <= 0)
                            && (ranges[i].to == null || ranges[i].to.compareTo(term) > 0)) {
                        expectedCounts[i]++;
                        break;
                    }
                }
            }
        }
        assertArrayEquals(expectedCounts, counts);
    }
,
(startLine=171 endLine=226 srcPath=/root/NewExperiment/elasticsearchFilter/01776/core/src/test/java/org/elasticsearch/search/aggregations/bucket/range/BinaryRangeAggregatorTests.java)
    private void doTestSortedBinaryRangeLeafCollector(int maxNumValuesPerDoc) throws Exception {
        final Set<BytesRef> termSet = new HashSet<>();
        final int numTerms = TestUtil.nextInt(random(), maxNumValuesPerDoc, 100);
        while (termSet.size() < numTerms) {
            termSet.add(new BytesRef(TestUtil.randomSimpleString(random(), randomInt(2))));
        }
        final BytesRef[] terms = termSet.toArray(new BytesRef[0]);
        Arrays.sort(terms);

        final int numRanges = randomIntBetween(1, 10);
        BinaryRangeAggregator.Range[] ranges = new BinaryRangeAggregator.Range[numRanges];
        for (int i = 0; i < numRanges; ++i) {
            ranges[i] = new BinaryRangeAggregator.Range(Integer.toString(i),
                    randomBoolean() ? null : new BytesRef(TestUtil.randomSimpleString(random(), randomInt(2))),
                    randomBoolean() ? null : new BytesRef(TestUtil.randomSimpleString(random(), randomInt(2))));
        }
        Arrays.sort(ranges, BinaryRangeAggregator.RANGE_COMPARATOR);

        FakeSortedBinaryDocValues values = new FakeSortedBinaryDocValues(terms);
        final int[] counts = new int[ranges.length];
        SortedBinaryRangeLeafCollector collector = new SortedBinaryRangeLeafCollector(values, ranges, null) {
            @Override
            protected void doCollect(LeafBucketCollector sub, int doc, long bucket) throws IOException {
                counts[(int) bucket]++;
            }
        };

        final int[] expectedCounts = new int[ranges.length];
        final int maxDoc = randomIntBetween(5, 10);
        for (int doc = 0; doc < maxDoc; ++doc) {
            LongHashSet ordinalSet = new LongHashSet();
            final int numValues = randomInt(maxNumValuesPerDoc);
            while (ordinalSet.size() < numValues) {
                ordinalSet.add(random().nextInt(terms.length));
            }
            final long[] ords = ordinalSet.toArray();
            Arrays.sort(ords);
            values.ords = ords;

            // simulate aggregation
            collector.collect(doc);

            // now do it the naive way
            for (int i = 0; i < ranges.length; ++i) {
                for (long ord : ords) {
                    BytesRef term = terms[(int) ord];
                    if ((ranges[i].from == null || ranges[i].from.compareTo(term) <= 0)
                            && (ranges[i].to == null || ranges[i].to.compareTo(term) > 0)) {
                        expectedCounts[i]++;
                        break;
                    }
                }
            }
        }
        assertArrayEquals(expectedCounts, counts);
    }
,
>
, <(startLine=65 endLine=93 srcPath=/root/NewExperiment/elasticsearchFilter/01072/src/main/java/org/elasticsearch/index/query/CustomScoreQueryParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                if ("query".equals(currentFieldName)) {
                    query = parseContext.parseInnerQuery();
                    queryOrFilterFound = true;
                } else if ("filter".equals(currentFieldName)) {
                    filter = parseContext.parseInnerFilter();
                    queryOrFilterFound = true;
                } else if ("params".equals(currentFieldName)) {
                    vars = parser.map();
                } else {
                    throw new QueryParsingException(parseContext.index(), "[custom_score] query does not support [" + currentFieldName
                            + "]");
                }
            } else if (token.isValue()) {
                if ("script".equals(currentFieldName)) {
                    script = parser.text();
                } else if ("lang".equals(currentFieldName)) {
                    scriptLang = parser.text();
                } else if ("boost".equals(currentFieldName)) {
                    boost = parser.floatValue();
                } else {
                    throw new QueryParsingException(parseContext.index(), "[custom_score] query does not support [" + currentFieldName
                            + "]");
                }
            }
        }
,
(startLine=60 endLine=81 srcPath=/root/NewExperiment/elasticsearchFilter/01072/src/main/java/org/elasticsearch/index/query/FQueryFilterParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                if ("query".equals(currentFieldName)) {
                    queryFound = true;
                    query = parseContext.parseInnerQuery();
                } else {
                    throw new QueryParsingException(parseContext.index(), "[fquery] filter does not support [" + currentFieldName + "]");
                }
            } else if (token.isValue()) {
                if ("_name".equals(currentFieldName)) {
                    filterName = parser.text();
                } else if ("_cache".equals(currentFieldName)) {
                    cache = parser.booleanValue();
                } else if ("_cache_key".equals(currentFieldName) || "_cacheKey".equals(currentFieldName)) {
                    cacheKey = new CacheKeyFilter.Key(parser.text());
                } else {
                    throw new QueryParsingException(parseContext.index(), "[fquery] filter does not support [" + currentFieldName + "]");
                }
            }
        }
,
(startLine=58 endLine=85 srcPath=/root/NewExperiment/elasticsearchFilter/01072/src/main/java/org/elasticsearch/index/query/NotFilterParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                if ("filter".equals(currentFieldName)) {
                    filter = parseContext.parseInnerFilter();
                    filterFound = true;
                } else {
                    filterFound = true;
                    // its the filter, and the name is the field
                    filter = parseContext.parseInnerFilter(currentFieldName);
                }
            } else if (token == XContentParser.Token.START_ARRAY) {
                filterFound = true;
                // its the filter, and the name is the field
                filter = parseContext.parseInnerFilter(currentFieldName);
            } else if (token.isValue()) {
                if ("_cache".equals(currentFieldName)) {
                    cache = parser.booleanValue();
                } else if ("_name".equals(currentFieldName)) {
                    filterName = parser.text();
                } else if ("_cache_key".equals(currentFieldName) || "_cacheKey".equals(currentFieldName)) {
                    cacheKey = new CacheKeyFilter.Key(parser.text());
                } else {
                    throw new QueryParsingException(parseContext.index(), "[not] filter does not support [" + currentFieldName + "]");
                }
            }
        }
,
(startLine=63 endLine=87 srcPath=/root/NewExperiment/elasticsearchFilter/01072/src/main/java/org/elasticsearch/index/query/ConstantScoreQueryParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.START_OBJECT) {
                if ("filter".equals(currentFieldName)) {
                    filter = parseContext.parseInnerFilter();
                    filterFound = true;
                } else if ("query".equals(currentFieldName)) {
                    query = parseContext.parseInnerQuery();
                    queryFound = true;
                } else {
                    throw new QueryParsingException(parseContext.index(), "[constant_score] query does not support [" + currentFieldName + "]");
                }
            } else if (token.isValue()) {
                if ("boost".equals(currentFieldName)) {
                    boost = parser.floatValue();
                } else if ("_cache".equals(currentFieldName)) {
                    cache = parser.booleanValue();
                } else if ("_cache_key".equals(currentFieldName) || "_cacheKey".equals(currentFieldName)) {
                    cacheKey = new CacheKeyFilter.Key(parser.text());
                } else {
                    throw new QueryParsingException(parseContext.index(), "[constant_score] query does not support [" + currentFieldName + "]");
                }
            }
        }
,
>
, <(startLine=642 endLine=676 srcPath=/root/NewExperiment/elasticsearchFilter/01242/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/RedBlackTree.java)
    private Iterator<IntCursor> iterator(final int startNode) {
        return new UnmodifiableIterator<IntCursor>() {

            boolean nextSet;
            final IntCursor cursor;

            {
                cursor = new IntCursor();
                cursor.index = -1;
                cursor.value = startNode;
                nextSet = cursor.value != NIL;
            }

            boolean computeNext() {
                if (cursor.value != NIL) {
                    cursor.value = RedBlackTree.this.nextNode(cursor.value);
                }
                return nextSet = (cursor.value != NIL);
            }

            @Override
            public boolean hasNext() {
                return nextSet || computeNext();
            }

            @Override
            public IntCursor next() {
                if (!hasNext()) {
                    throw new NoSuchElementException();
                }
                nextSet = false;
                return cursor;
            }
        };
    }
,
(startLine=682 endLine=716 srcPath=/root/NewExperiment/elasticsearchFilter/01242/src/main/java/org/elasticsearch/search/aggregations/metrics/percentiles/tdigest/RedBlackTree.java)
    private Iterator<IntCursor> reverseIterator(final int startNode) {
        return new UnmodifiableIterator<IntCursor>() {

            boolean nextSet;
            final IntCursor cursor;

            {
                cursor = new IntCursor();
                cursor.index = -1;
                cursor.value = startNode;
                nextSet = cursor.value != NIL;
            }

            boolean computeNext() {
                if (cursor.value != NIL) {
                    cursor.value = RedBlackTree.this.prevNode(cursor.value);
                }
                return nextSet = (cursor.value != NIL);
            }

            @Override
            public boolean hasNext() {
                return nextSet || computeNext();
            }

            @Override
            public IntCursor next() {
                if (!hasNext()) {
                    throw new NoSuchElementException();
                }
                nextSet = false;
                return cursor;
            }
        };
    }
,
>
, <(startLine=204 endLine=222 srcPath=/root/NewExperiment/elasticsearchFilter/01766/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/SignificantLongTerms.java)
    protected void doReadFrom(StreamInput in) throws IOException {
        this.formatter = ValueFormatterStreams.readOptional(in);
        this.requiredSize = readSize(in);
        this.minDocCount = in.readVLong();
        this.subsetSize = in.readVLong();
        this.supersetSize = in.readVLong();
        significanceHeuristic = SignificanceHeuristicStreams.read(in);

        int size = in.readVInt();
        List<InternalSignificantTerms.Bucket> buckets = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            Bucket bucket = new Bucket(subsetSize, supersetSize, formatter);
            bucket.readFrom(in);
            buckets.add(bucket);

        }
        this.buckets = buckets;
        this.bucketMap = null;
    }
,
(startLine=194 endLine=209 srcPath=/root/NewExperiment/elasticsearchFilter/01766/core/src/main/java/org/elasticsearch/search/aggregations/bucket/significant/SignificantStringTerms.java)
    protected void doReadFrom(StreamInput in) throws IOException {
        this.requiredSize = readSize(in);
        this.minDocCount = in.readVLong();
        this.subsetSize = in.readVLong();
        this.supersetSize = in.readVLong();
        significanceHeuristic = SignificanceHeuristicStreams.read(in);
        int size = in.readVInt();
        List<InternalSignificantTerms.Bucket> buckets = new ArrayList<>(size);
        for (int i = 0; i < size; i++) {
            Bucket bucket = new Bucket(subsetSize, supersetSize);
            bucket.readFrom(in);
            buckets.add(bucket);
        }
        this.buckets = buckets;
        this.bucketMap = null;
    }
,
>
, <(startLine=269 endLine=283 srcPath=/root/NewExperiment/elasticsearchFilter/01727/core/src/test/java/org/elasticsearch/index/search/child/ChildrenConstantScoreQueryTests.java)
                    for (String id : parentIds) {
                        TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("parent", id));
                        if (seekStatus == TermsEnum.SeekStatus.FOUND) {
                            docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
                            final Bits liveDocs = slowLeafReader.getLiveDocs();
                            for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
                                if (liveDocs == null || liveDocs.get(doc)) {
                                    break;
                                }
                            }
                            expectedResult.set(docsEnum.docID());
                        } else if (seekStatus == TermsEnum.SeekStatus.END) {
                            break;
                        }
                    }
,
(startLine=210 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/01727/core/src/test/java/org/elasticsearch/index/search/child/ParentConstantScoreQueryTests.java)
                    for (String id : childIds) {
                        TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("child", id));
                        if (seekStatus == TermsEnum.SeekStatus.FOUND) {
                            docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
                            final Bits liveDocs = slowLeafReader.getLiveDocs();
                            for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
                                if (liveDocs == null || liveDocs.get(doc)) {
                                    break;
                                }
                            }
                            expectedResult.set(docsEnum.docID());
                        } else if (seekStatus == TermsEnum.SeekStatus.END) {
                            break;
                        }
                    }
,
(startLine=208 endLine=227 srcPath=/root/NewExperiment/elasticsearchFilter/01727/core/src/test/java/org/elasticsearch/index/search/child/ParentQueryTests.java)
                    for (Map.Entry<String, Float> entry : childIdsAndScore.entrySet()) {
                        TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("child", entry.getKey()));
                        if (seekStatus == TermsEnum.SeekStatus.FOUND) {
                            docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
                            final Bits liveDocs = slowLeafReader.getLiveDocs();
                            for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
                                if (liveDocs == null || liveDocs.get(doc)) {
                                    break;
                                }
                            }
                            expectedResult.set(docsEnum.docID());
                            FloatArrayList s = scores[docsEnum.docID()];
                            if (s == null) {
                                scores[docsEnum.docID()] = s = new FloatArrayList(2);
                            }
                            s.add(entry.getValue());
                        } else if (seekStatus == TermsEnum.SeekStatus.END) {
                            break;
                        }
                    }
,
(startLine=230 endLine=248 srcPath=/root/NewExperiment/elasticsearchFilter/01727/core/src/test/java/org/elasticsearch/index/search/child/ChildrenQueryTests.java)
                    for (Map.Entry<String, FloatArrayList> entry : parentIdToChildScores.entrySet()) {
                        int count = entry.getValue().elementsCount;
                        if (count >= minChildren && (maxChildren == 0 || count <= maxChildren)) {
                            TermsEnum.SeekStatus seekStatus = termsEnum.seekCeil(Uid.createUidAsBytes("parent", entry.getKey()));
                            if (seekStatus == TermsEnum.SeekStatus.FOUND) {
                                docsEnum = termsEnum.postings(docsEnum, PostingsEnum.NONE);
                                final Bits liveDocs = slowLeafReader.getLiveDocs();
                                for (int doc = docsEnum.nextDoc(); doc != DocIdSetIterator.NO_MORE_DOCS; doc = docsEnum.nextDoc()) {
                                    if (liveDocs == null || liveDocs.get(doc)) {
                                        break;
                                    }
                                }
                                expectedResult.set(docsEnum.docID());
                                scores[docsEnum.docID()] = new FloatArrayList(entry.getValue());
                            } else if (seekStatus == TermsEnum.SeekStatus.END) {
                                break;
                            }
                        }
                    }
,
>
, <(startLine=156 endLine=206 srcPath=/root/NewExperiment/elasticsearchFilter/00495/modules/elasticsearch/src/test/java/org/elasticsearch/common/lucene/all/SimpleAllTests.java)
    @Test public void testMultipleTokensAllNoBoost() throws Exception {
        Directory dir = new RAMDirectory();
        IndexWriter indexWriter = new IndexWriter(dir, new IndexWriterConfig(Lucene.VERSION, Lucene.STANDARD_ANALYZER));

        Document doc = new Document();
        doc.add(new Field("_id", "1", Field.Store.YES, Field.Index.NO));
        AllEntries allEntries = new AllEntries();
        allEntries.addText("field1", "something moo", 1.0f);
        allEntries.addText("field2", "else koo", 1.0f);
        allEntries.reset();
        doc.add(new Field("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        doc = new Document();
        doc.add(new Field("_id", "2", Field.Store.YES, Field.Index.NO));
        allEntries = new AllEntries();
        allEntries.addText("field1", "else koo", 1.0f);
        allEntries.addText("field2", "something moo", 1.0f);
        allEntries.reset();
        doc.add(new Field("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        IndexReader reader = IndexReader.open(indexWriter, true);
        IndexSearcher searcher = new IndexSearcher(reader);

        TopDocs docs = searcher.search(new AllTermQuery(new Term("_all", "else")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "koo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "something")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "moo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        searcher.close();

        indexWriter.close();
    }
,
(startLine=208 endLine=258 srcPath=/root/NewExperiment/elasticsearchFilter/00495/modules/elasticsearch/src/test/java/org/elasticsearch/common/lucene/all/SimpleAllTests.java)
    @Test public void testMultipleTokensAllWithBoost() throws Exception {
        Directory dir = new RAMDirectory();
        IndexWriter indexWriter = new IndexWriter(dir, new IndexWriterConfig(Lucene.VERSION, Lucene.STANDARD_ANALYZER));

        Document doc = new Document();
        doc.add(new Field("_id", "1", Field.Store.YES, Field.Index.NO));
        AllEntries allEntries = new AllEntries();
        allEntries.addText("field1", "something moo", 1.0f);
        allEntries.addText("field2", "else koo", 1.0f);
        allEntries.reset();
        doc.add(new Field("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        doc = new Document();
        doc.add(new Field("_id", "2", Field.Store.YES, Field.Index.NO));
        allEntries = new AllEntries();
        allEntries.addText("field1", "else koo", 2.0f);
        allEntries.addText("field2", "something moo", 1.0f);
        allEntries.reset();
        doc.add(new Field("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        IndexReader reader = IndexReader.open(indexWriter, true);
        IndexSearcher searcher = new IndexSearcher(reader);

        TopDocs docs = searcher.search(new AllTermQuery(new Term("_all", "else")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(1));
        assertThat(docs.scoreDocs[1].doc, equalTo(0));

        docs = searcher.search(new AllTermQuery(new Term("_all", "koo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(1));
        assertThat(docs.scoreDocs[1].doc, equalTo(0));

        docs = searcher.search(new AllTermQuery(new Term("_all", "something")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "moo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        searcher.close();

        indexWriter.close();
    }
,
>
, <(startLine=221 endLine=269 srcPath=/root/NewExperiment/elasticsearchFilter/01431/src/test/java/org/elasticsearch/common/lucene/all/SimpleAllTests.java)
    public void testMultipleTokensAllNoBoost() throws Exception {
        Directory dir = new RAMDirectory();
        IndexWriter indexWriter = new IndexWriter(dir, new IndexWriterConfig(Lucene.VERSION, Lucene.STANDARD_ANALYZER));

        Document doc = new Document();
        doc.add(new Field("_id", "1", StoredField.TYPE));
        AllEntries allEntries = new AllEntries();
        allEntries.addText("field1", "something moo", 1.0f);
        allEntries.addText("field2", "else koo", 1.0f);
        allEntries.reset();
        doc.add(new TextField("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        doc = new Document();
        doc.add(new Field("_id", "2", StoredField.TYPE));
        allEntries = new AllEntries();
        allEntries.addText("field1", "else koo", 1.0f);
        allEntries.addText("field2", "something moo", 1.0f);
        allEntries.reset();
        doc.add(new TextField("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        IndexReader reader = DirectoryReader.open(indexWriter, true);
        IndexSearcher searcher = new IndexSearcher(reader);

        TopDocs docs = searcher.search(new AllTermQuery(new Term("_all", "else")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "koo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "something")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "moo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        indexWriter.close();
    }
,
(startLine=272 endLine=320 srcPath=/root/NewExperiment/elasticsearchFilter/01431/src/test/java/org/elasticsearch/common/lucene/all/SimpleAllTests.java)
    public void testMultipleTokensAllWithBoost() throws Exception {
        Directory dir = new RAMDirectory();
        IndexWriter indexWriter = new IndexWriter(dir, new IndexWriterConfig(Lucene.VERSION, Lucene.STANDARD_ANALYZER));

        Document doc = new Document();
        doc.add(new Field("_id", "1", StoredField.TYPE));
        AllEntries allEntries = new AllEntries();
        allEntries.addText("field1", "something moo", 1.0f);
        allEntries.addText("field2", "else koo", 1.0f);
        allEntries.reset();
        doc.add(new TextField("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        doc = new Document();
        doc.add(new Field("_id", "2", StoredField.TYPE));
        allEntries = new AllEntries();
        allEntries.addText("field1", "else koo", 2.0f);
        allEntries.addText("field2", "something moo", 1.0f);
        allEntries.reset();
        doc.add(new TextField("_all", AllTokenStream.allTokenStream("_all", allEntries, Lucene.STANDARD_ANALYZER)));

        indexWriter.addDocument(doc);

        IndexReader reader = DirectoryReader.open(indexWriter, true);
        IndexSearcher searcher = new IndexSearcher(reader);

        TopDocs docs = searcher.search(new AllTermQuery(new Term("_all", "else")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(1));
        assertThat(docs.scoreDocs[1].doc, equalTo(0));

        docs = searcher.search(new AllTermQuery(new Term("_all", "koo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(1));
        assertThat(docs.scoreDocs[1].doc, equalTo(0));

        docs = searcher.search(new AllTermQuery(new Term("_all", "something")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        docs = searcher.search(new AllTermQuery(new Term("_all", "moo")), 10);
        assertThat(docs.totalHits, equalTo(2));
        assertThat(docs.scoreDocs[0].doc, equalTo(0));
        assertThat(docs.scoreDocs[1].doc, equalTo(1));

        indexWriter.close();
    }
,
>
, <(startLine=35 endLine=45 srcPath=/root/NewExperiment/elasticsearchFilter/01697/src/test/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactoryTests.java)
    public void testDefault() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder()
                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter")
                .build());
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");
        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";
        String[] expected = new String[]{"Power", "Shot", "500", "42", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil"};
        Tokenizer tokenizer = new WhitespaceTokenizer();
        tokenizer.setReader(new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
(startLine=48 endLine=60 srcPath=/root/NewExperiment/elasticsearchFilter/01697/src/test/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactoryTests.java)
    public void testCatenateWords() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder()
                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter")
                .put("index.analysis.filter.my_word_delimiter.catenate_words", "true")
                .put("index.analysis.filter.my_word_delimiter.generate_word_parts", "false")
                .build());
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");
        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";
        String[] expected = new String[]{"PowerShot", "500", "42", "wifi", "wifi", "4000", "j", "2", "se", "ONeil"};
        Tokenizer tokenizer = new WhitespaceTokenizer();
        tokenizer.setReader(new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
(startLine=63 endLine=75 srcPath=/root/NewExperiment/elasticsearchFilter/01697/src/test/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactoryTests.java)
    public void testCatenateNumbers() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder()
                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter")
                .put("index.analysis.filter.my_word_delimiter.generate_number_parts", "false")
                .put("index.analysis.filter.my_word_delimiter.catenate_numbers", "true")
                .build());
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");
        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";
        String[] expected = new String[]{"Power", "Shot", "50042", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil"};
        Tokenizer tokenizer = new WhitespaceTokenizer();
        tokenizer.setReader(new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
(startLine=78 endLine=91 srcPath=/root/NewExperiment/elasticsearchFilter/01697/src/test/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactoryTests.java)
    public void testCatenateAll() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder()
                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter")
                .put("index.analysis.filter.my_word_delimiter.generate_word_parts", "false")
                .put("index.analysis.filter.my_word_delimiter.generate_number_parts", "false")
                .put("index.analysis.filter.my_word_delimiter.catenate_all", "true")
                .build());
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");
        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";
        String[] expected = new String[]{"PowerShot", "50042", "wifi", "wifi4000", "j2se", "ONeil"};
        Tokenizer tokenizer = new WhitespaceTokenizer();
        tokenizer.setReader(new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
(startLine=108 endLine=119 srcPath=/root/NewExperiment/elasticsearchFilter/01697/src/test/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactoryTests.java)
    public void testPreserveOriginal() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder()
                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter")
                .put("index.analysis.filter.my_word_delimiter.preserve_original", "true")
                .build());
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");
        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";
        String[] expected = new String[]{"PowerShot", "Power", "Shot", "500-42", "500", "42", "wi-fi", "wi", "fi", "wi-fi-4000", "wi", "fi", "4000", "j2se", "j", "2", "se", "O'Neil's", "O", "Neil"};
        Tokenizer tokenizer = new WhitespaceTokenizer();
        tokenizer.setReader(new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
(startLine=122 endLine=133 srcPath=/root/NewExperiment/elasticsearchFilter/01697/src/test/java/org/elasticsearch/index/analysis/WordDelimiterTokenFilterFactoryTests.java)
    public void testStemEnglishPossessive() throws IOException {
        AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settingsBuilder()
                .put("index.analysis.filter.my_word_delimiter.type", "word_delimiter")
                .put("index.analysis.filter.my_word_delimiter.stem_english_possessive", "false")
                .build());
        TokenFilterFactory tokenFilter = analysisService.tokenFilter("my_word_delimiter");
        String source = "PowerShot 500-42 wi-fi wi-fi-4000 j2se O'Neil's";
        String[] expected = new String[]{"Power", "Shot", "500", "42", "wi", "fi", "wi", "fi", "4000", "j", "2", "se", "O", "Neil", "s"};
        Tokenizer tokenizer = new WhitespaceTokenizer();
        tokenizer.setReader(new StringReader(source));
        assertTokenStreamContents(tokenFilter.create(tokenizer), expected);
    }
,
>
, <(startLine=1484 endLine=1496 srcPath=/root/NewExperiment/elasticsearchFilter/01190/src/main/java/jsr166e/ForkJoinPool.java)
            U.compareAndSwapInt(q, QLOCK, 0, 1)) { // lock
            if ((a = q.array) != null &&
                (am = a.length - 1) > (n = (s = q.top) - q.base)) {
                int j = ((am & s) << ASHIFT) + ABASE;
                U.putOrderedObject(a, j, task);
                q.top = s + 1;                     // push on to deque
                q.qlock = 0;
                if (n <= 1)
                    signalWork(ws, q);
                return;
            }
            q.qlock = 0;
        }
,
(startLine=1470 endLine=1482 srcPath=/root/NewExperiment/elasticsearchFilter/01190/src/main/java/jsr166y/ForkJoinPool.java)
            U.compareAndSwapInt(q, QLOCK, 0, 1)) { // lock
            int b = q.base, s = q.top, n, an;
            if ((a = q.array) != null && (an = a.length) > (n = s + 1 - b)) {
                int j = (((an - 1) & s) << ASHIFT) + ABASE;
                U.putOrderedObject(a, j, task);
                q.top = s + 1;                     // push on to deque
                q.qlock = 0;
                if (n <= 2)
                    signalWork(q);
                return;
            }
            q.qlock = 0;
        }
,
>
, <(startLine=619 endLine=638 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/action/IndicesRequestTests.java)
    public void testSearchQueryThenFetch() throws Exception {
        interceptTransportActions(SearchServiceTransportAction.QUERY_ACTION_NAME,
                SearchServiceTransportAction.FETCH_ID_ACTION_NAME, SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);

        String[] randomIndicesOrAliases = randomIndicesOrAliases();
        for (int i = 0; i < randomIndicesOrAliases.length; i++) {
            client().prepareIndex(randomIndicesOrAliases[i], "type", "id-" + i).setSource("field", "value").get();
        }
        refresh();

        SearchRequest searchRequest = new SearchRequest(randomIndicesOrAliases).searchType(SearchType.QUERY_THEN_FETCH);
        SearchResponse searchResponse = internalCluster().clientNodeClient().search(searchRequest).actionGet();
        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), greaterThan(0l));

        clearInterceptedActions();
        assertSameIndices(searchRequest, SearchServiceTransportAction.QUERY_ACTION_NAME, SearchServiceTransportAction.FETCH_ID_ACTION_NAME);
        //free context messages are not necessarily sent, but if they are, check their indices
        assertSameIndicesOptionalRequests(searchRequest, SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);
    }
,
(startLine=641 endLine=661 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/action/IndicesRequestTests.java)
    public void testSearchDfsQueryThenFetch() throws Exception {
        interceptTransportActions(SearchServiceTransportAction.DFS_ACTION_NAME, SearchServiceTransportAction.QUERY_ID_ACTION_NAME,
                SearchServiceTransportAction.FETCH_ID_ACTION_NAME, SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);

        String[] randomIndicesOrAliases = randomIndicesOrAliases();
        for (int i = 0; i < randomIndicesOrAliases.length; i++) {
            client().prepareIndex(randomIndicesOrAliases[i], "type", "id-" + i).setSource("field", "value").get();
        }
        refresh();

        SearchRequest searchRequest = new SearchRequest(randomIndicesOrAliases).searchType(SearchType.DFS_QUERY_THEN_FETCH);
        SearchResponse searchResponse = internalCluster().clientNodeClient().search(searchRequest).actionGet();
        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), greaterThan(0l));

        clearInterceptedActions();
        assertSameIndices(searchRequest, SearchServiceTransportAction.DFS_ACTION_NAME, SearchServiceTransportAction.QUERY_ID_ACTION_NAME,
                SearchServiceTransportAction.FETCH_ID_ACTION_NAME);
        //free context messages are not necessarily sent, but if they are, check their indices
        assertSameIndicesOptionalRequests(searchRequest, SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);
    }
,
(startLine=664 endLine=683 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/action/IndicesRequestTests.java)
    public void testSearchQueryAndFetch() throws Exception {
        interceptTransportActions(SearchServiceTransportAction.QUERY_FETCH_ACTION_NAME,
                SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);

        String[] randomIndicesOrAliases = randomIndicesOrAliases();
        for (int i = 0; i < randomIndicesOrAliases.length; i++) {
            client().prepareIndex(randomIndicesOrAliases[i], "type", "id-" + i).setSource("field", "value").get();
        }
        refresh();

        SearchRequest searchRequest = new SearchRequest(randomIndicesOrAliases).searchType(SearchType.QUERY_AND_FETCH);
        SearchResponse searchResponse = internalCluster().clientNodeClient().search(searchRequest).actionGet();
        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), greaterThan(0l));

        clearInterceptedActions();
        assertSameIndices(searchRequest, SearchServiceTransportAction.QUERY_FETCH_ACTION_NAME);
        //free context messages are not necessarily sent, but if they are, check their indices
        assertSameIndicesOptionalRequests(searchRequest, SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);
    }
,
(startLine=686 endLine=705 srcPath=/root/NewExperiment/elasticsearchFilter/01708/core/src/test/java/org/elasticsearch/action/IndicesRequestTests.java)
    public void testSearchDfsQueryAndFetch() throws Exception {
        interceptTransportActions(SearchServiceTransportAction.QUERY_QUERY_FETCH_ACTION_NAME,
                SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);

        String[] randomIndicesOrAliases = randomIndicesOrAliases();
        for (int i = 0; i < randomIndicesOrAliases.length; i++) {
            client().prepareIndex(randomIndicesOrAliases[i], "type", "id-" + i).setSource("field", "value").get();
        }
        refresh();

        SearchRequest searchRequest = new SearchRequest(randomIndicesOrAliases).searchType(SearchType.DFS_QUERY_AND_FETCH);
        SearchResponse searchResponse = internalCluster().clientNodeClient().search(searchRequest).actionGet();
        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), greaterThan(0l));

        clearInterceptedActions();
        assertSameIndices(searchRequest, SearchServiceTransportAction.QUERY_QUERY_FETCH_ACTION_NAME);
        //free context messages are not necessarily sent, but if they are, check their indices
        assertSameIndicesOptionalRequests(searchRequest, SearchServiceTransportAction.FREE_CONTEXT_ACTION_NAME);
    }
,
>
, <(startLine=176 endLine=221 srcPath=/root/NewExperiment/elasticsearchFilter/00671/src/main/java/org/elasticsearch/index/query/MatchQueryBuilder.java)
    public void doXContent(XContentBuilder builder, Params params) throws IOException {
        builder.startObject(MatchQueryParser.NAME);
        builder.startObject(name);

        builder.field("query", text);
        if (type != null) {
            builder.field("type", type.toString().toLowerCase(Locale.ENGLISH));
        }
        if (operator != null) {
            builder.field("operator", operator.toString());
        }
        if (analyzer != null) {
            builder.field("analyzer", analyzer);
        }
        if (boost != null) {
            builder.field("boost", boost);
        }
        if (slop != null) {
            builder.field("slop", slop);
        }
        if (fuzziness != null) {
            builder.field("fuzziness", fuzziness);
        }
        if (prefixLength != null) {
            builder.field("prefix_length", prefixLength);
        }
        if (maxExpansions != null) {
            builder.field("max_expansions", maxExpansions);
        }
        if (minimumShouldMatch != null) {
            builder.field("minimum_should_match", minimumShouldMatch);
        }
        if (rewrite != null) {
            builder.field("rewrite", rewrite);
        }
        if (fuzzyRewrite != null) {
            builder.field("fuzzy_rewrite", fuzzyRewrite);
        }

        if (lenient != null) {
            builder.field("lenient", lenient);
        }

        builder.endObject();
        builder.endObject();
    }
,
(startLine=171 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00671/src/main/java/org/elasticsearch/index/query/MultiMatchQueryBuilder.java)
    public void doXContent(XContentBuilder builder, Params params) throws IOException {
        builder.startObject(MultiMatchQueryParser.NAME);

        builder.field("query", text);
        builder.field("fields", fields);

        if (type != null) {
            builder.field("type", type.toString().toLowerCase(Locale.ENGLISH));
        }
        if (operator != null) {
            builder.field("operator", operator.toString());
        }
        if (analyzer != null) {
            builder.field("analyzer", analyzer);
        }
        if (boost != null) {
            builder.field("boost", boost);
        }
        if (slop != null) {
            builder.field("slop", slop);
        }
        if (fuzziness != null) {
            builder.field("fuzziness", fuzziness);
        }
        if (prefixLength != null) {
            builder.field("prefix_length", prefixLength);
        }
        if (maxExpansions != null) {
            builder.field("max_expansions", maxExpansions);
        }
        if (minimumShouldMatch != null) {
            builder.field("minimum_should_match", minimumShouldMatch);
        }
        if (rewrite != null) {
            builder.field("rewrite", rewrite);
        }
        if (fuzzyRewrite != null) {
            builder.field("fuzzy_rewrite", fuzzyRewrite);
        }

        if (useDisMax != null) {
            builder.field("use_dis_max", useDisMax);
        }

        if (tieBreaker != null) {
            builder.field("tie_breaker", tieBreaker);
        }

        if (lenient != null) {
            builder.field("lenient", lenient);
        }

        builder.endObject();
    }
,
>
, <(startLine=2344 endLine=2354 srcPath=/root/NewExperiment/elasticsearchFilter/01594/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    public void testBadTypeMatchQuery() throws Exception {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/match-query-bad-type.json");
        QueryParsingException expectedException = null;
        try {
            queryParser.parse(query).query();
        } catch (QueryParsingException qpe) {
            expectedException = qpe;
        }
        assertThat(expectedException, notNullValue());
    }
,
(startLine=2365 endLine=2375 srcPath=/root/NewExperiment/elasticsearchFilter/01594/src/test/java/org/elasticsearch/index/query/SimpleIndexQueryParserTests.java)
    public void testBadTypeMultiMatchQuery() throws Exception {
        IndexQueryParserService queryParser = queryParser();
        String query = copyToStringFromClasspath("/org/elasticsearch/index/query/multiMatch-query-bad-type.json");
        QueryParsingException expectedException = null;
        try {
            queryParser.parse(query).query();
        } catch (QueryParsingException qpe) {
            expectedException = qpe;
        }
        assertThat(expectedException, notNullValue());
    }
,
>
, <(startLine=148 endLine=156 srcPath=/root/NewExperiment/elasticsearchFilter/01005/src/main/java/org/elasticsearch/action/deletebyquery/TransportShardDeleteByQueryAction.java)
    protected ShardIterator shards(ClusterState clusterState, ShardDeleteByQueryRequest request) {
        GroupShardsIterator group = clusterService.operationRouting().deleteByQueryShards(clusterService.state(), request.index(), request.routing());
        for (ShardIterator shardIt : group) {
            if (shardIt.shardId().id() == request.shardId()) {
                return shardIt;
            }
        }
        throw new ElasticSearchIllegalStateException("No shards iterator found for shard [" + request.shardId() + "]");
    }
,
(startLine=133 endLine=141 srcPath=/root/NewExperiment/elasticsearchFilter/01005/src/main/java/org/elasticsearch/action/delete/index/TransportShardDeleteAction.java)
    protected ShardIterator shards(ClusterState clusterState, ShardDeleteRequest request) {
        GroupShardsIterator group = clusterService.operationRouting().broadcastDeleteShards(clusterService.state(), request.index());
        for (ShardIterator shardIt : group) {
            if (shardIt.shardId().id() == request.shardId()) {
                return shardIt;
            }
        }
        throw new ElasticSearchIllegalStateException("No shards iterator found for shard [" + request.shardId() + "]");
    }
,
>
, <(startLine=61 endLine=88 srcPath=/root/NewExperiment/elasticsearchFilter/00921/src/main/java/org/elasticsearch/action/search/TransportMultiSearchAction.java)
        for (int i = 0; i < responses.length; i++) {
            final int index = i;
            searchAction.execute(request.requests().get(i), new ActionListener<SearchResponse>() {
                @Override
                public void onResponse(SearchResponse searchResponse) {
                    synchronized (responses) {
                        responses[index] = new MultiSearchResponse.Item(searchResponse, null);
                    }
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }

                @Override
                public void onFailure(Throwable e) {
                    synchronized (responses) {
                        responses[index] = new MultiSearchResponse.Item(null, ExceptionsHelper.detailedMessage(e));
                    }
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }

                private void finishHim() {
                    listener.onResponse(new MultiSearchResponse(responses));
                }
            });
        }
,
(startLine=41 endLine=68 srcPath=/root/NewExperiment/elasticsearchFilter/00921/src/main/java/org/elasticsearch/action/percolate/TransportMultiPercolateAction.java)
        for (int i = 0; i < responses.length; i++) {
            final int index = i;
            percolateAction.execute(request.requests().get(i), new ActionListener<PercolateResponse>() {
                @Override
                public void onResponse(PercolateResponse percolateResponse) {
                    synchronized (responses) {
                        responses[index] = new MultiPercolateResponse.Item(percolateResponse, null);
                    }
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }

                @Override
                public void onFailure(Throwable e) {
                    synchronized (responses) {
                        responses[index] = new MultiPercolateResponse.Item(null, ExceptionsHelper.detailedMessage(e));
                    }
                    if (counter.decrementAndGet() == 0) {
                        finishHim();
                    }
                }

                private void finishHim() {
                    listener.onResponse(new MultiPercolateResponse(responses));
                }
            });
        }
,
>
, <(startLine=251 endLine=274 srcPath=/root/NewExperiment/elasticsearchFilter/00099/modules/elasticsearch/src/main/java/org/elasticsearch/util/gcommon/collect/AbstractMultiset.java)
  @Override public boolean equals(@Nullable Object object) {
    if (object == this) {
      return true;
    }
    if (object instanceof Multiset) {
      Multiset<?> that = (Multiset<?>) object;
      /*
       * We can't simply check whether the entry sets are equal, since that
       * approach fails when a TreeMultiset has a comparator that returns 0
       * when passed unequal elements.
       */

      if (this.size() != that.size()) {
        return false;
      }
      for (Entry<?> entry : that.entrySet()) {
        if (count(entry.getElement()) != entry.getCount()) {
          return false;
        }
      }
      return true;
    }
    return false;
  }
,
(startLine=237 endLine=254 srcPath=/root/NewExperiment/elasticsearchFilter/00099/modules/elasticsearch/src/main/java/org/elasticsearch/util/gcommon/collect/ImmutableMultiset.java)
  @Override public boolean equals(@Nullable Object object) {
    if (object == this) {
      return true;
    }
    if (object instanceof Multiset) {
      Multiset<?> that = (Multiset<?>) object;
      if (this.size() != that.size()) {
        return false;
      }
      for (Entry<?> entry : that.entrySet()) {
        if (count(entry.getElement()) != entry.getCount()) {
          return false;
        }
      }
      return true;
    }
    return false;
  }
,
>
, <(startLine=97 endLine=140 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void inlineScript() {

        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPaths("field2Sum", "field3Sum", "field4Sum").script(
                                                new Script("_value0 + _value1 + _value2", ScriptType.INLINE, null, null)))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, nullValue());
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(field2SumValue + field3SumValue + field4SumValue));
            }
        }
    }
,
(startLine=143 endLine=186 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void inlineScript2() {

        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPaths("field2Sum", "field3Sum", "field4Sum").script(
                                                new Script("_value0 + _value1 / _value2", ScriptType.INLINE, null, null)))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, nullValue());
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(field2SumValue + field3SumValue / field4SumValue));
            }
        }
    }
,
(startLine=227 endLine=274 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void inlineScriptNamedVars() {

        Map<String, String> bucketsPathsMap = new HashMap<>();
        bucketsPathsMap.put("foo", "field2Sum");
        bucketsPathsMap.put("bar", "field3Sum");
        bucketsPathsMap.put("baz", "field4Sum");
        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPathsMap(bucketsPathsMap ).script(
                                                new Script("foo + bar + baz", ScriptType.INLINE, null, null)))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, nullValue());
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(field2SumValue + field3SumValue + field4SumValue));
            }
        }
    }
,
(startLine=277 endLine=322 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void inlineScriptWithParams() {

        Map<String, Object> params = new HashMap<>();
        params.put("factor", 3);
        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPaths("field2Sum", "field3Sum", "field4Sum").script(
                                                new Script("(_value0 + _value1 + _value2) * factor", ScriptType.INLINE, null, params)))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, nullValue());
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo((field2SumValue + field3SumValue + field4SumValue) * 3));
            }
        }
    }
,
(startLine=325 endLine=370 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void inlineScriptInsertZeros() {

        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPaths("field2Sum", "field3Sum", "field4Sum").script(
                                                new Script("_value0 + _value1 + _value2", ScriptType.INLINE, null, null)).gapPolicy(GapPolicy.INSERT_ZEROS))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(0.0));
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(field2SumValue + field3SumValue + field4SumValue));
            }
        }
    }
,
(startLine=373 endLine=416 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void indexedScript() {

        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPaths("field2Sum", "field3Sum", "field4Sum").script(
                                                new Script("my_script", ScriptType.INDEXED, null, null)))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, nullValue());
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(field2SumValue + field3SumValue + field4SumValue));
            }
        }
    }
,
(startLine=443 endLine=485 srcPath=/root/NewExperiment/elasticsearchFilter/01713/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketScriptTests.java)
    public void partiallyUnmapped() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx", "idx_unmapped")
                .addAggregation(
                        histogram("histo")
                                .field(FIELD_1_NAME)
                                .interval(interval)
                                .subAggregation(sum("field2Sum").field(FIELD_2_NAME))
                                .subAggregation(sum("field3Sum").field(FIELD_3_NAME))
                                .subAggregation(sum("field4Sum").field(FIELD_4_NAME))
                                .subAggregation(
                                        bucketScript("seriesArithmetic").setBucketsPaths("field2Sum", "field3Sum", "field4Sum").script(
                                                new Script("_value0 + _value1 + _value2", ScriptType.INLINE, null, null)))).execute().actionGet();

        assertSearchResponse(response);

        InternalHistogram<Bucket> histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();

        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            if (bucket.getDocCount() == 0) {
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, nullValue());
            } else {
                Sum field2Sum = bucket.getAggregations().get("field2Sum");
                assertThat(field2Sum, notNullValue());
                double field2SumValue = field2Sum.getValue();
                Sum field3Sum = bucket.getAggregations().get("field3Sum");
                assertThat(field3Sum, notNullValue());
                double field3SumValue = field3Sum.getValue();
                Sum field4Sum = bucket.getAggregations().get("field4Sum");
                assertThat(field4Sum, notNullValue());
                double field4SumValue = field4Sum.getValue();
                SimpleValue seriesArithmetic = bucket.getAggregations().get("seriesArithmetic");
                assertThat(seriesArithmetic, notNullValue());
                double seriesArithmeticValue = seriesArithmetic.value();
                assertThat(seriesArithmeticValue, equalTo(field2SumValue + field3SumValue + field4SumValue));
            }
        }
    }
,
>
, <(startLine=634 endLine=648 srcPath=/root/NewExperiment/elasticsearchFilter/00485/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java)
                if (numberType == XContentParser.NumberType.INT) {
                    if (context.parser().estimatedNumberType()) {
                        Mapper.Builder builder = context.root().findTemplateBuilder(context, currentFieldName, "long");
                        if (builder == null) {
                            builder = longField(currentFieldName);
                        }
                        mapper = builder.build(builderContext);
                    } else {
                        Mapper.Builder builder = context.root().findTemplateBuilder(context, currentFieldName, "integer");
                        if (builder == null) {
                            builder = integerField(currentFieldName);
                        }
                        mapper = builder.build(builderContext);
                    }
                } else if (numberType == XContentParser.NumberType.LONG) {
,
(startLine=654 endLine=668 srcPath=/root/NewExperiment/elasticsearchFilter/00485/modules/elasticsearch/src/main/java/org/elasticsearch/index/mapper/object/ObjectMapper.java)
                } else if (numberType == XContentParser.NumberType.FLOAT) {
                    if (context.parser().estimatedNumberType()) {
                        Mapper.Builder builder = context.root().findTemplateBuilder(context, currentFieldName, "double");
                        if (builder == null) {
                            builder = doubleField(currentFieldName);
                        }
                        mapper = builder.build(builderContext);
                    } else {
                        Mapper.Builder builder = context.root().findTemplateBuilder(context, currentFieldName, "float");
                        if (builder == null) {
                            builder = floatField(currentFieldName);
                        }
                        mapper = builder.build(builderContext);
                    }
                } else if (numberType == XContentParser.NumberType.DOUBLE) {
,
>
, <(startLine=74 endLine=131 srcPath=/root/NewExperiment/elasticsearchFilter/00652/src/test/java/org/elasticsearch/test/unit/index/mapper/geopoint/LatLonMappingGeoPointTests.java)
    public void testValidateLatLonValues() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties").startObject("point").field("type", "geo_point").field("lat_lon", true).field("normalize", false).field("validate", true).endObject().endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTests.newParser().parse(mapping);


        ParsedDocument doc = defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 90).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", -91).field("lon", 1.3).endObject()
                    .endObject()
                    .bytes());
            assert false;
        } catch (ElasticSearchIllegalArgumentException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 91).field("lon", 1.3).endObject()
                    .endObject()
                    .bytes());
            assert false;
        } catch (ElasticSearchIllegalArgumentException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 1.2).field("lon", -181).endObject()
                    .endObject()
                    .bytes());
            assert false;
        } catch (ElasticSearchIllegalArgumentException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 1.2).field("lon", 181).endObject()
                    .endObject()
                    .bytes());
            assert false;
        } catch (ElasticSearchIllegalArgumentException e) {

        }
    }
,
(startLine=135 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/00652/src/test/java/org/elasticsearch/test/unit/index/mapper/geopoint/LatLonMappingGeoPointTests.java)
    public void testNoValidateLatLonValues() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties").startObject("point").field("type", "geo_point").field("lat_lon", true).field("normalize", false).field("validate", false).endObject().endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTests.newParser().parse(mapping);


        ParsedDocument doc = defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 90).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", -91).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 91).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 1.2).field("lon", -181).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 1.2).field("lon", 181).endObject()
                .endObject()
                .bytes());
    }
,
>
, <(startLine=152 endLine=166 srcPath=/root/NewExperiment/elasticsearchFilter/00385/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java)
    public DfsSearchResult executeDfsPhase(InternalSearchRequest request) throws ElasticSearchException {
        SearchContext context = createContext(request);
        activeContexts.put(context.id(), context);
        try {
            contextProcessing(context);
            dfsPhase.execute(context);
            contextProcessedSuccessfully(context);
            return context.dfsResult();
        } catch (RuntimeException e) {
            freeContext(context);
            throw e;
        } finally {
            cleanContext(context);
        }
    }
,
(startLine=168 endLine=182 srcPath=/root/NewExperiment/elasticsearchFilter/00385/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java)
    public QuerySearchResult executeQueryPhase(InternalSearchRequest request) throws ElasticSearchException {
        SearchContext context = createContext(request);
        activeContexts.put(context.id(), context);
        try {
            contextProcessing(context);
            queryPhase.execute(context);
            contextProcessedSuccessfully(context);
            return context.queryResult();
        } catch (RuntimeException e) {
            freeContext(context);
            throw e;
        } finally {
            cleanContext(context);
        }
    }
,
(startLine=184 endLine=198 srcPath=/root/NewExperiment/elasticsearchFilter/00385/modules/elasticsearch/src/main/java/org/elasticsearch/search/SearchService.java)
    public ScrollQuerySearchResult executeQueryPhase(InternalScrollSearchRequest request) throws ElasticSearchException {
        SearchContext context = findContext(request.id());
        try {
            contextProcessing(context);
            processScroll(request, context);
            contextProcessedSuccessfully(context);
            queryPhase.execute(context);
            return new ScrollQuerySearchResult(context.queryResult(), context.shardTarget());
        } catch (RuntimeException e) {
            freeContext(context);
            throw e;
        } finally {
            cleanContext(context);
        }
    }
,
>
, <(startLine=83 endLine=97 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EBool.java)
        if (operation == Operation.AND) {
            Label fals = new Label();
            Label end = new Label();

            left.write(writer, globals);
            writer.ifZCmp(Opcodes.IFEQ, fals);
            right.write(writer, globals);
            writer.ifZCmp(Opcodes.IFEQ, fals);

            writer.push(true);
            writer.goTo(end);
            writer.mark(fals);
            writer.push(false);
            writer.mark(end);
        } else if (operation == Operation.OR) {
,
(startLine=97 endLine=113 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EBool.java)
        } else if (operation == Operation.OR) {
            Label tru = new Label();
            Label fals = new Label();
            Label end = new Label();

            left.write(writer, globals);
            writer.ifZCmp(Opcodes.IFNE, tru);
            right.write(writer, globals);
            writer.ifZCmp(Opcodes.IFEQ, fals);

            writer.mark(tru);
            writer.push(true);
            writer.goTo(end);
            writer.mark(fals);
            writer.push(false);
            writer.mark(end);
        } else {
,
>
, <(startLine=55 endLine=65 srcPath=/root/NewExperiment/elasticsearchFilter/01436/src/main/java/org/elasticsearch/river/RiverName.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        RiverName that = (RiverName) o;

        if (name != null ? !name.equals(that.name) : that.name != null) return false;
        if (type != null ? !type.equals(that.type) : that.type != null) return false;

        return true;
    }
,
(startLine=53 endLine=63 srcPath=/root/NewExperiment/elasticsearchFilter/01436/src/main/java/org/elasticsearch/repositories/RepositoryName.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        RepositoryName that = (RepositoryName) o;

        if (name != null ? !name.equals(that.name) : that.name != null) return false;
        if (type != null ? !type.equals(that.type) : that.type != null) return false;

        return true;
    }
,
>
, <(startLine=253 endLine=268 srcPath=/root/NewExperiment/elasticsearchFilter/00548/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchDfsQueryThenFetchAction.java)
        void finishHim() {
            try {
                innerFinishHim();
            } catch (Exception e) {
                ReduceSearchPhaseException failure = new ReduceSearchPhaseException("fetch", "", e, buildShardFailures());
                if (logger.isDebugEnabled()) {
                    logger.debug("failed to reduce search", failure);
                }
                listener.onFailure(failure);
            } finally {
                releaseIrrelevantSearchContexts(queryResults, docIdsToLoad);
                searchCache.releaseDfsResults(dfsResults);
                searchCache.releaseQueryResults(queryResults);
                searchCache.releaseFetchResults(fetchResults);
            }
        }
,
(startLine=205 endLine=217 srcPath=/root/NewExperiment/elasticsearchFilter/00548/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchScrollScanAction.java)
        private void finishHim() {
            try {
                innerFinishHim();
            } catch (Exception e) {
                ReduceSearchPhaseException failure = new ReduceSearchPhaseException("fetch", "", e, buildShardFailures(shardFailures, searchCache));
                if (logger.isDebugEnabled()) {
                    logger.debug("failed to reduce search", failure);
                }
                listener.onFailure(failure);
            } finally {
                searchCache.releaseQueryFetchResults(queryFetchResults);
            }
        }
,
(startLine=159 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/00548/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchDfsQueryAndFetchAction.java)
        void finishHim() {
            try {
                innerFinishHim();
            } catch (Exception e) {
                ReduceSearchPhaseException failure = new ReduceSearchPhaseException("query_fetch", "", e, buildShardFailures());
                if (logger.isDebugEnabled()) {
                    logger.debug("failed to reduce search", failure);
                }
                listener.onFailure(failure);
            } finally {
                searchCache.releaseDfsResults(dfsResults);
                searchCache.releaseQueryFetchResults(queryFetchResults);
            }
        }
,
(startLine=167 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/00548/modules/elasticsearch/src/main/java/org/elasticsearch/action/search/type/TransportSearchQueryThenFetchAction.java)
        void finishHim() {
            try {
                innerFinishHim();
            } catch (Exception e) {
                ReduceSearchPhaseException failure = new ReduceSearchPhaseException("fetch", "", e, buildShardFailures());
                if (logger.isDebugEnabled()) {
                    logger.debug("failed to reduce search", failure);
                }
                listener.onFailure(failure);
            } finally {
                releaseIrrelevantSearchContexts(queryResults, docIdsToLoad);
                searchCache.releaseQueryResults(queryResults);
                searchCache.releaseFetchResults(fetchResults);
            }
        }
,
>
, <(startLine=986 endLine=1054 srcPath=/root/NewExperiment/elasticsearchFilter/00952/src/test/java/org/elasticsearch/test/integration/count/query/SimpleQueryTests.java)
    public void testNumericRangeFilter_2826() throws Exception {
        client().admin().indices().prepareDelete().execute().actionGet();
        client().admin().indices().prepareCreate("test").setSettings(
                ImmutableSettings.settingsBuilder()
                        .put("index.number_of_shards", 1)
                        .put("index.number_of_replicas", 0)
        )
                .addMapping("type1", jsonBuilder().startObject().startObject("type1").startObject("properties")
                        .startObject("num_byte").field("type", "byte").endObject()
                        .startObject("num_short").field("type", "short").endObject()
                        .startObject("num_integer").field("type", "integer").endObject()
                        .startObject("num_long").field("type", "long").endObject()
                        .startObject("num_float").field("type", "float").endObject()
                        .startObject("num_double").field("type", "double").endObject()
                        .endObject().endObject().endObject())
                .execute().actionGet();
        ensureGreen();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 1)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 2)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 3)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 4)
                .endObject())
                .execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();
        CountResponse response = client().prepareCount("test").setQuery(
                filteredQuery(matchAllQuery(), FilterBuilders.boolFilter()
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4)))
        ).execute().actionGet();
        assertHitCount(response, 4l);

        // This made 2826 fail! (only with bit based filters)
        response = client().prepareCount("test").setQuery(
                filteredQuery(matchAllQuery(), FilterBuilders.boolFilter()
                        .should(FilterBuilders.numericRangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.numericRangeFilter("num_long").from(3).to(4)))
        ).execute().actionGet();

        assertHitCount(response, 4l);

        // This made #2979 fail!
        response = client().prepareCount("test").setQuery(
                filteredQuery(matchAllQuery(), FilterBuilders.boolFilter()
                        .must(FilterBuilders.termFilter("field1", "test1"))
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4)))
        ).execute().actionGet();

        assertHitCount(response, 2l);
    }
,
(startLine=1341 endLine=1409 srcPath=/root/NewExperiment/elasticsearchFilter/00952/src/test/java/org/elasticsearch/test/integration/search/query/SimpleQueryTests.java)
    public void testNumericRangeFilter_2826() throws Exception {
        client().admin().indices().prepareDelete().execute().actionGet();
        client().admin().indices().prepareCreate("test").setSettings(
                ImmutableSettings.settingsBuilder()
                        .put("index.number_of_shards", 1)
                        .put("index.number_of_replicas", 0)
        )
                .addMapping("type1", jsonBuilder().startObject().startObject("type1").startObject("properties")
                        .startObject("num_byte").field("type", "byte").endObject()
                        .startObject("num_short").field("type", "short").endObject()
                        .startObject("num_integer").field("type", "integer").endObject()
                        .startObject("num_long").field("type", "long").endObject()
                        .startObject("num_float").field("type", "float").endObject()
                        .startObject("num_double").field("type", "double").endObject()
                        .endObject().endObject().endObject())
                .execute().actionGet();
        ensureGreen();

        client().prepareIndex("test", "type1", "1").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 1)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "2").setSource(jsonBuilder().startObject()
                .field("field1", "test1")
                .field("num_long", 2)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "3").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 3)
                .endObject())
                .execute().actionGet();

        client().prepareIndex("test", "type1", "4").setSource(jsonBuilder().startObject()
                .field("field1", "test2")
                .field("num_long", 4)
                .endObject())
                .execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();
        SearchResponse response = client().prepareSearch("test").setFilter(
                FilterBuilders.boolFilter()
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4))
        ).execute().actionGet();
        assertThat(response.getHits().totalHits(), equalTo(4l));

        // This made 2826 fail! (only with bit based filters)
        response = client().prepareSearch("test").setFilter(
                FilterBuilders.boolFilter()
                        .should(FilterBuilders.numericRangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.numericRangeFilter("num_long").from(3).to(4))
        ).execute().actionGet();

        assertThat(response.getHits().totalHits(), equalTo(4l));

        // This made #2979 fail!
        response = client().prepareSearch("test").setFilter(
                FilterBuilders.boolFilter()
                        .must(FilterBuilders.termFilter("field1", "test1"))
                        .should(FilterBuilders.rangeFilter("num_long").from(1).to(2))
                        .should(FilterBuilders.rangeFilter("num_long").from(3).to(4))
        ).execute().actionGet();

        assertThat(response.getHits().totalHits(), equalTo(2l));
    }
,
>
, <(startLine=83 endLine=97 srcPath=/root/NewExperiment/elasticsearchFilter/01982/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EBool.java)
        if (operation == Operation.AND) {
            Label fals = new Label();
            Label end = new Label();

            left.write(writer, globals);
            writer.ifZCmp(Opcodes.IFEQ, fals);
            right.write(writer, globals);
            writer.ifZCmp(Opcodes.IFEQ, fals);

            writer.push(true);
            writer.goTo(end);
            writer.mark(fals);
            writer.push(false);
            writer.mark(end);
        } else if (operation == Operation.OR) {
,
(startLine=97 endLine=113 srcPath=/root/NewExperiment/elasticsearchFilter/01982/modules/lang-painless/src/main/java/org/elasticsearch/painless/node/EBool.java)
        } else if (operation == Operation.OR) {
            Label tru = new Label();
            Label fals = new Label();
            Label end = new Label();

            left.write(writer, globals);
            writer.ifZCmp(Opcodes.IFNE, tru);
            right.write(writer, globals);
            writer.ifZCmp(Opcodes.IFEQ, fals);

            writer.mark(tru);
            writer.push(true);
            writer.goTo(end);
            writer.mark(fals);
            writer.push(false);
            writer.mark(end);
        } else {
,
>
, <(startLine=411 endLine=457 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testSimpleSingleValuedField() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts","_count")
                                        .window(windowSize)
                                        .modelBuilder(new SimpleModel.SimpleModelBuilder())
                                        .gapPolicy(gapPolicy))
                                .subAggregation(movingAvg("movavg_values","the_metric")
                                        .window(windowSize)
                                        .modelBuilder(new SimpleModel.SimpleModelBuilder())
                                        .gapPolicy(gapPolicy))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MovAvgType.SIMPLE.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.SIMPLE.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
(startLine=459 endLine=505 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testLinearSingleValuedField() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts", "_count")
                                        .window(windowSize)
                                        .modelBuilder(new LinearModel.LinearModelBuilder())
                                        .gapPolicy(gapPolicy))
                                .subAggregation(movingAvg("movavg_values", "the_metric")
                                        .window(windowSize)
                                        .modelBuilder(new LinearModel.LinearModelBuilder())
                                        .gapPolicy(gapPolicy))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MovAvgType.LINEAR.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.LINEAR.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
(startLine=507 endLine=553 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testEwmaSingleValuedField() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts", "_count")
                                        .window(windowSize)
                                        .modelBuilder(new EwmaModel.EWMAModelBuilder().alpha(alpha))
                                        .gapPolicy(gapPolicy))
                                .subAggregation(movingAvg("movavg_values", "the_metric")
                                        .window(windowSize)
                                        .modelBuilder(new EwmaModel.EWMAModelBuilder().alpha(alpha))
                                        .gapPolicy(gapPolicy))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MovAvgType.EWMA.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.EWMA.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
(startLine=555 endLine=601 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testHoltSingleValuedField() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts", "_count")
                                        .window(windowSize)
                                        .modelBuilder(new HoltLinearModel.HoltLinearModelBuilder().alpha(alpha).beta(beta))
                                        .gapPolicy(gapPolicy))
                                .subAggregation(movingAvg("movavg_values", "the_metric")
                                        .window(windowSize)
                                        .modelBuilder(new HoltLinearModel.HoltLinearModelBuilder().alpha(alpha).beta(beta))
                                        .gapPolicy(gapPolicy))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MovAvgType.HOLT.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.HOLT.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
(startLine=603 endLine=653 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testHoltWintersValuedField() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts", "_count")
                                        .window(windowSize)
                                        .modelBuilder(new HoltWintersModel.HoltWintersModelBuilder()
                                                .alpha(alpha).beta(beta).gamma(gamma).period(period).seasonalityType(seasonalityType))
                                        .gapPolicy(gapPolicy)
                                        .minimize(false))
                                .subAggregation(movingAvg("movavg_values", "the_metric")
                                        .window(windowSize)
                                        .modelBuilder(new HoltWintersModel.HoltWintersModelBuilder()
                                                .alpha(alpha).beta(beta).gamma(gamma).period(period).seasonalityType(seasonalityType))
                                        .gapPolicy(gapPolicy)
                                        .minimize(false))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MovAvgType.HOLT_WINTERS.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.HOLT_WINTERS.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
(startLine=1005 endLine=1080 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testHoltWintersMinimization() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts", "_count")
                                        .window(windowSize)
                                        .modelBuilder(new HoltWintersModel.HoltWintersModelBuilder()
                                                .period(period).seasonalityType(seasonalityType))
                                        .gapPolicy(gapPolicy)
                                        .minimize(true))
                                .subAggregation(movingAvg("movavg_values", "the_metric")
                                        .window(windowSize)
                                        .modelBuilder(new HoltWintersModel.HoltWintersModelBuilder()
                                                .period(period).seasonalityType(seasonalityType))
                                        .gapPolicy(gapPolicy)
                                        .minimize(true))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));


        List<Double> expectedCounts = testValues.get(MovAvgType.HOLT_WINTERS.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.HOLT_WINTERS.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValueIter = expectedValues.iterator();

        // The minimizer is stochastic, so just make sure all the values coming back aren't null
        while (actualIter.hasNext()) {

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValueIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            SimpleValue countMovAvg = actual.getAggregations().get("movavg_counts");
            SimpleValue valuesMovAvg = actual.getAggregations().get("movavg_values");

            if (expectedCount == null) {
                //this bucket wasn't supposed to have a value (empty, skipped, etc), so
                //movavg should be null too
                assertThat(countMovAvg, nullValue());
            } else {

                // Note that we don't compare against the mock values, since those are assuming
                // a non-minimized set of coefficients.  Just check for not-nullness
                assertThat(countMovAvg, notNullValue());
            }

            if (expectedValue == null) {
                //this bucket wasn't supposed to have a value (empty, skipped, etc), so
                //movavg should be null too
                assertThat(valuesMovAvg, nullValue());
            } else {

                // Note that we don't compare against the mock values, since those are assuming
                // a non-minimized set of coefficients.  Just check for not-nullness
                assertThat(valuesMovAvg, notNullValue());
            }
        }

    }
,
(startLine=1091 endLine=1139 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgIT.java)
    public void testMinimizeNotEnoughData() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts", "_count")
                                        .window(numBuckets)
                                        .modelBuilder(new HoltLinearModel.HoltLinearModelBuilder().alpha(alpha).beta(beta))
                                        .gapPolicy(gapPolicy)
                                        .minimize(true))
                                .subAggregation(movingAvg("movavg_values", "the_metric")
                                        .window(numBuckets)
                                        .modelBuilder(new HoltLinearModel.HoltLinearModelBuilder().alpha(alpha).beta(beta))
                                        .gapPolicy(gapPolicy)
                                        .minimize(true))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MovAvgType.HOLT_BIG_MINIMIZE.name() + "_" + MetricTarget.COUNT.name());
        List<Double> expectedValues = testValues.get(MovAvgType.HOLT_BIG_MINIMIZE.name() + "_" + MetricTarget.VALUE.name());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
(startLine=229 endLine=273 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/serialdiff/SerialDiffIT.java)
    public void testBasicDiff() {
        SearchResponse response = client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(diff("diff_counts", "_count")
                                        .lag(lag)
                                        .gapPolicy(gapPolicy))
                                .subAggregation(diff("diff_values", "the_metric")
                                        .lag(lag)
                                        .gapPolicy(gapPolicy))
                ).execute().actionGet();

        assertSearchResponse(response);

        Histogram histo = response.getAggregations().get("histo");
        assertThat(histo, notNullValue());
        assertThat(histo.getName(), equalTo("histo"));
        List<? extends Bucket> buckets = histo.getBuckets();
        assertThat("Size of buckets array is not correct.", buckets.size(), equalTo(mockHisto.size()));

        List<Double> expectedCounts = testValues.get(MetricTarget.COUNT.toString());
        List<Double> expectedValues = testValues.get(MetricTarget.VALUE.toString());

        Iterator<? extends Histogram.Bucket> actualIter = buckets.iterator();
        Iterator<PipelineAggregationHelperTests.MockBucket> expectedBucketIter = mockHisto.iterator();
        Iterator<Double> expectedCountsIter = expectedCounts.iterator();
        Iterator<Double> expectedValuesIter = expectedValues.iterator();

        while (actualIter.hasNext()) {
            assertValidIterators(expectedBucketIter, expectedCountsIter, expectedValuesIter);

            Histogram.Bucket actual = actualIter.next();
            PipelineAggregationHelperTests.MockBucket expected = expectedBucketIter.next();
            Double expectedCount = expectedCountsIter.next();
            Double expectedValue = expectedValuesIter.next();

            assertThat("keys do not match", ((Number) actual.getKey()).longValue(), equalTo(expected.key));
            assertThat("doc counts do not match", actual.getDocCount(), equalTo((long)expected.count));

            assertBucketContents(actual, expectedCount, expectedValue);
        }
    }
,
>
, <(startLine=34 endLine=67 srcPath=/root/NewExperiment/elasticsearchFilter/00301/plugins/lang/javascript/src/test/java/org/elasticsearch/script/javascript/SimpleBench.java)
    public static void main(String[] args) {
        JavaScriptScriptEngineService se = new JavaScriptScriptEngineService(ImmutableSettings.Builder.EMPTY_SETTINGS);
        Object compiled = se.compile("x + y");

        Map<String, Object> vars = new HashMap<String, Object>();
        // warm up
        for (int i = 0; i < 1000; i++) {
            vars.put("x", i);
            vars.put("y", i + 1);
            se.execute(compiled, vars);
        }

        final long ITER = 100000;

        StopWatch stopWatch = new StopWatch().start();
        for (long i = 0; i < ITER; i++) {
            se.execute(compiled, vars);
        }
        System.out.println("Execute Took: " + stopWatch.stop().lastTaskTime());

        stopWatch = new StopWatch().start();
        ExecutableScript executableScript = se.executable(compiled, vars);
        for (long i = 0; i < ITER; i++) {
            executableScript.run();
        }
        System.out.println("Executable Took: " + stopWatch.stop().lastTaskTime());

        stopWatch = new StopWatch().start();
        executableScript = se.executable(compiled, vars);
        for (long i = 0; i < ITER; i++) {
            executableScript.run(vars);
        }
        System.out.println("Executable (vars) Took: " + stopWatch.stop().lastTaskTime());
    }
,
(startLine=34 endLine=67 srcPath=/root/NewExperiment/elasticsearchFilter/00301/plugins/lang/python/src/test/java/org/elasticsearch/script/python/SimpleBench.java)
    public static void main(String[] args) {
        PythonScriptEngineService se = new PythonScriptEngineService(ImmutableSettings.Builder.EMPTY_SETTINGS);
        Object compiled = se.compile("x + y");

        Map<String, Object> vars = new HashMap<String, Object>();
        // warm up
        for (int i = 0; i < 1000; i++) {
            vars.put("x", i);
            vars.put("y", i + 1);
            se.execute(compiled, vars);
        }

        final long ITER = 100000;

        StopWatch stopWatch = new StopWatch().start();
        for (long i = 0; i < ITER; i++) {
            se.execute(compiled, vars);
        }
        System.out.println("Execute Took: " + stopWatch.stop().lastTaskTime());

        stopWatch = new StopWatch().start();
        ExecutableScript executableScript = se.executable(compiled, vars);
        for (long i = 0; i < ITER; i++) {
            executableScript.run();
        }
        System.out.println("Executable Took: " + stopWatch.stop().lastTaskTime());

        stopWatch = new StopWatch().start();
        executableScript = se.executable(compiled, vars);
        for (long i = 0; i < ITER; i++) {
            executableScript.run(vars);
        }
        System.out.println("Executable (vars) Took: " + stopWatch.stop().lastTaskTime());
    }
,
>
, <(startLine=148 endLine=155 srcPath=/root/NewExperiment/elasticsearchFilter/01968/core/src/main/java/org/elasticsearch/search/fetch/subphase/FetchSourceContext.java)
                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                            if (token == XContentParser.Token.VALUE_STRING) {
                                includesList.add(parser.text());
                            } else {
                                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token
                                        + " in [" + currentFieldName + "].", parser.getTokenLocation());
                            }
                        }
,
(startLine=159 endLine=166 srcPath=/root/NewExperiment/elasticsearchFilter/01968/core/src/main/java/org/elasticsearch/search/fetch/subphase/FetchSourceContext.java)
                        while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                            if (token == XContentParser.Token.VALUE_STRING) {
                                excludesList.add(parser.text());
                            } else {
                                throw new ParsingException(parser.getTokenLocation(), "Unknown key for a " + token
                                        + " in [" + currentFieldName + "].", parser.getTokenLocation());
                            }
                        }
,
>
, <(startLine=994 endLine=1066 srcPath=/root/NewExperiment/elasticsearchFilter/01238/src/main/java/jsr166e/ForkJoinTask.java)
        throws InterruptedException, ExecutionException, TimeoutException {
        if (Thread.interrupted())
            throw new InterruptedException();
        // Messy in part because we measure in nanosecs, but wait in millisecs
        int s; long ms;
        long ns = unit.toNanos(timeout);
        ForkJoinPool cp;
        if ((s = status) >= 0 && ns > 0L) {
            long deadline = System.nanoTime() + ns;
            ForkJoinPool p = null;
            ForkJoinPool.WorkQueue w = null;
            Thread t = Thread.currentThread();
            if (t instanceof ForkJoinWorkerThread) {
                ForkJoinWorkerThread wt = (ForkJoinWorkerThread)t;
                p = wt.pool;
                w = wt.workQueue;
                p.helpJoinOnce(w, this); // no retries on failure
            }
            else if ((cp = ForkJoinPool.common) != null) {
                if (this instanceof CountedCompleter)
                    cp.externalHelpComplete((CountedCompleter<?>)this);
                else if (cp.tryExternalUnpush(this))
                    doExec();
            }
            boolean canBlock = false;
            boolean interrupted = false;
            try {
                while ((s = status) >= 0) {
                    if (w != null && w.qlock < 0)
                        cancelIgnoringExceptions(this);
                    else if (!canBlock) {
                        if (p == null || p.tryCompensate(p.ctl))
                            canBlock = true;
                    }
                    else {
                        if ((ms = TimeUnit.NANOSECONDS.toMillis(ns)) > 0L &&
                            U.compareAndSwapInt(this, STATUS, s, s | SIGNAL)) {
                            synchronized (this) {
                                if (status >= 0) {
                                    try {
                                        wait(ms);
                                    } catch (InterruptedException ie) {
                                        if (p == null)
                                            interrupted = true;
                                    }
                                }
                                else
                                    notifyAll();
                            }
                        }
                        if ((s = status) < 0 || interrupted ||
                            (ns = deadline - System.nanoTime()) <= 0L)
                            break;
                    }
                }
            } finally {
                if (p != null && canBlock)
                    p.incrementActiveCount();
            }
            if (interrupted)
                throw new InterruptedException();
        }
        if ((s &= DONE_MASK) != NORMAL) {
            Throwable ex;
            if (s == CANCELLED)
                throw new CancellationException();
            if (s != EXCEPTIONAL)
                throw new TimeoutException();
            if ((ex = getThrowableException()) != null)
                throw new ExecutionException(ex);
        }
        return getRawResult();
    }
,
(startLine=980 endLine=1047 srcPath=/root/NewExperiment/elasticsearchFilter/01238/src/main/java/jsr166y/ForkJoinTask.java)
        throws InterruptedException, ExecutionException, TimeoutException {
        if (Thread.interrupted())
            throw new InterruptedException();
        // Messy in part because we measure in nanosecs, but wait in millisecs
        int s; long ms;
        long ns = unit.toNanos(timeout);
        if ((s = status) >= 0 && ns > 0L) {
            long deadline = System.nanoTime() + ns;
            ForkJoinPool p = null;
            ForkJoinPool.WorkQueue w = null;
            Thread t = Thread.currentThread();
            if (t instanceof ForkJoinWorkerThread) {
                ForkJoinWorkerThread wt = (ForkJoinWorkerThread)t;
                p = wt.pool;
                w = wt.workQueue;
                p.helpJoinOnce(w, this); // no retries on failure
            }
            else
                ForkJoinPool.externalHelpJoin(this);
            boolean canBlock = false;
            boolean interrupted = false;
            try {
                while ((s = status) >= 0) {
                    if (w != null && w.qlock < 0)
                        cancelIgnoringExceptions(this);
                    else if (!canBlock) {
                        if (p == null || p.tryCompensate())
                            canBlock = true;
                    }
                    else {
                        if ((ms = TimeUnit.NANOSECONDS.toMillis(ns)) > 0L &&
                            U.compareAndSwapInt(this, STATUS, s, s | SIGNAL)) {
                            synchronized (this) {
                                if (status >= 0) {
                                    try {
                                        wait(ms);
                                    } catch (InterruptedException ie) {
                                        if (p == null)
                                            interrupted = true;
                                    }
                                }
                                else
                                    notifyAll();
                            }
                        }
                        if ((s = status) < 0 || interrupted ||
                            (ns = deadline - System.nanoTime()) <= 0L)
                            break;
                    }
                }
            } finally {
                if (p != null && canBlock)
                    p.incrementActiveCount();
            }
            if (interrupted)
                throw new InterruptedException();
        }
        if ((s &= DONE_MASK) != NORMAL) {
            Throwable ex;
            if (s == CANCELLED)
                throw new CancellationException();
            if (s != EXCEPTIONAL)
                throw new TimeoutException();
            if ((ex = getThrowableException()) != null)
                throw new ExecutionException(ex);
        }
        return getRawResult();
    }
,
>
, <(startLine=61 endLine=78 srcPath=/root/NewExperiment/elasticsearchFilter/00009/modules/elasticsearch/src/main/java/org/elasticsearch/index/store/bytebuffer/ByteBufferDirectory.java)
    public ByteBufferDirectory(SizeValue bufferSize, SizeValue cacheSize, boolean direct, boolean warmCache) {
        disableCache = cacheSize.bytes() == 0;
        if (!disableCache && cacheSize.bytes() < bufferSize.bytes()) {
            throw new IllegalArgumentException("Cache size [" + cacheSize + "] is smaller than buffer size [" + bufferSize + "]");
        }
        this.bufferSize = bufferSize;
        this.bufferSizeInBytes = (int) bufferSize.bytes();
        int numberOfCacheEntries = (int) (cacheSize.bytes() / bufferSize.bytes());
        this.cache = disableCache ? null : new ArrayBlockingQueue<ByteBuffer>(numberOfCacheEntries);
        this.cacheSize = disableCache ? new SizeValue(0, SizeUnit.BYTES) : new SizeValue(numberOfCacheEntries * bufferSize.bytes(), SizeUnit.BYTES);
        this.direct = direct;
        setLockFactory(new SingleInstanceLockFactory());
        if (!disableCache && warmCache) {
            for (int i = 0; i < numberOfCacheEntries; i++) {
                cache.add(createBuffer());
            }
        }
    }
,
(startLine=58 endLine=74 srcPath=/root/NewExperiment/elasticsearchFilter/00009/modules/elasticsearch/src/main/java/org/elasticsearch/index/store/memory/MemoryDirectory.java)
    public MemoryDirectory(SizeValue bufferSize, SizeValue cacheSize, boolean warmCache) {
        disableCache = cacheSize.bytes() == 0;
        if (!disableCache && cacheSize.bytes() < bufferSize.bytes()) {
            throw new IllegalArgumentException("Cache size [" + cacheSize + "] is smaller than buffer size [" + bufferSize + "]");
        }
        this.bufferSize = bufferSize;
        this.bufferSizeInBytes = (int) bufferSize.bytes();
        int numberOfCacheEntries = (int) (cacheSize.bytes() / bufferSize.bytes());
        this.cache = disableCache ? null : new ArrayBlockingQueue<byte[]>(numberOfCacheEntries);
        this.cacheSize = disableCache ? new SizeValue(0, SizeUnit.BYTES) : new SizeValue(numberOfCacheEntries * bufferSize.bytes(), SizeUnit.BYTES);
        setLockFactory(new SingleInstanceLockFactory());
        if (!disableCache && warmCache) {
            for (int i = 0; i < numberOfCacheEntries; i++) {
                cache.add(createBuffer());
            }
        }
    }
,
>
, <(startLine=96 endLine=121 srcPath=/root/NewExperiment/elasticsearchFilter/02442/core/src/test/java/org/elasticsearch/search/aggregations/bucket/DateHistogramTests.java)
    private List<BucketOrder> randomOrder() {
        List<BucketOrder> orders = new ArrayList<>();
        switch (randomInt(4)) {
            case 0:
                orders.add(BucketOrder.key(randomBoolean()));
                break;
            case 1:
                orders.add(BucketOrder.count(randomBoolean()));
                break;
            case 2:
                orders.add(BucketOrder.aggregation(randomAlphaOfLengthBetween(3, 20), randomBoolean()));
                break;
            case 3:
                orders.add(BucketOrder.aggregation(randomAlphaOfLengthBetween(3, 20), randomAlphaOfLengthBetween(3, 20), randomBoolean()));
                break;
            case 4:
                int numOrders = randomIntBetween(1, 3);
                for (int i = 0; i < numOrders; i++) {
                    orders.addAll(randomOrder());
                }
                break;
            default:
                fail();
        }
        return orders;
    }
,
(startLine=171 endLine=196 srcPath=/root/NewExperiment/elasticsearchFilter/02442/core/src/test/java/org/elasticsearch/search/aggregations/bucket/TermsTests.java)
    private List<BucketOrder> randomOrder() {
        List<BucketOrder> orders = new ArrayList<>();
        switch (randomInt(4)) {
        case 0:
            orders.add(BucketOrder.key(randomBoolean()));
            break;
        case 1:
            orders.add(BucketOrder.count(randomBoolean()));
            break;
        case 2:
            orders.add(BucketOrder.aggregation(randomAlphaOfLengthBetween(3, 20), randomBoolean()));
            break;
        case 3:
            orders.add(BucketOrder.aggregation(randomAlphaOfLengthBetween(3, 20), randomAlphaOfLengthBetween(3, 20), randomBoolean()));
            break;
        case 4:
            int numOrders = randomIntBetween(1, 3);
            for (int i = 0; i < numOrders; i++) {
                orders.addAll(randomOrder());
            }
            break;
        default:
            fail();
        }
        return orders;
    }
,
>
, <(startLine=138 endLine=225 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/bytes/TermsByteOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                byte value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalByteTermsFacet.ByteEntry entry = new InternalByteTermsFacet.ByteEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalByteTermsFacet.ByteEntry[] list = new InternalByteTermsFacet.ByteEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalByteTermsFacet.ByteEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalByteTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalByteTermsFacet.ByteEntry> ordered = new BoundedTreeSet<InternalByteTermsFacet.ByteEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            byte value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalByteTermsFacet.ByteEntry entry = new InternalByteTermsFacet.ByteEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalByteTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=137 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/floats/TermsFloatOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                float value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalFloatTermsFacet.FloatEntry entry = new InternalFloatTermsFacet.FloatEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalFloatTermsFacet.FloatEntry[] list = new InternalFloatTermsFacet.FloatEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalFloatTermsFacet.FloatEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalFloatTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalFloatTermsFacet.FloatEntry> ordered = new BoundedTreeSet<InternalFloatTermsFacet.FloatEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            float value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalFloatTermsFacet.FloatEntry entry = new InternalFloatTermsFacet.FloatEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalFloatTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=137 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/longs/TermsLongOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                long value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalLongTermsFacet.LongEntry entry = new InternalLongTermsFacet.LongEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalLongTermsFacet.LongEntry[] list = new InternalLongTermsFacet.LongEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalLongTermsFacet.LongEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalLongTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalLongTermsFacet.LongEntry> ordered = new BoundedTreeSet<InternalLongTermsFacet.LongEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            long value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalLongTermsFacet.LongEntry entry = new InternalLongTermsFacet.LongEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalLongTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=137 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/shorts/TermsShortOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                short value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalShortTermsFacet.ShortEntry entry = new InternalShortTermsFacet.ShortEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalShortTermsFacet.ShortEntry[] list = new InternalShortTermsFacet.ShortEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalShortTermsFacet.ShortEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalShortTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalShortTermsFacet.ShortEntry> ordered = new BoundedTreeSet<InternalShortTermsFacet.ShortEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            short value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalShortTermsFacet.ShortEntry entry = new InternalShortTermsFacet.ShortEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalShortTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=137 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/doubles/TermsDoubleOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                double value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalDoubleTermsFacet.DoubleEntry entry = new InternalDoubleTermsFacet.DoubleEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalDoubleTermsFacet.DoubleEntry[] list = new InternalDoubleTermsFacet.DoubleEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalDoubleTermsFacet.DoubleEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalDoubleTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry> ordered = new BoundedTreeSet<InternalDoubleTermsFacet.DoubleEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            double value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalDoubleTermsFacet.DoubleEntry entry = new InternalDoubleTermsFacet.DoubleEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalDoubleTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=137 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/ip/TermsIpOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                long value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalIpTermsFacet.LongEntry entry = new InternalIpTermsFacet.LongEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalIpTermsFacet.LongEntry[] list = new InternalIpTermsFacet.LongEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalIpTermsFacet.LongEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalIpTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalIpTermsFacet.LongEntry> ordered = new BoundedTreeSet<InternalIpTermsFacet.LongEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            long value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalIpTermsFacet.LongEntry entry = new InternalIpTermsFacet.LongEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalIpTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=137 endLine=224 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/ints/TermsIntOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                int value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value == agg.current);

                if (count > minCount) {
                    if (excluded == null || !excluded.contains(value)) {
                        InternalIntTermsFacet.IntEntry entry = new InternalIntTermsFacet.IntEntry(value, count);
                        ordered.insertWithOverflow(entry);
                    }
                }
            }
            InternalIntTermsFacet.IntEntry[] list = new InternalIntTermsFacet.IntEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalIntTermsFacet.IntEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalIntTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalIntTermsFacet.IntEntry> ordered = new BoundedTreeSet<InternalIntTermsFacet.IntEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            int value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value == agg.current);

            if (count > minCount) {
                if (excluded == null || !excluded.contains(value)) {
                    InternalIntTermsFacet.IntEntry entry = new InternalIntTermsFacet.IntEntry(value, count);
                    ordered.add(entry);
                }
            }
        }

        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalIntTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
(startLine=138 endLine=234 srcPath=/root/NewExperiment/elasticsearchFilter/00572/src/main/java/org/elasticsearch/search/facet/terms/strings/TermsStringOrdinalsFacetCollector.java)
    public Facet facet() {
        if (current != null) {
            missing += current.counts[0];
            total += current.total - current.counts[0];
            // if we have values for this one, add it
            if (current.values.length > 1) {
                aggregators.add(current);
            }
        }

        AggregatorPriorityQueue queue = new AggregatorPriorityQueue(aggregators.size());

        for (ReaderAggregator aggregator : aggregators) {
            if (aggregator.nextPosition()) {
                queue.add(aggregator);
            }
        }

        // YACK, we repeat the same logic, but once with an optimizer priority queue for smaller sizes
        if (size < EntryPriorityQueue.LIMIT) {
            // optimize to use priority size
            EntryPriorityQueue ordered = new EntryPriorityQueue(size, comparatorType.comparator());

            while (queue.size() > 0) {
                ReaderAggregator agg = queue.top();
                String value = agg.current;
                int count = 0;
                do {
                    count += agg.counts[agg.position];
                    if (agg.nextPosition()) {
                        agg = queue.updateTop();
                    } else {
                        // we are done with this reader
                        queue.pop();
                        agg = queue.top();
                    }
                } while (agg != null && value.equals(agg.current));

                if (count > minCount) {
                    if (excluded != null && excluded.contains(value)) {
                        continue;
                    }
                    if (matcher != null && !matcher.reset(value).matches()) {
                        continue;
                    }
                    InternalStringTermsFacet.StringEntry entry = new InternalStringTermsFacet.StringEntry(value, count);
                    ordered.insertWithOverflow(entry);
                }
            }
            InternalStringTermsFacet.StringEntry[] list = new InternalStringTermsFacet.StringEntry[ordered.size()];
            for (int i = ordered.size() - 1; i >= 0; i--) {
                list[i] = (InternalStringTermsFacet.StringEntry) ordered.pop();
            }

            for (ReaderAggregator aggregator : aggregators) {
                CacheRecycler.pushIntArray(aggregator.counts);
            }

            return new InternalStringTermsFacet(facetName, comparatorType, size, Arrays.asList(list), missing, total);
        }

        BoundedTreeSet<InternalStringTermsFacet.StringEntry> ordered = new BoundedTreeSet<InternalStringTermsFacet.StringEntry>(comparatorType.comparator(), size);

        while (queue.size() > 0) {
            ReaderAggregator agg = queue.top();
            String value = agg.current;
            int count = 0;
            do {
                count += agg.counts[agg.position];
                if (agg.nextPosition()) {
                    agg = queue.updateTop();
                } else {
                    // we are done with this reader
                    queue.pop();
                    agg = queue.top();
                }
            } while (agg != null && value.equals(agg.current));

            if (count > minCount) {
                if (excluded != null && excluded.contains(value)) {
                    continue;
                }
                if (matcher != null && !matcher.reset(value).matches()) {
                    continue;
                }
                InternalStringTermsFacet.StringEntry entry = new InternalStringTermsFacet.StringEntry(value, count);
                ordered.add(entry);
            }
        }


        for (ReaderAggregator aggregator : aggregators) {
            CacheRecycler.pushIntArray(aggregator.counts);
        }

        return new InternalStringTermsFacet(facetName, comparatorType, size, ordered, missing, total);
    }
,
>
, <(startLine=680 endLine=859 srcPath=/root/NewExperiment/elasticsearchFilter/00969/src/test/java/org/elasticsearch/search/customscore/CustomScoreSearchTests.java)
    public void testCustomFiltersScore() throws Exception {
        wipeIndices();
        client().admin().indices().prepareCreate("test").setSettings(settingsBuilder().put("index.number_of_shards", 1)).execute()
                .actionGet();

        client().prepareIndex("test", "type", "1").setSource("field", "value1", "color", "red").execute().actionGet();
        client().prepareIndex("test", "type", "2").setSource("field", "value2", "color", "blue").execute().actionGet();
        client().prepareIndex("test", "type", "3").setSource("field", "value3", "color", "red").execute().actionGet();
        client().prepareIndex("test", "type", "4").setSource("field", "value4", "color", "blue").execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).add(termFilter("field", "value4"), "2").add(termFilter("field", "value2"),
                                "3")).setExplain(true).execute().actionGet();

        assertNoFailures(searchResponse);

        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(3.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(1.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).add(termFilter("field", "value4"), 2)
                                .add(termFilter("field", "value2"), 3)).setExplain(true).execute().actionGet();

        assertNoFailures(searchResponse);

        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(3.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(1.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).scoreMode("total").add(termFilter("field", "value4"), 2)
                                .add(termFilter("field", "value1"), 3).add(termFilter("color", "red"), 5)).setExplain(true).execute()
                .actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(8.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).scoreMode("max").add(termFilter("field", "value4"), 2)
                                .add(termFilter("field", "value1"), 3).add(termFilter("color", "red"), 5)).setExplain(true).execute()
                .actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), anyOf(equalTo("1"), equalTo("3"))); // could
                                                                                               // be
                                                                                               // both
                                                                                               // depending
                                                                                               // on
                                                                                               // the
                                                                                               // order
                                                                                               // of
                                                                                               // the
                                                                                               // docs
                                                                                               // internally
                                                                                               // (lucene
                                                                                               // order)
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(5.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).scoreMode("avg").add(termFilter("field", "value4"), 2)
                                .add(termFilter("field", "value1"), 3).add(termFilter("color", "red"), 5)).setExplain(true).execute()
                .actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(5.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(4.0f));
        logger.info("--> Hit[1] {} Explanation {}", searchResponse.getHits().getAt(1).id(), searchResponse.getHits().getAt(1).explanation());

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).scoreMode("min").add(termFilter("field", "value4"), 2)
                                .add(termFilter("field", "value1"), 3).add(termFilter("color", "red"), 5)).setExplain(true).execute()
                .actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(5.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(3.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(matchAllQuery()).scoreMode("multiply").add(termFilter("field", "value4"), 2)
                                .add(termFilter("field", "value1"), 3).add(termFilter("color", "red"), 5)).setExplain(true).execute()
                .actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(15.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(5.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(termsQuery("field", "value1", "value2", "value3", "value4")).scoreMode("first")
                                .add(termFilter("field", "value4"), 2).add(termFilter("field", "value3"), 3)
                                .add(termFilter("field", "value2"), 4)).setExplain(true).execute().actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(searchResponse.getHits().getAt(0).explanation().getValue()));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(searchResponse.getHits().getAt(1).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(searchResponse.getHits().getAt(2).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(searchResponse.getHits().getAt(3).explanation().getValue()));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        customFiltersScoreQuery(termsQuery("field", "value1", "value2", "value3", "value4")).scoreMode("multiply")
                                .add(termFilter("field", "value4"), 2).add(termFilter("field", "value1"), 3)
                                .add(termFilter("color", "red"), 5)).setExplain(true).execute().actionGet();

        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(searchResponse.getHits().getAt(0).explanation().getValue()));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(searchResponse.getHits().getAt(1).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(searchResponse.getHits().getAt(2).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(searchResponse.getHits().getAt(3).explanation().getValue()));
    }
,
(startLine=862 endLine=1057 srcPath=/root/NewExperiment/elasticsearchFilter/00969/src/test/java/org/elasticsearch/search/customscore/CustomScoreSearchTests.java)
    public void testCustomFiltersScore_withFunctionScore() throws Exception {
        wipeIndices();
        client().admin().indices().prepareCreate("test").setSettings(settingsBuilder().put("index.number_of_shards", 1)).execute()
                .actionGet();

        client().prepareIndex("test", "type", "1").setSource("field", "value1", "color", "red").execute().actionGet();
        client().prepareIndex("test", "type", "2").setSource("field", "value2", "color", "blue").execute().actionGet();
        client().prepareIndex("test", "type", "3").setSource("field", "value3", "color", "red").execute().actionGet();
        client().prepareIndex("test", "type", "4").setSource("field", "value4", "color", "blue").execute().actionGet();

        client().admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery())
                                .add(termFilter("field", "value4"), scriptFunction("2")).add(
                                        termFilter("field", "value2"), scriptFunction("3"))).setExplain(true)
                .execute().actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));

        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(3.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(1.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery()).add(termFilter("field", "value4"), factorFunction(2)).add(
                                termFilter("field", "value2"), factorFunction(3))).setExplain(true).execute().actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));

        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(3.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(1.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), anyOf(equalTo("1"), equalTo("3")));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery()).scoreMode("sum")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value1"), factorFunction(3))
                                .add(termFilter("color", "red"), factorFunction(5))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(8.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery()).scoreMode("max")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value1"), factorFunction(3))
                                .add(termFilter("color", "red"), factorFunction(5))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), anyOf(equalTo("1"), equalTo("3"))); // could
                                                                                               // be
                                                                                               // both
                                                                                               // depending
                                                                                               // on
                                                                                               // the
                                                                                               // order
                                                                                               // of
                                                                                               // the
                                                                                               // docs
                                                                                               // internally
                                                                                               // (lucene
                                                                                               // order)
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(5.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery()).scoreMode("avg")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value1"), factorFunction(3))
                                .add(termFilter("color", "red"), factorFunction(5))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(5.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(4.0f));
        logger.info("--> Hit[1] {} Explanation {}", searchResponse.getHits().getAt(1).id(), searchResponse.getHits().getAt(1).explanation());

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery()).scoreMode("min")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value1"), factorFunction(3))
                                .add(termFilter("color", "red"), factorFunction(5))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(5.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(3.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(matchAllQuery()).scoreMode("multiply")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value1"), factorFunction(3))
                                .add(termFilter("color", "red"), factorFunction(5))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(15.0f));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(5.0f));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(2.0f));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(1.0f));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(termsQuery("field", "value1", "value2", "value3", "value4")).scoreMode("first")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value3"), factorFunction(3))
                                .add(termFilter("field", "value2"), factorFunction(4))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(searchResponse.getHits().getAt(0).explanation().getValue()));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(searchResponse.getHits().getAt(1).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(searchResponse.getHits().getAt(2).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(searchResponse.getHits().getAt(3).explanation().getValue()));

        searchResponse = client()
                .prepareSearch("test")
                .setQuery(
                        functionScoreQuery(termsQuery("field", "value1", "value2", "value3", "value4")).scoreMode("multiply")
                                .add(termFilter("field", "value4"), factorFunction(2))
                                .add(termFilter("field", "value1"), factorFunction(3))
                                .add(termFilter("color", "red"), factorFunction(5))).setExplain(true).execute()
                .actionGet();

        assertThat(Arrays.toString(searchResponse.getShardFailures()), searchResponse.getFailedShards(), equalTo(0));
        assertThat(searchResponse.getHits().totalHits(), equalTo(4l));
        assertThat(searchResponse.getHits().getAt(0).id(), equalTo("1"));
        assertThat(searchResponse.getHits().getAt(0).score(), equalTo(searchResponse.getHits().getAt(0).explanation().getValue()));
        logger.info("--> Hit[0] {} Explanation {}", searchResponse.getHits().getAt(0).id(), searchResponse.getHits().getAt(0).explanation());
        assertThat(searchResponse.getHits().getAt(1).id(), equalTo("3"));
        assertThat(searchResponse.getHits().getAt(1).score(), equalTo(searchResponse.getHits().getAt(1).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(2).id(), equalTo("4"));
        assertThat(searchResponse.getHits().getAt(2).score(), equalTo(searchResponse.getHits().getAt(2).explanation().getValue()));
        assertThat(searchResponse.getHits().getAt(3).id(), equalTo("2"));
        assertThat(searchResponse.getHits().getAt(3).score(), equalTo(searchResponse.getHits().getAt(3).explanation().getValue()));
    }
,
>
, <(startLine=190 endLine=216 srcPath=/root/NewExperiment/elasticsearchFilter/01770/plugins/delete-by-query/src/test/java/org/elasticsearch/plugin/deletebyquery/DeleteByQueryTests.java)
    public void testDeleteByQueryWithRouting() throws Exception {
        assertAcked(prepareCreate("test").setSettings("number_of_shards", 2));
        ensureGreen("test");

        final int docs = randomIntBetween(2, 10);
        logger.info("--> indexing [{}] documents with routing", docs);
        for (int i = 0; i < docs; i++) {
            client().prepareIndex("test", "test", String.valueOf(i)).setRouting(String.valueOf(i)).setSource("field1", 1).get();
        }
        refresh();

        logger.info("--> counting documents with no routing, should be equal to [{}]", docs);
        assertHitCount(client().prepareSearch().setSize(0).get(), docs);

        String routing = String.valueOf(randomIntBetween(2, docs));

        logger.info("--> counting documents with routing [{}]", routing);
        long expected = client().prepareSearch().setSize(0).setRouting(routing).get().getHits().totalHits();

        logger.info("--> delete all documents with routing [{}] with a delete-by-query", routing);
        DeleteByQueryRequestBuilder delete = newDeleteByQuery().setRouting(routing).setQuery(QueryBuilders.matchAllQuery());
        assertDBQResponse(delete.get(), expected, expected, 0L, 0L);
        refresh();

        assertHitCount(client().prepareSearch().setSize(0).get(), docs - expected);
        assertSearchContextsClosed();
    }
,
(startLine=131 endLine=158 srcPath=/root/NewExperiment/elasticsearchFilter/01770/modules/reindex/src/test/java/org/elasticsearch/index/reindex/DeleteByQueryBasicTests.java)
    public void testDeleteByQueryWithRouting() throws Exception {
        assertAcked(prepareCreate("test").setSettings("number_of_shards", 2));
        ensureGreen("test");

        final int docs = randomIntBetween(2, 10);
        logger.info("--> indexing [{}] documents with routing", docs);

        List<IndexRequestBuilder> builders = new ArrayList<>();
        for (int i = 0; i < docs; i++) {
            builders.add(client().prepareIndex("test", "test", String.valueOf(i)).setRouting(String.valueOf(i)).setSource("field1", 1));
        }
        indexRandom(true, true, true, builders);

        logger.info("--> counting documents with no routing, should be equal to [{}]", docs);
        assertHitCount(client().prepareSearch().setSize(0).get(), docs);

        String routing = String.valueOf(randomIntBetween(2, docs));

        logger.info("--> counting documents with routing [{}]", routing);
        long expected = client().prepareSearch().setSize(0).setRouting(routing).get().getHits().totalHits();

        logger.info("--> delete all documents with routing [{}] with a delete-by-query", routing);
        DeleteByQueryRequestBuilder delete = deleteByQuery().source("test");
        delete.source().setRouting(routing);
        assertThat(delete.refresh(true).get(), matcher().deleted(expected));

        assertHitCount(client().prepareSearch().setSize(0).get(), docs - expected);
    }
,
>
, <(startLine=110 endLine=126 srcPath=/root/NewExperiment/elasticsearchFilter/00607/src/test/java/org/elasticsearch/benchmark/trove/StringMapAdjustOrPutBenchmark.java)
        for (long iter = 0; iter < ITERATIONS; iter++) {
            if (REUSE) {
                tMap.clear();
            } else {
                tMap = new THashMap<String, StringEntry>();
            }
            for (long i = 0; i < PUT_OPERATIONS; i++) {
                String key = values[(int) (i % NUMBER_OF_KEYS)];
                StringEntry stringEntry = tMap.get(key);
                if (stringEntry == null) {
                    stringEntry = new StringEntry(key, 1);
                    tMap.put(key, stringEntry);
                } else {
                    stringEntry.counter++;
                }
            }
        }
,
(startLine=136 endLine=152 srcPath=/root/NewExperiment/elasticsearchFilter/00607/src/test/java/org/elasticsearch/benchmark/trove/StringMapAdjustOrPutBenchmark.java)
        for (long iter = 0; iter < ITERATIONS; iter++) {
            if (REUSE) {
                hMap.clear();
            } else {
                hMap = new HashMap<String, StringEntry>();
            }
            for (long i = 0; i < PUT_OPERATIONS; i++) {
                String key = values[(int) (i % NUMBER_OF_KEYS)];
                StringEntry stringEntry = hMap.get(key);
                if (stringEntry == null) {
                    stringEntry = new StringEntry(key, 1);
                    hMap.put(key, stringEntry);
                } else {
                    stringEntry.counter++;
                }
            }
        }
,
(startLine=163 endLine=179 srcPath=/root/NewExperiment/elasticsearchFilter/00607/src/test/java/org/elasticsearch/benchmark/trove/StringMapAdjustOrPutBenchmark.java)
        for (long iter = 0; iter < ITERATIONS; iter++) {
            if (REUSE) {
                ihMap.clear();
            } else {
                hMap = new HashMap<String, StringEntry>();
            }
            for (long i = 0; i < PUT_OPERATIONS; i++) {
                String key = values[(int) (i % NUMBER_OF_KEYS)];
                StringEntry stringEntry = ihMap.get(key);
                if (stringEntry == null) {
                    stringEntry = new StringEntry(key, 1);
                    ihMap.put(key, stringEntry);
                } else {
                    stringEntry.counter++;
                }
            }
        }
,
>
, <(startLine=360 endLine=427 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/MinBucketIT.java)
    public void testNested() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        terms("terms")
                                .field("tag")
                                .order(BucketOrder.key(true))
                                .subAggregation(
                                        histogram("histo").field(SINGLE_VALUED_FIELD_NAME).interval(interval)
                                                .extendedBounds(minRandomValue, maxRandomValue))
                                .subAggregation(minBucket("min_histo_bucket", "histo>_count")))
                .addAggregation(minBucket("min_terms_bucket", "terms>min_histo_bucket")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<? extends Terms.Bucket> termsBuckets = terms.getBuckets();
        assertThat(termsBuckets.size(), equalTo(interval));

        List<String> minTermsKeys = new ArrayList<>();
        double minTermsValue = Double.POSITIVE_INFINITY;
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> minHistoKeys = new ArrayList<>();
            double minHistoValue = Double.POSITIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                if (bucket.getDocCount() < minHistoValue) {
                    minHistoValue = bucket.getDocCount();
                    minHistoKeys = new ArrayList<>();
                    minHistoKeys.add(bucket.getKeyAsString());
                } else if (bucket.getDocCount() == minHistoValue) {
                    minHistoKeys.add(bucket.getKeyAsString());
                }
            }

            InternalBucketMetricValue minBucketValue = termsBucket.getAggregations().get("min_histo_bucket");
            assertThat(minBucketValue, notNullValue());
            assertThat(minBucketValue.getName(), equalTo("min_histo_bucket"));
            assertThat(minBucketValue.value(), equalTo(minHistoValue));
            assertThat(minBucketValue.keys(), equalTo(minHistoKeys.toArray(new String[minHistoKeys.size()])));
            if (minHistoValue < minTermsValue) {
                minTermsValue = minHistoValue;
                minTermsKeys = new ArrayList<>();
                minTermsKeys.add(termsBucket.getKeyAsString());
            } else if (minHistoValue == minTermsValue) {
                minTermsKeys.add(termsBucket.getKeyAsString());
            }
        }

        InternalBucketMetricValue minBucketValue = response.getAggregations().get("min_terms_bucket");
        assertThat(minBucketValue, notNullValue());
        assertThat(minBucketValue.getName(), equalTo("min_terms_bucket"));
        assertThat(minBucketValue.value(), equalTo(minTermsValue));
        assertThat(minBucketValue.keys(), equalTo(minTermsKeys.toArray(new String[minTermsKeys.size()])));
    }
,
(startLine=410 endLine=477 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/MaxBucketIT.java)
    public void testNested() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .addAggregation(
                        terms("terms")
                                .field("tag")
                                .order(BucketOrder.key(true))
                                .subAggregation(
                                        histogram("histo").field(SINGLE_VALUED_FIELD_NAME).interval(interval)
                                .extendedBounds(minRandomValue, maxRandomValue))
                                .subAggregation(maxBucket("max_histo_bucket", "histo>_count")))
                .addAggregation(maxBucket("max_terms_bucket", "terms>max_histo_bucket")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<? extends Terms.Bucket> termsBuckets = terms.getBuckets();
        assertThat(termsBuckets.size(), equalTo(interval));

        List<String> maxTermsKeys = new ArrayList<>();
        double maxTermsValue = Double.NEGATIVE_INFINITY;
        for (int i = 0; i < interval; ++i) {
            Terms.Bucket termsBucket = termsBuckets.get(i);
            assertThat(termsBucket, notNullValue());
            assertThat((String) termsBucket.getKey(), equalTo("tag" + (i % interval)));

            Histogram histo = termsBucket.getAggregations().get("histo");
            assertThat(histo, notNullValue());
            assertThat(histo.getName(), equalTo("histo"));
            List<? extends Bucket> buckets = histo.getBuckets();

            List<String> maxHistoKeys = new ArrayList<>();
            double maxHistoValue = Double.NEGATIVE_INFINITY;
            for (int j = 0; j < numValueBuckets; ++j) {
                Histogram.Bucket bucket = buckets.get(j);
                assertThat(bucket, notNullValue());
                assertThat(((Number) bucket.getKey()).longValue(), equalTo((long) j * interval));
                if (bucket.getDocCount() > maxHistoValue) {
                    maxHistoValue = bucket.getDocCount();
                    maxHistoKeys = new ArrayList<>();
                    maxHistoKeys.add(bucket.getKeyAsString());
                } else if (bucket.getDocCount() == maxHistoValue) {
                    maxHistoKeys.add(bucket.getKeyAsString());
                }
            }

            InternalBucketMetricValue maxBucketValue = termsBucket.getAggregations().get("max_histo_bucket");
            assertThat(maxBucketValue, notNullValue());
            assertThat(maxBucketValue.getName(), equalTo("max_histo_bucket"));
            assertThat(maxBucketValue.value(), equalTo(maxHistoValue));
            assertThat(maxBucketValue.keys(), equalTo(maxHistoKeys.toArray(new String[maxHistoKeys.size()])));
            if (maxHistoValue > maxTermsValue) {
                maxTermsValue = maxHistoValue;
                maxTermsKeys = new ArrayList<>();
                maxTermsKeys.add(termsBucket.getKeyAsString());
            } else if (maxHistoValue == maxTermsValue) {
                maxTermsKeys.add(termsBucket.getKeyAsString());
            }
        }

        InternalBucketMetricValue maxBucketValue = response.getAggregations().get("max_terms_bucket");
        assertThat(maxBucketValue, notNullValue());
        assertThat(maxBucketValue.getName(), equalTo("max_terms_bucket"));
        assertThat(maxBucketValue.value(), equalTo(maxTermsValue));
        assertThat(maxBucketValue.keys(), equalTo(maxTermsKeys.toArray(new String[maxTermsKeys.size()])));
    }
,
>
, <(startLine=80 endLine=105 srcPath=/root/NewExperiment/elasticsearchFilter/01571/src/test/java/org/elasticsearch/action/termvectors/GetTermVectorsTests.java)
    public void testExistingFieldWithNoTermVectorsNoNPE() throws Exception {
        XContentBuilder mapping = jsonBuilder().startObject().startObject("type1")
                .startObject("properties")
                        .startObject("existingfield")
                            .field("type", "string")
                            .field("term_vector", "with_positions_offsets_payloads")
                        .endObject()
                .endObject()
                .endObject().endObject();
        assertAcked(prepareCreate("test").addAlias(new Alias("alias")).addMapping("type1", mapping));

        ensureYellow();

        // when indexing a field that simply has a question mark, the term vectors will be null
        client().prepareIndex("test", "type1", "0").setSource("existingfield", "?").execute().actionGet();
        refresh();
        ActionFuture<TermVectorsResponse> termVector = client().termVectors(new TermVectorsRequest(indexOrAlias(), "type1", "0")
                .selectedFields(new String[]{"existingfield"}));

        // lets see if the null term vectors are caught...
        TermVectorsResponse actionGet = termVector.actionGet();
        assertThat(actionGet, notNullValue());
        assertThat(actionGet.isExists(), equalTo(true));
        assertThat(actionGet.getIndex(), equalTo("test"));
        assertThat(actionGet.getFields().terms("existingfield"), nullValue());
    }
,
(startLine=108 endLine=136 srcPath=/root/NewExperiment/elasticsearchFilter/01571/src/test/java/org/elasticsearch/action/termvectors/GetTermVectorsTests.java)
    public void testExistingFieldButNotInDocNPE() throws Exception {
        XContentBuilder mapping = jsonBuilder().startObject().startObject("type1")
                .startObject("properties")
                        .startObject("existingfield")
                            .field("type", "string")
                            .field("term_vector", "with_positions_offsets_payloads")
                        .endObject()
                .endObject()
                .endObject().endObject();
        assertAcked(prepareCreate("test").addAlias(new Alias("alias")).addMapping("type1", mapping));

        ensureYellow();

        // when indexing a field that simply has a question mark, the term vectors will be null
        client().prepareIndex("test", "type1", "0").setSource("anotherexistingfield", 1).execute().actionGet();
        refresh();
        ActionFuture<TermVectorsResponse> termVectors = client().termVectors(new TermVectorsRequest(indexOrAlias(), "type1", "0")
                .selectedFields(randomBoolean() ? new String[]{"existingfield"} : null)
                .termStatistics(true)
                .fieldStatistics(true)
                .dfs(true));

        // lets see if the null term vectors are caught...
        TermVectorsResponse actionGet = termVectors.actionGet();
        assertThat(actionGet, notNullValue());
        assertThat(actionGet.isExists(), equalTo(true));
        assertThat(actionGet.getIndex(), equalTo("test"));
        assertThat(actionGet.getFields().terms("existingfield"), nullValue());
    }
,
>
, <(startLine=244 endLine=263 srcPath=/root/NewExperiment/elasticsearchFilter/01620/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java)
        outer: for (ThreadPool.Info info : groups) {
            if ("my_pool1".equals(info.getName())) {
                foundPool1 = true;
                assertThat(info.getType(), equalTo("cached"));
            } else if ("my_pool2".equals(info.getName())) {
                foundPool2 = true;
                assertThat(info.getType(), equalTo("fixed"));
                assertThat(info.getMin(), equalTo(1));
                assertThat(info.getMax(), equalTo(1));
                assertThat(info.getQueueSize().singles(), equalTo(1l));
            } else {
                for (Field field : Names.class.getFields()) {
                    if (info.getName().equalsIgnoreCase(field.getName())) {
                        // This is ok it is a default thread pool
                        continue outer;
                    }
                }
                fail("Unexpected pool name: " + info.getName());
            }
        }
,
(startLine=276 endLine=295 srcPath=/root/NewExperiment/elasticsearchFilter/01620/src/test/java/org/elasticsearch/threadpool/UpdateThreadPoolSettingsTests.java)
        outer: for (ThreadPool.Info info : groups) {
            if ("my_pool1".equals(info.getName())) {
                foundPool1 = true;
                assertThat(info.getType(), equalTo("cached"));
            } else if ("my_pool2".equals(info.getName())) {
                foundPool2 = true;
                assertThat(info.getMax(), equalTo(10));
                assertThat(info.getMin(), equalTo(10));
                assertThat(info.getQueueSize().singles(), equalTo(1l));
                assertThat(info.getType(), equalTo("fixed"));
            } else {
                for (Field field : Names.class.getFields()) {
                    if (info.getName().equalsIgnoreCase(field.getName())) {
                        // This is ok it is a default thread pool
                        continue outer;
                    }
                }
                fail("Unexpected pool name: " + info.getName());
            }
        }
,
>
, <(startLine=98 endLine=112 srcPath=/root/NewExperiment/elasticsearchFilter/01762/core/src/test/java/org/elasticsearch/index/query/plugin/CustomQueryParserIT.java)
        for (BooleanClause clause : bq.clauses()) {
            DummyQueryParserPlugin.DummyQuery dummy = (DummyQueryParserPlugin.DummyQuery) clause.getQuery();
            switch (clause.getOccur()) {
                case FILTER:
                case MUST_NOT:
                    assertEquals(true, dummy.isFilter);
                    break;
                case MUST:
                case SHOULD:
                    assertEquals(false, dummy.isFilter);
                    break;
                default:
                    throw new AssertionError();
            }
        }
,
(startLine=123 endLine=137 srcPath=/root/NewExperiment/elasticsearchFilter/01762/core/src/test/java/org/elasticsearch/index/query/plugin/CustomQueryParserIT.java)
        for (BooleanClause clause : bq.clauses()) {
            DummyQueryParserPlugin.DummyQuery dummy = (DummyQueryParserPlugin.DummyQuery) clause.getQuery();
            switch (clause.getOccur()) {
                case FILTER:
                case MUST_NOT:
                    assertEquals(true, dummy.isFilter);
                    break;
                case MUST:
                case SHOULD:
                    assertEquals(false, dummy.isFilter);
                    break;
                default:
                    throw new AssertionError();
            }
        }
,
>
, <(startLine=60 endLine=69 srcPath=/root/NewExperiment/elasticsearchFilter/01709/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/movavg/models/HoltWintersModel.java)
            for (SeasonalityType policy : values()) {
                if (policy.parseField.match(text)) {
                    if (result == null) {
                        result = policy;
                    } else {
                        throw new IllegalStateException("Text can be parsed to 2 different seasonality types: text=[" + text
                                + "], " + "policies=" + Arrays.asList(result, policy));
                    }
                }
            }
,
(startLine=67 endLine=76 srcPath=/root/NewExperiment/elasticsearchFilter/01709/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/BucketHelpers.java)
            for (GapPolicy policy : values()) {
                if (policy.parseField.match(text)) {
                    if (result == null) {
                        result = policy;
                    } else {
                        throw new IllegalStateException("Text can be parsed to 2 different gap policies: text=[" + text
                                + "], " + "policies=" + Arrays.asList(result, policy));
                    }
                }
            }
,
>
, <(startLine=81 endLine=93 srcPath=/root/NewExperiment/elasticsearchFilter/01989/modules/lang-mustache/src/test/java/org/elasticsearch/script/mustache/MustacheScriptEngineTests.java)
    public void testSimple() throws IOException {
        String templateString =
                  "{" 
                + "\"inline\":{\"match_{{template}}\": {}},"
                + "\"params\":{\"template\":\"all\"}"
                + "}";
        XContentParser parser = createParser(JsonXContent.jsonXContent, templateString);
        Script script = Script.parse(parser);
        CompiledScript compiledScript = new CompiledScript(ScriptType.INLINE, null, "mustache",
                qe.compile(null, script.getIdOrCode(), Collections.emptyMap()));
        ExecutableScript executableScript = qe.executable(compiledScript, script.getParams());
        assertThat(((BytesReference) executableScript.run()).utf8ToString(), equalTo("{\"match_all\":{}}"));
    }
,
(startLine=95 endLine=109 srcPath=/root/NewExperiment/elasticsearchFilter/01989/modules/lang-mustache/src/test/java/org/elasticsearch/script/mustache/MustacheScriptEngineTests.java)
    public void testParseTemplateAsSingleStringWithConditionalClause() throws IOException {
        String templateString =
                  "{"
                + "  \"inline\" : \"{ \\\"match_{{#use_it}}{{template}}{{/use_it}}\\\":{} }\"," + "  \"params\":{"
                + "    \"template\":\"all\","
                + "    \"use_it\": true"
                + "  }"
                + "}";
        XContentParser parser = createParser(JsonXContent.jsonXContent, templateString);
        Script script = Script.parse(parser);
        CompiledScript compiledScript = new CompiledScript(ScriptType.INLINE, null, "mustache",
                qe.compile(null, script.getIdOrCode(), Collections.emptyMap()));
        ExecutableScript executableScript = qe.executable(compiledScript, script.getParams());
        assertThat(((BytesReference) executableScript.run()).utf8ToString(), equalTo("{ \"match_all\":{} }"));
    }
,
>
, <(startLine=59 endLine=86 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/test/java/org/elasticsearch/validate/RenderSearchTemplateIT.java)
    public void inlineTemplate() {
        Map<String, Object> params = new HashMap<>();
        params.put("value", "bar");
        params.put("size", 20);
        Template template = new Template(TEMPLATE_CONTENTS, ScriptType.INLINE, MustacheScriptEngineService.NAME, XContentType.JSON, params);
        RenderSearchTemplateResponse response = client().admin().indices().prepareRenderSearchTemplate().template(template).get();
        assertThat(response, notNullValue());
        BytesReference source = response.source();
        assertThat(source, notNullValue());
        Map<String, Object> sourceAsMap = XContentHelper.convertToMap(source, false).v2();
        assertThat(sourceAsMap, notNullValue());
        String expected = TEMPLATE_CONTENTS.replace("{{value}}", "bar").replace("{{size}}", "20");
        Map<String, Object> expectedMap = XContentHelper.convertToMap(new BytesArray(expected), false).v2();
        assertThat(sourceAsMap, equalTo(expectedMap));
        
        params = new HashMap<>();
        params.put("value", "baz");
        params.put("size", 100);
        template = new Template(TEMPLATE_CONTENTS, ScriptType.INLINE, MustacheScriptEngineService.NAME, XContentType.JSON, params);
        response = client().admin().indices().prepareRenderSearchTemplate().template(template).get();
        assertThat(response, notNullValue());
        source = response.source();
        assertThat(source, notNullValue());
        sourceAsMap = XContentHelper.convertToMap(source, false).v2();
        expected = TEMPLATE_CONTENTS.replace("{{value}}", "baz").replace("{{size}}", "100");
        expectedMap = XContentHelper.convertToMap(new BytesArray(expected), false).v2();
        assertThat(sourceAsMap, equalTo(expectedMap));
    }
,
(startLine=89 endLine=116 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/test/java/org/elasticsearch/validate/RenderSearchTemplateIT.java)
    public void indexedTemplate() {
        Map<String, Object> params = new HashMap<>();
        params.put("value", "bar");
        params.put("size", 20);
        Template template = new Template("index_template_1", ScriptType.INDEXED, MustacheScriptEngineService.NAME, XContentType.JSON, params);
        RenderSearchTemplateResponse response = client().admin().indices().prepareRenderSearchTemplate().template(template).get();
        assertThat(response, notNullValue());
        BytesReference source = response.source();
        assertThat(source, notNullValue());
        Map<String, Object> sourceAsMap = XContentHelper.convertToMap(source, false).v2();
        assertThat(sourceAsMap, notNullValue());
        String expected = TEMPLATE_CONTENTS.replace("{{value}}", "bar").replace("{{size}}", "20");
        Map<String, Object> expectedMap = XContentHelper.convertToMap(new BytesArray(expected), false).v2();
        assertThat(sourceAsMap, equalTo(expectedMap));
        
        params = new HashMap<>();
        params.put("value", "baz");
        params.put("size", 100);
        template = new Template("index_template_1", ScriptType.INDEXED, MustacheScriptEngineService.NAME, XContentType.JSON, params);
        response = client().admin().indices().prepareRenderSearchTemplate().template(template).get();
        assertThat(response, notNullValue());
        source = response.source();
        assertThat(source, notNullValue());
        sourceAsMap = XContentHelper.convertToMap(source, false).v2();
        expected = TEMPLATE_CONTENTS.replace("{{value}}", "baz").replace("{{size}}", "100");
        expectedMap = XContentHelper.convertToMap(new BytesArray(expected), false).v2();
        assertThat(sourceAsMap, equalTo(expectedMap));
    }
,
(startLine=119 endLine=146 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/test/java/org/elasticsearch/validate/RenderSearchTemplateIT.java)
    public void fileTemplate() {
        Map<String, Object> params = new HashMap<>();
        params.put("value", "bar");
        params.put("size", 20);
        Template template = new Template("file_template_1", ScriptType.FILE, MustacheScriptEngineService.NAME, XContentType.JSON, params);
        RenderSearchTemplateResponse response = client().admin().indices().prepareRenderSearchTemplate().template(template).get();
        assertThat(response, notNullValue());
        BytesReference source = response.source();
        assertThat(source, notNullValue());
        Map<String, Object> sourceAsMap = XContentHelper.convertToMap(source, false).v2();
        assertThat(sourceAsMap, notNullValue());
        String expected = TEMPLATE_CONTENTS.replace("{{value}}", "bar").replace("{{size}}", "20");
        Map<String, Object> expectedMap = XContentHelper.convertToMap(new BytesArray(expected), false).v2();
        assertThat(sourceAsMap, equalTo(expectedMap));
        
        params = new HashMap<>();
        params.put("value", "baz");
        params.put("size", 100);
        template = new Template("file_template_1", ScriptType.FILE, MustacheScriptEngineService.NAME, XContentType.JSON, params);
        response = client().admin().indices().prepareRenderSearchTemplate().template(template).get();
        assertThat(response, notNullValue());
        source = response.source();
        assertThat(source, notNullValue());
        sourceAsMap = XContentHelper.convertToMap(source, false).v2();
        expected = TEMPLATE_CONTENTS.replace("{{value}}", "baz").replace("{{size}}", "100");
        expectedMap = XContentHelper.convertToMap(new BytesArray(expected), false).v2();
        assertThat(sourceAsMap, equalTo(expectedMap));
    }
,
>
, <(startLine=705 endLine=737 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java)
    public void multiValuedField_WithValueScript_WithInheritedSubAggregator() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("terms").executionHint(randomExecutionHint()).field(MULTI_VALUED_FIELD_NAME)
                                .collectMode(randomFrom(SubAggCollectionMode.values())).script(new Script("'foo_' + _value"))
                                .subAggregation(count("count"))).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(6));

        for (int i = 0; i < 6; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("foo_val" + i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("foo_val" + i));
            if (i == 0 | i == 5) {
                assertThat(bucket.getDocCount(), equalTo(1l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat(valueCount.getValue(), equalTo(2l));
            } else {
                assertThat(bucket.getDocCount(), equalTo(2l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat("term[" + key(bucket) + "]", valueCount.getValue(), equalTo(4l));
            }
        }
    }
,
(startLine=844 endLine=876 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java)
    public void script_MultiValued_WithAggregatorInherited() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("terms").collectMode(randomFrom(SubAggCollectionMode.values())).executionHint(randomExecutionHint())
                                .script(new Script("doc['" + MULTI_VALUED_FIELD_NAME + "']")).subAggregation(count("count"))).execute()
                .actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(6));

        for (int i = 0; i < 6; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("val" + i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("val" + i));
            if (i == 0 | i == 5) {
                assertThat(bucket.getDocCount(), equalTo(1l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat(valueCount.getValue(), equalTo(2l));
            } else {
                assertThat(bucket.getDocCount(), equalTo(2l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat(valueCount.getValue(), equalTo(4l));
            }
        }
    }
,
(startLine=1719 endLine=1751 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java)
    public void multiValuedField_WithValueScript_WithInheritedSubAggregatorOldScriptAPI() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("terms").executionHint(randomExecutionHint()).field(MULTI_VALUED_FIELD_NAME)
                                .collectMode(randomFrom(SubAggCollectionMode.values())).script("'foo_' + _value")
                                .subAggregation(count("count"))).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(6));

        for (int i = 0; i < 6; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("foo_val" + i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("foo_val" + i));
            if (i == 0 | i == 5) {
                assertThat(bucket.getDocCount(), equalTo(1l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat(valueCount.getValue(), equalTo(2l));
            } else {
                assertThat(bucket.getDocCount(), equalTo(2l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat("term[" + key(bucket) + "]", valueCount.getValue(), equalTo(4l));
            }
        }
    }
,
(startLine=1873 endLine=1904 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/test/java/org/elasticsearch/search/aggregations/bucket/StringTermsTests.java)
    public void script_MultiValued_WithAggregatorInheritedOldScriptAPI() throws Exception {
        SearchResponse response = client()
                .prepareSearch("idx")
                .setTypes("type")
                .addAggregation(
                        terms("terms").collectMode(randomFrom(SubAggCollectionMode.values())).executionHint(randomExecutionHint())
                                .script("doc['" + MULTI_VALUED_FIELD_NAME + "']").subAggregation(count("count"))).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        assertThat(terms.getBuckets().size(), equalTo(6));

        for (int i = 0; i < 6; i++) {
            Terms.Bucket bucket = terms.getBucketByKey("val" + i);
            assertThat(bucket, notNullValue());
            assertThat(key(bucket), equalTo("val" + i));
            if (i == 0 | i == 5) {
                assertThat(bucket.getDocCount(), equalTo(1l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat(valueCount.getValue(), equalTo(2l));
            } else {
                assertThat(bucket.getDocCount(), equalTo(2l));
                ValueCount valueCount = bucket.getAggregations().get("count");
                assertThat(valueCount, notNullValue());
                assertThat(valueCount.getValue(), equalTo(4l));
            }
        }
    }
,
>
, <(startLine=68 endLine=79 srcPath=/root/NewExperiment/elasticsearchFilter/00703/src/test/java/org/elasticsearch/test/unit/index/analysis/AnalysisTestsHelper.java)
    public static void assertSimpleTSOutput(TokenStream stream, String[] expected) throws IOException {
        stream.reset();
        CharTermAttribute termAttr = stream.getAttribute(CharTermAttribute.class);
        Assert.assertNotNull(termAttr);
        int i = 0;
        while (stream.incrementToken()) {
            Assert.assertTrue(i < expected.length, "got extra term: " + termAttr.toString());
            Assert.assertEquals(termAttr.toString(), expected[i], "expected different term at index " + i);
            i++;
        }
        Assert.assertEquals(i, expected.length, "not all tokens produced");
    }
,
(startLine=81 endLine=94 srcPath=/root/NewExperiment/elasticsearchFilter/00703/src/test/java/org/elasticsearch/test/unit/index/analysis/AnalysisTestsHelper.java)
    public static void assertSimpleTSOutput(TokenStream stream, String[] expected, int[] posInc) throws IOException {
        stream.reset();
        CharTermAttribute termAttr = stream.getAttribute(CharTermAttribute.class);
        PositionIncrementAttribute posIncAttr = stream.getAttribute(PositionIncrementAttribute.class);
        Assert.assertNotNull(termAttr);
        int i = 0;
        while (stream.incrementToken()) {
            Assert.assertTrue(i < expected.length, "got extra term: " + termAttr.toString());
            Assert.assertEquals(termAttr.toString(), expected[i], "expected different term at index " + i);
            Assert.assertEquals(posIncAttr.getPositionIncrement(), posInc[i]);
            i++;
        }
        Assert.assertEquals(i, expected.length, "not all tokens produced");
    }
,
>
, <(startLine=211 endLine=227 srcPath=/root/NewExperiment/elasticsearchFilter/01397/src/main/java/jsr166e/Striped64.java)
                        if (busy == 0 && casBusy()) {
                            boolean created = false;
                            try {               // Recheck under lock
                                Cell[] rs; int m, j;
                                if ((rs = cells) != null &&
                                    (m = rs.length) > 0 &&
                                    rs[j = (m - 1) & h] == null) {
                                    rs[j] = r;
                                    created = true;
                                }
                            } finally {
                                busy = 0;
                            }
                            if (created)
                                break;
                            continue;           // Slot is now non-empty
                        }
,
(startLine=6177 endLine=6193 srcPath=/root/NewExperiment/elasticsearchFilter/01397/src/main/java/jsr166e/ConcurrentHashMapV8.java)
                            U.compareAndSwapInt(this, CELLSBUSY, 0, 1)) {
                            boolean created = false;
                            try {               // Recheck under lock
                                CounterCell[] rs; int m, j;
                                if ((rs = counterCells) != null &&
                                    (m = rs.length) > 0 &&
                                    rs[j = (m - 1) & h] == null) {
                                    rs[j] = r;
                                    created = true;
                                }
                            } finally {
                                cellsBusy = 0;
                            }
                            if (created)
                                break;
                            continue;           // Slot is now non-empty
                        }
,
>
, <(startLine=354 endLine=359 srcPath=/root/NewExperiment/elasticsearchFilter/00423/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java)
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(routingTable.index("test" + i).shards().size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).shards().size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).shards().get(0).state(), equalTo(INITIALIZING));
        }
,
(startLine=383 endLine=388 srcPath=/root/NewExperiment/elasticsearchFilter/00423/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java)
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(routingTable.index("test" + i).shards().size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).shards().size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).shards().get(0).state(), anyOf(equalTo(RELOCATING), equalTo(STARTED)));
        }
,
(startLine=400 endLine=405 srcPath=/root/NewExperiment/elasticsearchFilter/00423/modules/elasticsearch/src/test/java/org/elasticsearch/cluster/routing/allocation/SingleShardNoReplicasRoutingTests.java)
        for (int i = 0; i < numberOfIndices; i++) {
            assertThat(routingTable.index("test" + i).shards().size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).shards().size(), equalTo(1));
            assertThat(routingTable.index("test" + i).shard(0).shards().get(0).state(), anyOf(equalTo(RELOCATING), equalTo(STARTED)));
        }
,
>
, <(startLine=345 endLine=363 srcPath=/root/NewExperiment/elasticsearchFilter/02026/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/StatsBucketIT.java)
    public void testNoBuckets() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(terms("terms").field("tag").includeExclude(new IncludeExclude(null, "tag.*"))
                        .subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                .addAggregation(statsBucket("stats_bucket", "terms>sum")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<Terms.Bucket> buckets = terms.getBuckets();
        assertThat(buckets.size(), equalTo(0));

        StatsBucket statsBucketValue = response.getAggregations().get("stats_bucket");
        assertThat(statsBucketValue, notNullValue());
        assertThat(statsBucketValue.getName(), equalTo("stats_bucket"));
        assertThat(statsBucketValue.getAvg(), equalTo(Double.NaN));
    }
,
(startLine=299 endLine=317 srcPath=/root/NewExperiment/elasticsearchFilter/02026/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/SumBucketIT.java)
    public void testNoBuckets() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(terms("terms").field("tag").includeExclude(new IncludeExclude(null, "tag.*"))
                        .subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                .addAggregation(sumBucket("sum_bucket", "terms>sum")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<Terms.Bucket> buckets = terms.getBuckets();
        assertThat(buckets.size(), equalTo(0));

        InternalSimpleValue sumBucketValue = response.getAggregations().get("sum_bucket");
        assertThat(sumBucketValue, notNullValue());
        assertThat(sumBucketValue.getName(), equalTo("sum_bucket"));
        assertThat(sumBucketValue.value(), equalTo(0.0));
    }
,
(startLine=421 endLine=439 srcPath=/root/NewExperiment/elasticsearchFilter/02026/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/ExtendedStatsBucketIT.java)
    public void testNoBuckets() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(terms("terms").field("tag").includeExclude(new IncludeExclude(null, "tag.*"))
                        .subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                .addAggregation(extendedStatsBucket("extended_stats_bucket", "terms>sum")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<Terms.Bucket> buckets = terms.getBuckets();
        assertThat(buckets.size(), equalTo(0));

        ExtendedStatsBucket extendedStatsBucketValue = response.getAggregations().get("extended_stats_bucket");
        assertThat(extendedStatsBucketValue, notNullValue());
        assertThat(extendedStatsBucketValue.getName(), equalTo("extended_stats_bucket"));
        assertThat(extendedStatsBucketValue.getAvg(), equalTo(Double.NaN));
    }
,
(startLine=314 endLine=332 srcPath=/root/NewExperiment/elasticsearchFilter/02026/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/AvgBucketIT.java)
    public void testNoBuckets() throws Exception {
        SearchResponse response = client().prepareSearch("idx")
                .addAggregation(terms("terms").field("tag").includeExclude(new IncludeExclude(null, "tag.*"))
                        .subAggregation(sum("sum").field(SINGLE_VALUED_FIELD_NAME)))
                .addAggregation(avgBucket("avg_bucket", "terms>sum")).execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        assertThat(terms, notNullValue());
        assertThat(terms.getName(), equalTo("terms"));
        List<Terms.Bucket> buckets = terms.getBuckets();
        assertThat(buckets.size(), equalTo(0));

        InternalSimpleValue avgBucketValue = response.getAggregations().get("avg_bucket");
        assertThat(avgBucketValue, notNullValue());
        assertThat(avgBucketValue.getName(), equalTo("avg_bucket"));
        assertThat(avgBucketValue.value(), equalTo(Double.NaN));
    }
,
>
, <(startLine=93 endLine=105 srcPath=/root/NewExperiment/elasticsearchFilter/00143/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/field/support/AbstractConcurrentMapFieldDataCache.java)
        if (fieldData == null) {
            synchronized (creationMutex) {
                fieldData = (T) fieldDataCache.get(fieldName);
                if (fieldData == null) {
                    fieldData = FieldData.load(type, reader, fieldName, options);
                    fieldDataCache.put(fieldName, fieldData);
                } else if (!options.subsetOf(fieldData.options())) {
                    fieldData = FieldData.load(type, reader, fieldName, options);
                    fieldDataCache.put(fieldName, fieldData);
                }
                return fieldData;
            }
        } else if (!options.subsetOf(fieldData.options())) {
,
(startLine=105 endLine=118 srcPath=/root/NewExperiment/elasticsearchFilter/00143/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/field/support/AbstractConcurrentMapFieldDataCache.java)
        } else if (!options.subsetOf(fieldData.options())) {
            synchronized (creationMutex) {
                fieldData = (T) fieldDataCache.get(fieldName);
                if (fieldData != null) {
                    if (!options.subsetOf(fieldData.options())) {
                        fieldData = FieldData.load(type, reader, fieldName, options);
                        fieldDataCache.put(fieldName, fieldData);
                    }
                } else {
                    fieldData = FieldData.load(type, reader, fieldName, options);
                    fieldDataCache.put(fieldName, fieldData);
                }
            }
        }
,
>
, <(startLine=127 endLine=133 srcPath=/root/NewExperiment/elasticsearchFilter/01443/src/test/java/org/elasticsearch/index/analysis/commongrams/CommonGramsTokenFilterFactoryTests.java)
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick", "quick_brown", "brown", "brown_is", "is", "a", "a_fox", "fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
,
(startLine=134 endLine=140 srcPath=/root/NewExperiment/elasticsearchFilter/01443/src/test/java/org/elasticsearch/index/analysis/commongrams/CommonGramsTokenFilterFactoryTests.java)
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer_file").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick", "quick_brown", "brown", "brown_is", "is", "a", "a_fox", "fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
,
(startLine=200 endLine=206 srcPath=/root/NewExperiment/elasticsearchFilter/01443/src/test/java/org/elasticsearch/index/analysis/commongrams/CommonGramsTokenFilterFactoryTests.java)
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick_brown", "brown_is", "is", "a_fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
,
(startLine=207 endLine=213 srcPath=/root/NewExperiment/elasticsearchFilter/01443/src/test/java/org/elasticsearch/index/analysis/commongrams/CommonGramsTokenFilterFactoryTests.java)
        {
            AnalysisService analysisService = AnalysisTestsHelper.createAnalysisServiceFromSettings(settings);
            Analyzer analyzer = analysisService.analyzer("commongramsAnalyzer_file").analyzer();
            String source = "the quick brown is a fox or not";
            String[] expected = new String[] { "the", "quick_brown", "brown_is", "is", "a_fox", "fox_or", "or", "not" };
            assertTokenStreamContents(analyzer.tokenStream("test", source), expected);
        }
,
>
, <(startLine=39 endLine=50 srcPath=/root/NewExperiment/elasticsearchFilter/02355/core/src/test/java/org/elasticsearch/index/analysis/PatternAnalyzerTests.java)
  public void testNonWordPattern() throws IOException {
    // Split on non-letter pattern, do not lowercase, no stopwords
    PatternAnalyzer a = new PatternAnalyzer(Pattern.compile("\\W+"), false, null);
    assertAnalyzesTo(a, "The quick brown Fox,the abcd1234 (56.78) dc.",
                        new String[] { "The", "quick", "brown", "Fox", "the", "abcd1234", "56", "78", "dc" });

    // split on non-letter pattern, lowercase, english stopwords
    PatternAnalyzer b = new PatternAnalyzer(Pattern.compile("\\W+"), true,
                                            StopAnalyzer.ENGLISH_STOP_WORDS_SET);
    assertAnalyzesTo(b, "The quick brown Fox,the abcd1234 (56.78) dc.",
                         new String[] { "quick", "brown", "fox", "abcd1234", "56", "78", "dc" });
  }
,
(startLine=56 endLine=67 srcPath=/root/NewExperiment/elasticsearchFilter/02355/core/src/test/java/org/elasticsearch/index/analysis/PatternAnalyzerTests.java)
  public void testWhitespacePattern() throws IOException {
    // Split on whitespace patterns, do not lowercase, no stopwords
    PatternAnalyzer a = new PatternAnalyzer(Pattern.compile("\\s+"), false, null);
    assertAnalyzesTo(a, "The quick brown Fox,the abcd1234 (56.78) dc.",
                        new String[] { "The", "quick", "brown", "Fox,the", "abcd1234", "(56.78)", "dc." });

    // Split on whitespace patterns, lowercase, english stopwords
    PatternAnalyzer b = new PatternAnalyzer(Pattern.compile("\\s+"), true,
                                            StopAnalyzer.ENGLISH_STOP_WORDS_SET);
    assertAnalyzesTo(b, "The quick brown Fox,the abcd1234 (56.78) dc.",
                         new String[] { "quick", "brown", "fox,the", "abcd1234", "(56.78)", "dc." });
  }
,
>
, <(startLine=102 endLine=121 srcPath=/root/NewExperiment/elasticsearchFilter/00511/modules/elasticsearch/src/main/java/org/elasticsearch/transport/support/TransportStreams.java)
    public static void buildRequest(CachedStreamOutput.Entry cachedEntry, final long requestId, final String action, final Streamable message, TransportRequestOptions options) throws IOException {
        byte status = 0;
        status = TransportStreams.statusSetRequest(status);

        if (options.compress()) {
            status = TransportStreams.statusSetCompress(status);
            HandlesStreamOutput stream = cachedEntry.cachedHandlesLzfBytes();
            cachedEntry.bytes().write(HEADER_PLACEHOLDER);
            stream.writeUTF(action);
            message.writeTo(stream);
            stream.flush();
        } else {
            HandlesStreamOutput stream = cachedEntry.cachedHandlesBytes();
            cachedEntry.bytes().write(HEADER_PLACEHOLDER);
            stream.writeUTF(action);
            message.writeTo(stream);
            stream.flush();
        }
        TransportStreams.writeHeader(cachedEntry.bytes().unsafeByteArray(), cachedEntry.bytes().size(), requestId, status);
    }
,
(startLine=123 endLine=140 srcPath=/root/NewExperiment/elasticsearchFilter/00511/modules/elasticsearch/src/main/java/org/elasticsearch/transport/support/TransportStreams.java)
    public static void buildResponse(CachedStreamOutput.Entry cachedEntry, final long requestId, Streamable message, TransportResponseOptions options) throws IOException {
        byte status = 0;
        status = TransportStreams.statusSetResponse(status);

        if (options.compress()) {
            status = TransportStreams.statusSetCompress(status);
            HandlesStreamOutput stream = cachedEntry.cachedHandlesLzfBytes();
            cachedEntry.bytes().write(HEADER_PLACEHOLDER);
            message.writeTo(stream);
            stream.flush();
        } else {
            HandlesStreamOutput stream = cachedEntry.cachedHandlesBytes();
            cachedEntry.bytes().write(HEADER_PLACEHOLDER);
            message.writeTo(stream);
            stream.flush();
        }
        TransportStreams.writeHeader(cachedEntry.bytes().unsafeByteArray(), cachedEntry.bytes().size(), requestId, status);
    }
,
>
, <(startLine=67 endLine=75 srcPath=/root/NewExperiment/elasticsearchFilter/00654/src/main/java/org/elasticsearch/index/query/SpanNearQueryParser.java)
                if ("clauses".equals(currentFieldName)) {
                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                        Query query = parseContext.parseInnerQuery();
                        if (!(query instanceof SpanQuery)) {
                            throw new QueryParsingException(parseContext.index(), "spanNear [clauses] must be of type span query");
                        }
                        clauses.add((SpanQuery) query);
                    }
                } else {
,
(startLine=64 endLine=72 srcPath=/root/NewExperiment/elasticsearchFilter/00654/src/main/java/org/elasticsearch/index/query/SpanOrQueryParser.java)
                if ("clauses".equals(currentFieldName)) {
                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                        Query query = parseContext.parseInnerQuery();
                        if (!(query instanceof SpanQuery)) {
                            throw new QueryParsingException(parseContext.index(), "spanOr [clauses] must be of type span query");
                        }
                        clauses.add((SpanQuery) query);
                    }
                } else {
,
>
, <(startLine=42 endLine=68 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/common/util/concurrent/AbstractLifecycleRunnableTests.java)
    public void testDoRunOnlyRunsWhenNotStoppedOrClosed() throws Exception {
        Callable<?> runCallable = mock(Callable.class);

        // it's "not stopped or closed"
        when(lifecycle.stoppedOrClosed()).thenReturn(false);

        AbstractLifecycleRunnable runnable = new AbstractLifecycleRunnable(lifecycle, logger) {
            @Override
            public void onFailure(Exception e) {
                fail("It should not fail");
            }

            @Override
            protected void doRunInLifecycle() throws Exception {
                runCallable.call();
            }
        };

        runnable.run();

        InOrder inOrder = inOrder(lifecycle, logger, runCallable);

        inOrder.verify(lifecycle).stoppedOrClosed();
        inOrder.verify(runCallable).call();
        inOrder.verify(lifecycle).stoppedOrClosed(); // onAfter uses it too, but we're not testing it here
        inOrder.verifyNoMoreInteractions();
    }
,
(startLine=71 endLine=97 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/common/util/concurrent/AbstractLifecycleRunnableTests.java)
    public void testDoRunDoesNotRunWhenStoppedOrClosed() throws Exception {
        Callable<?> runCallable = mock(Callable.class);

        // it's stopped or closed
        when(lifecycle.stoppedOrClosed()).thenReturn(true);

        AbstractLifecycleRunnable runnable = new AbstractLifecycleRunnable(lifecycle, logger) {
            @Override
            public void onFailure(Exception e) {
                fail("It should not fail");
            }

            @Override
            protected void doRunInLifecycle() throws Exception {
                fail("Should not run with lifecycle stopped or closed.");
            }
        };

        runnable.run();

        InOrder inOrder = inOrder(lifecycle, logger, runCallable);

        inOrder.verify(lifecycle).stoppedOrClosed();
        inOrder.verify(logger).trace(anyString());
        inOrder.verify(lifecycle).stoppedOrClosed(); // onAfter uses it too, but we're not testing it here
        inOrder.verifyNoMoreInteractions();
    }
,
(startLine=139 endLine=168 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/common/util/concurrent/AbstractLifecycleRunnableTests.java)
    public void testOnAfterDoesNotHappenWhenStoppedOrClosed() throws Exception {
        Callable<?> runCallable = mock(Callable.class);

        // it's stopped or closed
        when(lifecycle.stoppedOrClosed()).thenReturn(true);

        AbstractLifecycleRunnable runnable = new AbstractLifecycleRunnable(lifecycle, logger) {
            @Override
            public void onFailure(Exception e) {
                fail("It should not fail");
            }

            @Override
            protected void doRunInLifecycle() throws Exception {
                fail("Should not run with lifecycle stopped or closed.");
            }

            @Override
            protected void onAfterInLifecycle() {
                fail("Should not run with lifecycle stopped or closed.");
            }
        };

        runnable.run();

        InOrder inOrder = inOrder(lifecycle, runCallable);

        inOrder.verify(lifecycle, times(2)).stoppedOrClosed();
        inOrder.verifyNoMoreInteractions();
    }
,
>
, <(startLine=67 endLine=72 srcPath=/root/NewExperiment/elasticsearchFilter/01573/src/test/java/org/elasticsearch/common/property/PropertyPlaceholderTest.java)
    public void testIgnoredUnresolvedPlaceholder() {
        PropertyPlaceholder propertyPlaceholder = new PropertyPlaceholder("${", "}", true);
        Map<String, String> map = new LinkedHashMap<>();
        PropertyPlaceholder.PlaceholderResolver placeholderResolver = new SimplePlaceholderResolver(map, false);
        assertEquals("${foo}", propertyPlaceholder.replacePlaceholders("${foo}", placeholderResolver));
    }
,
(startLine=83 endLine=88 srcPath=/root/NewExperiment/elasticsearchFilter/01573/src/test/java/org/elasticsearch/common/property/PropertyPlaceholderTest.java)
    public void testShouldIgnoreMissing() {
        PropertyPlaceholder propertyPlaceholder = new PropertyPlaceholder("${", "}", false);
        Map<String, String> map = new LinkedHashMap<>();
        PropertyPlaceholder.PlaceholderResolver placeholderResolver = new SimplePlaceholderResolver(map, true);
        assertEquals("bar", propertyPlaceholder.replacePlaceholders("bar${foo}", placeholderResolver));
    }
,
>
, <(startLine=168 endLine=181 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketselector/BucketSelectorPipelineAggregatorBuilder.java)
            } else if (token == XContentParser.Token.START_OBJECT) {
                if (context.getParseFieldMatcher().match(currentFieldName, ScriptField.SCRIPT)) {
                    script = Script.parse(parser, context.getParseFieldMatcher());
                } else if (context.getParseFieldMatcher().match(currentFieldName, BUCKETS_PATH)) {
                    Map<String, Object> map = parser.map();
                    bucketsPathsMap = new HashMap<>();
                    for (Map.Entry<String, Object> entry : map.entrySet()) {
                        bucketsPathsMap.put(entry.getKey(), String.valueOf(entry.getValue()));
                    }
                } else {
                    throw new ParsingException(parser.getTokenLocation(),
                            "Unknown key for a " + token + " in [" + reducerName + "]: [" + currentFieldName + "].");
                }
            } else {
,
(startLine=205 endLine=218 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregatorBuilder.java)
            } else if (token == XContentParser.Token.START_OBJECT) {
                if (context.getParseFieldMatcher().match(currentFieldName, ScriptField.SCRIPT)) {
                    script = Script.parse(parser, context.getParseFieldMatcher());
                } else if (context.getParseFieldMatcher().match(currentFieldName, BUCKETS_PATH)) {
                    Map<String, Object> map = parser.map();
                    bucketsPathsMap = new HashMap<>();
                    for (Map.Entry<String, Object> entry : map.entrySet()) {
                        bucketsPathsMap.put(entry.getKey(), String.valueOf(entry.getValue()));
                    }
                } else {
                    throw new ParsingException(parser.getTokenLocation(),
                            "Unknown key for a " + token + " in [" + reducerName + "]: [" + currentFieldName + "].");
                }
            } else {
,
>
, <(startLine=673 endLine=685 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/common/geo/builders/PolygonBuilder.java)
    private static int top(Coordinate[] points, int offset, int length) {
        int top = 0; // we start at 1 here since top points to 0
        for (int i = 1; i < length; i++) {
            if (points[offset + i].y < points[offset + top].y) {
                top = i;
            } else if (points[offset + i].y == points[offset + top].y) {
                if (points[offset + i].x < points[offset + top].x) {
                    top = i;
                }
            }
        }
        return top;
    }
,
(startLine=53 endLine=65 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchGeoAssertions.java)
    private static int top(Coordinate...points) {
        int top = 0;
        for (int i = 1; i < points.length; i++) {
            if(points[i].y < points[top].y) {
                top = i;
            } else if(points[i].y == points[top].y) {
                if(points[i].x <= points[top].x) {
                    top = i;
                }
            }
        }
        return top;
    }
,
>
, <(startLine=100 endLine=140 srcPath=/root/NewExperiment/elasticsearchFilter/00542/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java)
                for (IndexReader reader : readers) {
                    if (idReaders.containsKey(reader.getCoreCacheKey())) {
                        // no need, continue
                        continue;
                    }

                    reader.addReaderFinishedListener(this);
                    HashMap<String, TypeBuilder> readerBuilder = new HashMap<String, TypeBuilder>();
                    builders.put(reader.getCoreCacheKey(), readerBuilder);

                    String field = StringHelper.intern(UidFieldMapper.NAME);
                    TermDocs termDocs = reader.termDocs();
                    TermEnum termEnum = reader.terms(new Term(field));
                    try {
                        do {
                            Term term = termEnum.term();
                            if (term == null || term.field() != field) break;
                            // TODO we can optimize this, since type is the prefix, and we get terms ordered
                            // so, only need to move to the next type once its different
                            Uid uid = Uid.createUid(term.text());

                            TypeBuilder typeBuilder = readerBuilder.get(uid.type());
                            if (typeBuilder == null) {
                                typeBuilder = new TypeBuilder(reader);
                                readerBuilder.put(StringHelper.intern(uid.type()), typeBuilder);
                            }

                            BytesWrap idAsBytes = checkIfCanReuse(builders, new BytesWrap(uid.id()));
                            termDocs.seek(termEnum);
                            while (termDocs.next()) {
                                // when traversing, make sure to ignore deleted docs, so the key->docId will be correct
                                if (!reader.isDeleted(termDocs.doc())) {
                                    typeBuilder.idToDoc.put(idAsBytes, termDocs.doc());
                                }
                            }
                        } while (termEnum.next());
                    } finally {
                        termDocs.close();
                        termEnum.close();
                    }
                }
,
(startLine=144 endLine=191 srcPath=/root/NewExperiment/elasticsearchFilter/00542/modules/elasticsearch/src/main/java/org/elasticsearch/index/cache/id/simple/SimpleIdCache.java)
                for (IndexReader reader : readers) {
                    if (idReaders.containsKey(reader.getCoreCacheKey())) {
                        // no need, continue
                        continue;
                    }

                    Map<String, TypeBuilder> readerBuilder = builders.get(reader.getCoreCacheKey());

                    String field = StringHelper.intern(ParentFieldMapper.NAME);
                    TermDocs termDocs = reader.termDocs();
                    TermEnum termEnum = reader.terms(new Term(field));
                    try {
                        do {
                            Term term = termEnum.term();
                            if (term == null || term.field() != field) break;
                            // TODO we can optimize this, since type is the prefix, and we get terms ordered
                            // so, only need to move to the next type once its different
                            Uid uid = Uid.createUid(term.text());

                            TypeBuilder typeBuilder = readerBuilder.get(uid.type());
                            if (typeBuilder == null) {
                                typeBuilder = new TypeBuilder(reader);
                                readerBuilder.put(StringHelper.intern(uid.type()), typeBuilder);
                            }

                            BytesWrap idAsBytes = checkIfCanReuse(builders, new BytesWrap(uid.id()));
                            boolean added = false; // optimize for when all the docs are deleted for this id

                            termDocs.seek(termEnum);
                            while (termDocs.next()) {
                                // ignore deleted docs while we are at it
                                if (!reader.isDeleted(termDocs.doc())) {
                                    if (!added) {
                                        typeBuilder.parentIdsValues.add(idAsBytes);
                                        added = true;
                                    }
                                    typeBuilder.parentIdsOrdinals[termDocs.doc()] = typeBuilder.t;
                                }
                            }
                            if (added) {
                                typeBuilder.t++;
                            }
                        } while (termEnum.next());
                    } finally {
                        termDocs.close();
                        termEnum.close();
                    }
                }
,
>
, <(startLine=583 endLine=606 srcPath=/root/NewExperiment/elasticsearchFilter/01725/core/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchIT.java)
    public void testGeoContextDefaultMapping() throws Exception {
        GeoPoint berlinAlexanderplatz = GeoHashUtils.decode("u33dc1");

        XContentBuilder xContentBuilder = jsonBuilder().startObject()
            .startObject("poi").startObject("properties").startObject("suggest")
                .field("type", "completion")
                .startObject("context").startObject("location")
                    .field("type", "geo")
                    .field("precision", "500m")
                    .startObject("default").field("lat", berlinAlexanderplatz.lat()).field("lon", berlinAlexanderplatz.lon()).endObject()
                .endObject().endObject()
                .endObject().endObject().endObject()
            .endObject();

        assertAcked(prepareCreate(INDEX).addMapping("poi", xContentBuilder));
        ensureYellow();

        index(INDEX, "poi", "1", jsonBuilder().startObject().startObject("suggest").field("input", "Berlin Alexanderplatz").endObject().endObject());
        refresh();

        CompletionSuggestionBuilder suggestionBuilder = SuggestBuilders.completionSuggestion("suggestion").field("suggest").text("b").size(10).addGeoLocation("location", berlinAlexanderplatz.lat(), berlinAlexanderplatz.lon());
        SuggestResponse suggestResponse = client().prepareSuggest(INDEX).addSuggestion(suggestionBuilder).get();
        assertSuggestion(suggestResponse.getSuggest(), 0, "suggestion", "Berlin Alexanderplatz");
    }
,
(startLine=778 endLine=800 srcPath=/root/NewExperiment/elasticsearchFilter/01725/core/src/test/java/org/elasticsearch/search/suggest/ContextSuggestSearchIT.java)
    public void testThatGeoPathCanBeSelected() throws Exception {
        XContentBuilder xContentBuilder = jsonBuilder().startObject()
                .startObject("item").startObject("properties").startObject("suggest")
                .field("type", "completion")
                .startObject("context").startObject("location")
                .field("type", "geo")
                .field("precision", "5m")
                .field("path", "loc")
                .endObject().endObject()
                .endObject().endObject().endObject()
                .endObject();

        assertAcked(prepareCreate(INDEX).addMapping("item", xContentBuilder));
        ensureYellow();

        GeoPoint alexanderplatz = GeoHashUtils.decode("u33dc1");
        index(INDEX, "item", "1", jsonBuilder().startObject().startObject("suggest").field("input", "Berlin Alexanderplatz").endObject().startObject("loc").field("lat", alexanderplatz.lat()).field("lon", alexanderplatz.lon()).endObject().endObject());
        refresh();

        CompletionSuggestionBuilder suggestionBuilder = SuggestBuilders.completionSuggestion("suggestion").field("suggest").text("b").size(10).addGeoLocation("location", alexanderplatz.lat(), alexanderplatz.lon());
        SuggestResponse suggestResponse = client().prepareSuggest(INDEX).addSuggestion(suggestionBuilder).get();
        assertSuggestion(suggestResponse.getSuggest(), 0, "suggestion", "Berlin Alexanderplatz");
    }
,
>
, <(startLine=2903 endLine=2912 srcPath=/root/NewExperiment/elasticsearchFilter/00797/src/main/java/jsr166e/ForkJoinPool.java)
    protected ForkJoinTask<?> pollSubmission() {
        WorkQueue[] ws; WorkQueue w; ForkJoinTask<?> t;
        if ((ws = workQueues) != null) {
            for (int i = 0; i < ws.length; i += 2) {
                if ((w = ws[i]) != null && (t = w.poll()) != null)
                    return t;
            }
        }
        return null;
    }
,
(startLine=2903 endLine=2912 srcPath=/root/NewExperiment/elasticsearchFilter/00797/src/main/java/jsr166y/ForkJoinPool.java)
    protected ForkJoinTask<?> pollSubmission() {
        WorkQueue[] ws; WorkQueue w; ForkJoinTask<?> t;
        if ((ws = workQueues) != null) {
            for (int i = 0; i < ws.length; i += 2) {
                if ((w = ws[i]) != null && (t = w.poll()) != null)
                    return t;
            }
        }
        return null;
    }
,
>
, <(startLine=93 endLine=100 srcPath=/root/NewExperiment/elasticsearchFilter/00993/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java)
    public static String formatShardStatus(BroadcastOperationResponse response) {
        String msg = " Total shards: " + response.getTotalShards() + " Successful shards: " + response.getSuccessfulShards() + " & "
                + response.getFailedShards() + " shard failures:";
        for (ShardOperationFailedException failure : response.getShardFailures()) {
            msg += "\n " + failure.toString();
        }
        return msg;
    }
,
(startLine=102 endLine=109 srcPath=/root/NewExperiment/elasticsearchFilter/00993/src/test/java/org/elasticsearch/test/hamcrest/ElasticsearchAssertions.java)
    public static String formatShardStatus(SearchResponse response) {
        String msg = " Total shards: " + response.getTotalShards() + " Successful shards: " + response.getSuccessfulShards() + " & "
                + response.getFailedShards() + " shard failures:";
        for (ShardSearchFailure failure : response.getShardFailures()) {
            msg += "\n " + failure.toString();
        }
        return msg;
    }
,
>
, <(startLine=945 endLine=958 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ForkJoinPool.java)
                if (o instanceof CountedCompleter) {
                    for (t = (CountedCompleter<?>)o, r = t;;) {
                        if (r == root) {
                            if (base == b &&
                                U.compareAndSwapObject(a, j, t, null)) {
                                U.putOrderedInt(this, QBASE, b + 1);
                                t.doExec();
                            }
                            return true;
                        }
                        else if ((r = r.completer) == null)
                            break; // not part of root computation
                    }
                }
,
(startLine=1001 endLine=1013 srcPath=/root/NewExperiment/elasticsearchFilter/01297/src/main/java/jsr166e/ForkJoinPool.java)
                if ((o = U.getObject(a, j)) instanceof CountedCompleter) {
                    for (t = (CountedCompleter<?>)o, r = t;;) {
                        if (r == root) {
                            if (U.compareAndSwapObject(a, j, t, null)) {
                                top = s - 1;
                                t.doExec();
                            }
                            return true;
                        }
                        else if ((r = r.completer) == null)
                            break;
                    }
                }
,
>
, <(startLine=68 endLine=91 srcPath=/root/NewExperiment/elasticsearchFilter/02406/core/src/main/java/org/elasticsearch/search/aggregations/metrics/avg/AvgAggregator.java)
            final LeafBucketCollector sub) throws IOException {
        if (valuesSource == null) {
            return LeafBucketCollector.NO_OP_COLLECTOR;
        }
        final BigArrays bigArrays = context.bigArrays();
        final SortedNumericDoubleValues values = valuesSource.doubleValues(ctx);
        return new LeafBucketCollectorBase(sub, values) {
            @Override
            public void collect(int doc, long bucket) throws IOException {
                counts = bigArrays.grow(counts, bucket + 1);
                sums = bigArrays.grow(sums, bucket + 1);

                if (values.advanceExact(doc)) {
                    final int valueCount = values.docValueCount();
                    counts.increment(bucket, valueCount);
                    double sum = 0;
                    for (int i = 0; i < valueCount; i++) {
                        sum += values.nextValue();
                    }
                    sums.increment(bucket, sum);
                }
            }
        };
    }
,
(startLine=64 endLine=84 srcPath=/root/NewExperiment/elasticsearchFilter/02406/core/src/main/java/org/elasticsearch/search/aggregations/metrics/sum/SumAggregator.java)
            final LeafBucketCollector sub) throws IOException {
        if (valuesSource == null) {
            return LeafBucketCollector.NO_OP_COLLECTOR;
        }
        final BigArrays bigArrays = context.bigArrays();
        final SortedNumericDoubleValues values = valuesSource.doubleValues(ctx);
        return new LeafBucketCollectorBase(sub, values) {
            @Override
            public void collect(int doc, long bucket) throws IOException {
                sums = bigArrays.grow(sums, bucket + 1);
                if (values.advanceExact(doc)) {
                    final int valuesCount = values.docValueCount();
                    double sum = 0;
                    for (int i = 0; i < valuesCount; i++) {
                        sum += values.nextValue();
                    }
                    sums.increment(bucket, sum);
                }
            }
        };
    }
,
>
, <(startLine=128 endLine=149 srcPath=/root/NewExperiment/elasticsearchFilter/01610/src/main/java/org/elasticsearch/rest/action/update/RestUpdateAction.java)
            public RestResponse buildResponse(UpdateResponse response, XContentBuilder builder) throws Exception {
                builder.startObject();
                ActionWriteResponse.ShardInfo shardInfo = response.getShardInfo();
                builder.field(Fields._INDEX, response.getIndex())
                        .field(Fields._TYPE, response.getType())
                        .field(Fields._ID, response.getId())
                        .field(Fields._VERSION, response.getVersion());

                shardInfo.toXContent(builder, request);
                if (response.getGetResult() != null) {
                    builder.startObject(Fields.GET);
                    response.getGetResult().toXContentEmbedded(builder, request);
                    builder.endObject();
                }

                builder.endObject();
                RestStatus status = shardInfo.status();
                if (response.isCreated()) {
                    status = CREATED;
                }
                return new BytesRestResponse(status, builder);
            }
,
(startLine=112 endLine=127 srcPath=/root/NewExperiment/elasticsearchFilter/01610/src/main/java/org/elasticsearch/rest/action/index/RestIndexAction.java)
            public RestResponse buildResponse(IndexResponse response, XContentBuilder builder) throws Exception {
                builder.startObject();
                ActionWriteResponse.ShardInfo shardInfo = response.getShardInfo();
                builder.field(Fields._INDEX, response.getIndex())
                        .field(Fields._TYPE, response.getType())
                        .field(Fields._ID, response.getId())
                        .field(Fields._VERSION, response.getVersion());
                shardInfo.toXContent(builder, request);
                builder.field(Fields.CREATED, response.isCreated());
                builder.endObject();
                RestStatus status = shardInfo.status();
                if (response.isCreated()) {
                    status = CREATED;
                }
                return new BytesRestResponse(status, builder);
            }
,
>
, <(startLine=48 endLine=73 srcPath=/root/NewExperiment/elasticsearchFilter/02349/modules/analysis-common/src/test/java/org/elasticsearch/analysis/common/StemmerTokenFilterFactoryTests.java)
    public void testEnglishFilterFactory() throws IOException {
        int iters = scaledRandomIntBetween(20, 100);
        for (int i = 0; i < iters; i++) {
            Version v = VersionUtils.randomVersion(random());
            Settings settings = Settings.builder()
                    .put("index.analysis.filter.my_english.type", "stemmer")
                    .put("index.analysis.filter.my_english.language", "english")
                    .put("index.analysis.analyzer.my_english.tokenizer","whitespace")
                    .put("index.analysis.analyzer.my_english.filter","my_english")
                    .put(SETTING_VERSION_CREATED,v)
                    .put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString())
                    .build();

            ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(settings, PLUGIN);
            TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_english");
            assertThat(tokenFilter, instanceOf(StemmerTokenFilterFactory.class));
            Tokenizer tokenizer = new WhitespaceTokenizer();
            tokenizer.setReader(new StringReader("foo bar"));
            TokenStream create = tokenFilter.create(tokenizer);
            IndexAnalyzers indexAnalyzers = analysis.indexAnalyzers;
            NamedAnalyzer analyzer = indexAnalyzers.get("my_english");
            assertThat(create, instanceOf(PorterStemFilter.class));
            assertAnalyzesTo(analyzer, "consolingly", new String[]{"consolingli"});
        }

    }
,
(startLine=75 endLine=101 srcPath=/root/NewExperiment/elasticsearchFilter/02349/modules/analysis-common/src/test/java/org/elasticsearch/analysis/common/StemmerTokenFilterFactoryTests.java)
    public void testPorter2FilterFactory() throws IOException {
        int iters = scaledRandomIntBetween(20, 100);
        for (int i = 0; i < iters; i++) {

            Version v = VersionUtils.randomVersion(random());
            Settings settings = Settings.builder()
                    .put("index.analysis.filter.my_porter2.type", "stemmer")
                    .put("index.analysis.filter.my_porter2.language", "porter2")
                    .put("index.analysis.analyzer.my_porter2.tokenizer","whitespace")
                    .put("index.analysis.analyzer.my_porter2.filter","my_porter2")
                    .put(SETTING_VERSION_CREATED,v)
                    .put(Environment.PATH_HOME_SETTING.getKey(), createTempDir().toString())
                    .build();

            ESTestCase.TestAnalysis analysis = AnalysisTestsHelper.createTestAnalysisFromSettings(settings, PLUGIN);
            TokenFilterFactory tokenFilter = analysis.tokenFilter.get("my_porter2");
            assertThat(tokenFilter, instanceOf(StemmerTokenFilterFactory.class));
            Tokenizer tokenizer = new WhitespaceTokenizer();
            tokenizer.setReader(new StringReader("foo bar"));
            TokenStream create = tokenFilter.create(tokenizer);
            IndexAnalyzers indexAnalyzers = analysis.indexAnalyzers;
            NamedAnalyzer analyzer = indexAnalyzers.get("my_porter2");
            assertThat(create, instanceOf(SnowballFilter.class));
            assertAnalyzesTo(analyzer, "possibly", new String[]{"possibl"});
        }

    }
,
>
, <(startLine=2498 endLine=2537 srcPath=/root/NewExperiment/elasticsearchFilter/02400/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  public final PostfixContext postfix() throws RecognitionException {
    PostfixContext _localctx = new PostfixContext(_ctx, getState());
    enterRule(_localctx, 36, RULE_postfix);
    try {
      setState(351);
      _errHandler.sync(this);
      switch ( getInterpreter().adaptivePredict(_input,25,_ctx) ) {
      case 1:
        enterOuterAlt(_localctx, 1);
        {
        setState(348);
        callinvoke();
        }
        break;
      case 2:
        enterOuterAlt(_localctx, 2);
        {
        setState(349);
        fieldaccess();
        }
        break;
      case 3:
        enterOuterAlt(_localctx, 3);
        {
        setState(350);
        braceaccess();
        }
        break;
      }
    }
    catch (RecognitionException re) {
      _localctx.exception = re;
      _errHandler.reportError(this, re);
      _errHandler.recover(this, re);
    }
    finally {
      exitRule();
    }
    return _localctx;
  }
,
(startLine=3263 endLine=3302 srcPath=/root/NewExperiment/elasticsearchFilter/02400/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
  public final ArgumentContext argument() throws RecognitionException {
    ArgumentContext _localctx = new ArgumentContext(_ctx, getState());
    enterRule(_localctx, 56, RULE_argument);
    try {
      setState(465);
      _errHandler.sync(this);
      switch ( getInterpreter().adaptivePredict(_input,41,_ctx) ) {
      case 1:
        enterOuterAlt(_localctx, 1);
        {
        setState(462);
        expression(0);
        }
        break;
      case 2:
        enterOuterAlt(_localctx, 2);
        {
        setState(463);
        lambda();
        }
        break;
      case 3:
        enterOuterAlt(_localctx, 3);
        {
        setState(464);
        funcref();
        }
        break;
      }
    }
    catch (RecognitionException re) {
      _localctx.exception = re;
      _errHandler.reportError(this, re);
      _errHandler.recover(this, re);
    }
    finally {
      exitRule();
    }
    return _localctx;
  }
,
>
, <(startLine=513 endLine=525 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/HDRPercentilesIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            Percentiles percentiles = filter.getAggregations().get("percentiles");
            assertThat(percentiles, notNullValue());
            assertThat(percentiles.percentile(99), equalTo(Double.NaN));

        }
,
(startLine=268 endLine=280 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/ValueCountIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            ValueCount count = filter.getAggregations().get("count");
            assertThat(count, notNullValue());
            assertThat(count.value(), equalTo(0.0));

        }
,
(startLine=355 endLine=367 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MinIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            Min min = filter.getAggregations().get("min");
            assertThat(min, notNullValue());
            assertThat(min.value(), equalTo(Double.POSITIVE_INFINITY));

        }
,
(startLine=343 endLine=355 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/MaxIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            Max max = filter.getAggregations().get("max");
            assertThat(max, notNullValue());
            assertThat(max.value(), equalTo(Double.NEGATIVE_INFINITY));

        }
,
(startLine=332 endLine=344 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/SumIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            Sum sum = filter.getAggregations().get("sum");
            assertThat(sum, notNullValue());
            assertThat(sum.value(), equalTo(0.0));

        }
,
(startLine=458 endLine=470 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/TDigestPercentilesIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            Percentiles percentiles = filter.getAggregations().get("percentiles");
            assertThat(percentiles, notNullValue());
            assertThat(percentiles.percentile(99), equalTo(Double.NaN));

        }
,
(startLine=335 endLine=347 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/search/aggregations/metrics/AvgIT.java)
        for (int i = 0; i < 10; i++) {
            Terms.Bucket bucket = buckets.get(i);
            assertThat(bucket, notNullValue());
            assertThat(bucket.getKeyAsNumber(), equalTo((long) i + 1));
            assertThat(bucket.getDocCount(), equalTo(1L));
            Filter filter = bucket.getAggregations().get("filter");
            assertThat(filter, notNullValue());
            assertThat(filter.getDocCount(), equalTo(0L));
            Avg avg = filter.getAggregations().get("avg");
            assertThat(avg, notNullValue());
            assertThat(avg.value(), equalTo(Double.NaN));

        }
,
>
, <(startLine=74 endLine=131 srcPath=/root/NewExperiment/elasticsearchFilter/01212/src/test/java/org/elasticsearch/index/mapper/geo/LatLonMappingGeoPointTests.java)
    public void testValidateLatLonValues() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties").startObject("point").field("type", "geo_point").field("lat_lon", true).field("normalize", false).field("validate", true).endObject().endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTestUtils.newParser().parse(mapping);


        ParsedDocument doc = defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 90).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", -91).field("lon", 1.3).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 91).field("lon", 1.3).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 1.2).field("lon", -181).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }

        try {
            defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                    .startObject()
                    .startObject("point").field("lat", 1.2).field("lon", 181).endObject()
                    .endObject()
                    .bytes());
            fail();
        } catch (MapperParsingException e) {

        }
    }
,
(startLine=135 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/01212/src/test/java/org/elasticsearch/index/mapper/geo/LatLonMappingGeoPointTests.java)
    public void testNoValidateLatLonValues() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties").startObject("point").field("type", "geo_point").field("lat_lon", true).field("normalize", false).field("validate", false).endObject().endObject()
                .endObject().endObject().string();

        DocumentMapper defaultMapper = MapperTestUtils.newParser().parse(mapping);


        ParsedDocument doc = defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 90).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", -91).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 91).field("lon", 1.3).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 1.2).field("lon", -181).endObject()
                .endObject()
                .bytes());

        defaultMapper.parse("type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .startObject("point").field("lat", 1.2).field("lon", 181).endObject()
                .endObject()
                .bytes());
    }
,
>
, <(startLine=90 endLine=109 srcPath=/root/NewExperiment/elasticsearchFilter/01938/core/src/test/java/org/elasticsearch/search/aggregations/support/ScriptValuesTests.java)
    public void testLongs() {
        final Object[][] values = new Long[randomInt(10)][];
        for (int i = 0; i < values.length; ++i) {
            Long[] longs = new Long[randomInt(8)];
            for (int j = 0; j < longs.length; ++j) {
                longs[j] = randomLong();
            }
            Arrays.sort(longs);
            values[i] = longs;
        }
        FakeSearchScript script = new FakeSearchScript(values);
        ScriptLongValues scriptValues = new ScriptLongValues(script);
        for (int i = 0; i < values.length; ++i) {
            scriptValues.setDocument(i);
            assertEquals(values[i].length, scriptValues.count());
            for (int j = 0; j < values[i].length; ++j) {
                assertEquals(values[i][j], scriptValues.valueAt(j));
            }
        }
    }
,
(startLine=111 endLine=130 srcPath=/root/NewExperiment/elasticsearchFilter/01938/core/src/test/java/org/elasticsearch/search/aggregations/support/ScriptValuesTests.java)
    public void testBooleans() {
        final Object[][] values = new Boolean[randomInt(10)][];
        for (int i = 0; i < values.length; ++i) {
            Boolean[] booleans = new Boolean[randomInt(8)];
            for (int j = 0; j < booleans.length; ++j) {
                booleans[j] = randomBoolean();
            }
            Arrays.sort(booleans);
            values[i] = booleans;
        }
        FakeSearchScript script = new FakeSearchScript(values);
        ScriptLongValues scriptValues = new ScriptLongValues(script);
        for (int i = 0; i < values.length; ++i) {
            scriptValues.setDocument(i);
            assertEquals(values[i].length, scriptValues.count());
            for (int j = 0; j < values[i].length; ++j) {
                assertEquals(values[i][j], scriptValues.valueAt(j) == 1L);
            }
        }
    }
,
(startLine=132 endLine=151 srcPath=/root/NewExperiment/elasticsearchFilter/01938/core/src/test/java/org/elasticsearch/search/aggregations/support/ScriptValuesTests.java)
    public void testDoubles() {
        final Object[][] values = new Double[randomInt(10)][];
        for (int i = 0; i < values.length; ++i) {
            Double[] doubles = new Double[randomInt(8)];
            for (int j = 0; j < doubles.length; ++j) {
                doubles[j] = randomDouble();
            }
            Arrays.sort(doubles);
            values[i] = doubles;
        }
        FakeSearchScript script = new FakeSearchScript(values);
        ScriptDoubleValues scriptValues = new ScriptDoubleValues(script);
        for (int i = 0; i < values.length; ++i) {
            scriptValues.setDocument(i);
            assertEquals(values[i].length, scriptValues.count());
            for (int j = 0; j < values[i].length; ++j) {
                assertEquals(values[i][j], scriptValues.valueAt(j));
            }
        }
    }
,
(startLine=153 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/01938/core/src/test/java/org/elasticsearch/search/aggregations/support/ScriptValuesTests.java)
    public void testBytes() {
        final String[][] values = new String[randomInt(10)][];
        for (int i = 0; i < values.length; ++i) {
            String[] strings = new String[randomInt(8)];
            for (int j = 0; j < strings.length; ++j) {
                strings[j] = RandomStrings.randomAsciiOfLength(random(), 5);
            }
            Arrays.sort(strings);
            values[i] = strings;
        }
        FakeSearchScript script = new FakeSearchScript(values);
        ScriptBytesValues scriptValues = new ScriptBytesValues(script);
        for (int i = 0; i < values.length; ++i) {
            scriptValues.setDocument(i);
            assertEquals(values[i].length, scriptValues.count());
            for (int j = 0; j < values[i].length; ++j) {
                assertEquals(new BytesRef(values[i][j]), scriptValues.valueAt(j));
            }
        }
    }
,
>
, <(startLine=185 endLine=195 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketscript/BucketScriptPipelineAggregationBuilder.java)
                if (BUCKETS_PATH.match(currentFieldName)) {
                    List<String> paths = new ArrayList<>();
                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                        String path = parser.text();
                        paths.add(path);
                    }
                    bucketsPathsMap = new HashMap<>();
                    for (int i = 0; i < paths.size(); i++) {
                        bucketsPathsMap.put("_value" + i, paths.get(i));
                    }
                } else {
,
(startLine=148 endLine=158 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/pipeline/bucketselector/BucketSelectorPipelineAggregationBuilder.java)
                if (BUCKETS_PATH.match(currentFieldName)) {
                    List<String> paths = new ArrayList<>();
                    while ((token = parser.nextToken()) != XContentParser.Token.END_ARRAY) {
                        String path = parser.text();
                        paths.add(path);
                    }
                    bucketsPathsMap = new HashMap<>();
                    for (int i = 0; i < paths.size(); i++) {
                        bucketsPathsMap.put("_value" + i, paths.get(i));
                    }
                } else {
,
>
, <(startLine=1196 endLine=1211 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgTests.java)
        try {
            client()
                .prepareSearch("idx").setTypes("type")
                .addAggregation(
                        histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                .subAggregation(metric)
                                .subAggregation(movingAvg("movavg_counts")
                                        .window(numBuckets)
                                        .modelBuilder(new SimpleModel.SimpleModelBuilder())
                                        .gapPolicy(gapPolicy)
                                        .minimize(true)
                                        .setBucketsPaths("_count"))
                ).execute().actionGet();
            fail("Simple Model cannot be minimized, but an exception was not thrown");
        } catch (SearchPhaseExecutionException e) {
,
(startLine=1215 endLine=1230 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgTests.java)
        try {
            client()
                    .prepareSearch("idx").setTypes("type")
                    .addAggregation(
                            histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                    .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                    .subAggregation(metric)
                                    .subAggregation(movingAvg("movavg_counts")
                                            .window(numBuckets)
                                            .modelBuilder(new LinearModel.LinearModelBuilder())
                                            .gapPolicy(gapPolicy)
                                            .minimize(true)
                                            .setBucketsPaths("_count"))
                    ).execute().actionGet();
            fail("Linear Model cannot be minimized, but an exception was not thrown");
        } catch (SearchPhaseExecutionException e) {
,
(startLine=1247 endLine=1265 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/moving/avg/MovAvgTests.java)
        for (MovAvgModelBuilder builder : builders) {
            try {
                client()
                        .prepareSearch("idx").setTypes("type")
                        .addAggregation(
                                histogram("histo").field(INTERVAL_FIELD).interval(interval)
                                        .extendedBounds(0L, (long) (interval * (numBuckets - 1)))
                                        .subAggregation(metric)
                                        .subAggregation(movingAvg("movavg_counts")
                                                .window(numBuckets)
                                                .modelBuilder(builder)
                                                .gapPolicy(gapPolicy)
                                                .minimize(true)
                                                .setBucketsPaths("_count"))
                        ).execute().actionGet();
            } catch (SearchPhaseExecutionException e) {
                fail("Model [" + builder.toString() + "] can be minimized, but an exception was thrown");
            }
        }
,
>
, <(startLine=69 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/01732/core/src/test/java/org/elasticsearch/index/query/HasChildQueryBuilderTests.java)
    protected void setSearchContext(String[] types) {
        final MapperService mapperService = queryParserService().mapperService;
        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
        TestSearchContext testSearchContext = new TestSearchContext() {
            private InnerHitsContext context;


            @Override
            public void innerHits(InnerHitsContext innerHitsContext) {
                context = innerHitsContext;
            }

            @Override
            public InnerHitsContext innerHits() {
                return context;
            }

            @Override
            public MapperService mapperService() {
                return mapperService; // need to build / parse inner hits sort fields
            }

            @Override
            public IndexFieldDataService fieldData() {
                return fieldData; // need to build / parse inner hits sort fields
            }
        };
        testSearchContext.setTypes(types);
        SearchContext.setCurrent(testSearchContext);
    }
,
(startLine=60 endLine=89 srcPath=/root/NewExperiment/elasticsearchFilter/01732/core/src/test/java/org/elasticsearch/index/query/NestedQueryBuilderTests.java)
    protected void setSearchContext(String[] types) {
        final MapperService mapperService = queryParserService().mapperService;
        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
        TestSearchContext testSearchContext = new TestSearchContext() {
            private InnerHitsContext context;


            @Override
            public void innerHits(InnerHitsContext innerHitsContext) {
                context = innerHitsContext;
            }

            @Override
            public InnerHitsContext innerHits() {
                return context;
            }

            @Override
            public MapperService mapperService() {
                return mapperService; // need to build / parse inner hits sort fields
            }

            @Override
            public IndexFieldDataService fieldData() {
                return fieldData; // need to build / parse inner hits sort fields
            }
        };
        testSearchContext.setTypes(types);
        SearchContext.setCurrent(testSearchContext);
    }
,
(startLine=69 endLine=98 srcPath=/root/NewExperiment/elasticsearchFilter/01732/core/src/test/java/org/elasticsearch/index/query/HasParentQueryBuilderTests.java)
    protected void setSearchContext(String[] types) {
        final MapperService mapperService = queryParserService().mapperService;
        final IndexFieldDataService fieldData = queryParserService().fieldDataService;
        TestSearchContext testSearchContext = new TestSearchContext() {
            private InnerHitsContext context;


            @Override
            public void innerHits(InnerHitsContext innerHitsContext) {
                context = innerHitsContext;
            }

            @Override
            public InnerHitsContext innerHits() {
                return context;
            }

            @Override
            public MapperService mapperService() {
                return mapperService; // need to build / parse inner hits sort fields
            }

            @Override
            public IndexFieldDataService fieldData() {
                return fieldData; // need to build / parse inner hits sort fields
            }
        };
        testSearchContext.setTypes(types);
        SearchContext.setCurrent(testSearchContext);
    }
,
>
, <(startLine=2139 endLine=2158 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
        {
        setState(310);
        primary();
        setState(314);
        _errHandler.sync(this);
        _alt = getInterpreter().adaptivePredict(_input,21,_ctx);
        while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
          if ( _alt==1 ) {
            {
            {
            setState(311);
            postfix();
            }
            } 
          }
          setState(316);
          _errHandler.sync(this);
          _alt = getInterpreter().adaptivePredict(_input,21,_ctx);
        }
        }
,
(startLine=2163 endLine=2184 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
        {
        setState(317);
        decltype();
        setState(318);
        postdot();
        setState(322);
        _errHandler.sync(this);
        _alt = getInterpreter().adaptivePredict(_input,22,_ctx);
        while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
          if ( _alt==1 ) {
            {
            {
            setState(319);
            postfix();
            }
            } 
          }
          setState(324);
          _errHandler.sync(this);
          _alt = getInterpreter().adaptivePredict(_input,22,_ctx);
        }
        }
,
(startLine=2853 endLine=2872 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/modules/lang-painless/src/main/java/org/elasticsearch/painless/antlr/PainlessParser.java)
          {
          setState(378);
          postdot();
          setState(382);
          _errHandler.sync(this);
          _alt = getInterpreter().adaptivePredict(_input,28,_ctx);
          while ( _alt!=2 && _alt!=org.antlr.v4.runtime.atn.ATN.INVALID_ALT_NUMBER ) {
            if ( _alt==1 ) {
              {
              {
              setState(379);
              postfix();
              }
              } 
            }
            setState(384);
            _errHandler.sync(this);
            _alt = getInterpreter().adaptivePredict(_input,28,_ctx);
          }
          }
,
>
, <(startLine=265 endLine=280 srcPath=/root/NewExperiment/elasticsearchFilter/01712/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/SubAggregationSearchCollectModeBenchmark.java)
        for (int j = 0; j < QUERY_WARMUP; j++) {
            SearchResponse searchResponse = client.prepareSearch("test")
                    .setSize(0)
                    .setQuery(matchAllQuery())
                    .addAggregation(AggregationBuilders.terms(name + "s_value").field("s_value").collectMode(collectionModes[0])
                            .subAggregation(AggregationBuilders.terms(name + "l_value").field("l_value").collectMode(collectionModes[1])
                                    .subAggregation(AggregationBuilders.terms(name + "s_value_dv").field("s_value_dv").collectMode(collectionModes[2])
                                            .subAggregation(AggregationBuilders.terms(name + "l_value_dv").field("l_value_dv").collectMode(collectionModes[3])))))
                    .execute().actionGet();
            if (j == 0) {
                System.out.println("--> Loading : took: " + searchResponse.getTook());
            }
            if (searchResponse.getHits().totalHits() != COUNT) {
                System.err.println("--> mismatch on hits");
            }
        }
,
(startLine=286 endLine=299 srcPath=/root/NewExperiment/elasticsearchFilter/01712/core/src/test/java/org/elasticsearch/benchmark/search/aggregations/SubAggregationSearchCollectModeBenchmark.java)
        for (int j = 0; j < QUERY_COUNT; j++) {
            SearchResponse searchResponse = client.prepareSearch("test")
                    .setSize(0)
                    .setQuery(matchAllQuery())
                    .addAggregation(AggregationBuilders.terms(name + "s_value").field("s_value").collectMode(collectionModes[0])
                            .subAggregation(AggregationBuilders.terms(name + "l_value").field("l_value").collectMode(collectionModes[1])
                                    .subAggregation(AggregationBuilders.terms(name + "s_value_dv").field("s_value_dv").collectMode(collectionModes[2])
                                            .subAggregation(AggregationBuilders.terms(name + "l_value_dv").field("l_value_dv").collectMode(collectionModes[3])))))
                    .execute().actionGet();
            if (searchResponse.getHits().totalHits() != COUNT) {
                System.err.println("--> mismatch on hits");
            }
            totalQueryTime += searchResponse.getTookInMillis();
        }
,
>
, <(startLine=132 endLine=141 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java)
    static void trySetMaxSizeVirtualMemory() {
        if (Constants.LINUX || Constants.MAC_OS_X) {
            final JNACLibrary.Rlimit rlimit = new JNACLibrary.Rlimit();
            if (JNACLibrary.getrlimit(JNACLibrary.RLIMIT_AS, rlimit) == 0) {
                MAX_SIZE_VIRTUAL_MEMORY = rlimit.rlim_cur.longValue();
            } else {
                logger.warn("unable to retrieve max size virtual memory [" + JNACLibrary.strerror(Native.getLastError()) + "]");
            }
        }
    }
,
(startLine=143 endLine=152 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/bootstrap/JNANatives.java)
    static void trySetMaxFileSize() {
        if (Constants.LINUX || Constants.MAC_OS_X) {
            final JNACLibrary.Rlimit rlimit = new JNACLibrary.Rlimit();
            if (JNACLibrary.getrlimit(JNACLibrary.RLIMIT_FSIZE, rlimit) == 0) {
                MAX_FILE_SIZE = rlimit.rlim_cur.longValue();
            } else {
                logger.warn("unable to retrieve max file size [" + JNACLibrary.strerror(Native.getLastError()) + "]");
            }
        }
    }
,
>
, <(startLine=122 endLine=131 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, greaterThan(100.0));
        }
,
(startLine=158 endLine=167 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, lessThan(10000.0));
        }
,
(startLine=218 endLine=227 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field3SumValue - field2SumValue, greaterThan(0.0));
        }
,
(startLine=289 endLine=298 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, greaterThan(100.0));
        }
,
(startLine=327 endLine=336 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, greaterThan(100.0));
        }
,
(startLine=362 endLine=371 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, greaterThan(100.0));
        }
,
(startLine=396 endLine=405 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, greaterThan(100.0));
        }
,
(startLine=457 endLine=466 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/pipeline/BucketSelectorTests.java)
        for (int i = 0; i < buckets.size(); ++i) {
            Histogram.Bucket bucket = buckets.get(i);
            Sum field2Sum = bucket.getAggregations().get("field2Sum");
            assertThat(field2Sum, notNullValue());
            double field2SumValue = field2Sum.getValue();
            Sum field3Sum = bucket.getAggregations().get("field3Sum");
            assertThat(field3Sum, notNullValue());
            double field3SumValue = field3Sum.getValue();
            assertThat(field2SumValue + field3SumValue, greaterThan(100.0));
        }
,
>
, <(startLine=162 endLine=194 srcPath=/root/NewExperiment/elasticsearchFilter/01705/src/test/java/org/elasticsearch/indices/SycnedFlushSingleNodeTest.java)
    public void testFailAfterIntermediateCommit() throws InterruptedException {
        createIndex("test");
        client().prepareIndex("test", "test", "1").setSource("{}").get();
        IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
        IndexShard shard = test.shard(0);

        SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
        final ShardId shardId = shard.shardId();
        final ClusterState state = getInstanceFromNode(ClusterService.class).state();
        final IndexShardRoutingTable shardRoutingTable = flushService.getActiveShardRoutings(shardId, state);
        final List<ShardRouting> activeShards = shardRoutingTable.activeShards();
        assertEquals("exactly one active shard", 1, activeShards.size());
        Map<String, Engine.CommitId> commitIds = SyncedFlushUtil.sendPreSyncRequests(flushService, activeShards, state, shardId);
        assertEquals("exactly one commit id", 1, commitIds.size());
        if (randomBoolean()) {
            client().prepareIndex("test", "test", "2").setSource("{}").get();
        }
        client().admin().indices().prepareFlush("test").setForce(true).get();
        String syncId = Strings.base64UUID();
        final SyncedFlushUtil.LatchedListener<SyncedFlushService.SyncedFlushResult> listener = new SyncedFlushUtil.LatchedListener();
        flushService.sendSyncRequests(syncId, activeShards, state, commitIds, shardId, listener);
        listener.latch.await();
        assertNull(listener.error);
        SyncedFlushService.SyncedFlushResult syncedFlushResult = listener.result;
        assertNotNull(syncedFlushResult);
        assertEquals(0, syncedFlushResult.successfulShards());
        assertEquals(1, syncedFlushResult.totalShards());
        assertEquals(syncId, syncedFlushResult.syncId());
        assertNotNull(syncedFlushResult.shardResponses().get(activeShards.get(0)));
        assertFalse(syncedFlushResult.shardResponses().get(activeShards.get(0)).success());
        assertEquals("commit has changed", syncedFlushResult.shardResponses().get(activeShards.get(0)).failureReason());
        ElasticsearchAssertions.assertVersionSerializable(syncedFlushResult);
    }
,
(startLine=196 endLine=225 srcPath=/root/NewExperiment/elasticsearchFilter/01705/src/test/java/org/elasticsearch/indices/SycnedFlushSingleNodeTest.java)
    public void testFailWhenCommitIsMissing() throws InterruptedException {
        createIndex("test");
        client().prepareIndex("test", "test", "1").setSource("{}").get();
        IndexService test = getInstanceFromNode(IndicesService.class).indexService("test");
        IndexShard shard = test.shard(0);

        SyncedFlushService flushService = getInstanceFromNode(SyncedFlushService.class);
        final ShardId shardId = shard.shardId();
        final ClusterState state = getInstanceFromNode(ClusterService.class).state();
        final IndexShardRoutingTable shardRoutingTable = flushService.getActiveShardRoutings(shardId, state);
        final List<ShardRouting> activeShards = shardRoutingTable.activeShards();
        assertEquals("exactly one active shard", 1, activeShards.size());
        Map<String, Engine.CommitId> commitIds =  SyncedFlushUtil.sendPreSyncRequests(flushService, activeShards, state, shardId);
        assertEquals("exactly one commit id", 1, commitIds.size());
        commitIds.clear(); // wipe it...
        String syncId = Strings.base64UUID();
        SyncedFlushUtil.LatchedListener<SyncedFlushService.SyncedFlushResult> listener = new SyncedFlushUtil.LatchedListener();
        flushService.sendSyncRequests(syncId, activeShards, state, commitIds, shardId, listener);
        listener.latch.await();
        assertNull(listener.error);
        SyncedFlushService.SyncedFlushResult syncedFlushResult = listener.result;
        assertNotNull(syncedFlushResult);
        assertEquals(0, syncedFlushResult.successfulShards());
        assertEquals(1, syncedFlushResult.totalShards());
        assertEquals(syncId, syncedFlushResult.syncId());
        assertNotNull(syncedFlushResult.shardResponses().get(activeShards.get(0)));
        assertFalse(syncedFlushResult.shardResponses().get(activeShards.get(0)).success());
        assertEquals("no commit id from pre-sync flush", syncedFlushResult.shardResponses().get(activeShards.get(0)).failureReason());
        ElasticsearchAssertions.assertVersionSerializable(syncedFlushResult);
    }
,
>
, <(startLine=166 endLine=174 srcPath=/root/NewExperiment/elasticsearchFilter/00579/src/main/java/org/elasticsearch/search/facet/terms/longs/TermsLongFacetCollector.java)
            } else {
                BoundedTreeSet<InternalLongTermsFacet.LongEntry> ordered = new BoundedTreeSet<InternalLongTermsFacet.LongEntry>(comparatorType.comparator(), size);
                for (TLongIntIterator it = facets.iterator(); it.hasNext(); ) {
                    it.advance();
                    ordered.add(new InternalLongTermsFacet.LongEntry(it.key(), it.value()));
                }
                CacheRecycler.pushLongIntMap(facets);
                return new InternalLongTermsFacet(facetName, comparatorType, size, ordered, aggregator.missing(), aggregator.total());
            }
,
(startLine=156 endLine=164 srcPath=/root/NewExperiment/elasticsearchFilter/00579/src/main/java/org/elasticsearch/search/facet/terms/ip/TermsIpFacetCollector.java)
            } else {
                BoundedTreeSet<InternalIpTermsFacet.LongEntry> ordered = new BoundedTreeSet<InternalIpTermsFacet.LongEntry>(comparatorType.comparator(), size);
                for (TLongIntIterator it = facets.iterator(); it.hasNext(); ) {
                    it.advance();
                    ordered.add(new InternalIpTermsFacet.LongEntry(it.key(), it.value()));
                }
                CacheRecycler.pushLongIntMap(facets);
                return new InternalIpTermsFacet(facetName, comparatorType, size, ordered, aggregator.missing(), aggregator.total());
            }
,
>
, <(startLine=54 endLine=96 srcPath=/root/NewExperiment/elasticsearchFilter/00995/src/main/java/org/elasticsearch/rest/action/cat/RestShardsAction.java)
    public void handleRequest(final RestRequest request, final RestChannel channel) {
        final String[] indices = Strings.splitStringByCommaToArray(request.param("index"));
        final ClusterStateRequest clusterStateRequest = new ClusterStateRequest();
        clusterStateRequest.local(request.paramAsBoolean("local", clusterStateRequest.local()));
        clusterStateRequest.masterNodeTimeout(request.paramAsTime("master_timeout", clusterStateRequest.masterNodeTimeout()));

        client.admin().cluster().state(clusterStateRequest, new ActionListener<ClusterStateResponse>() {
            @Override
            public void onResponse(final ClusterStateResponse clusterStateResponse) {
                final String[] concreteIndices = clusterStateResponse.getState().metaData().concreteIndicesIgnoreMissing(indices);
                IndicesStatsRequest indicesStatsRequest = new IndicesStatsRequest();
                indicesStatsRequest.clear().docs(true).store(true);
                client.admin().indices().stats(indicesStatsRequest, new ActionListener<IndicesStatsResponse>() {
                    @Override
                    public void onResponse(IndicesStatsResponse indicesStatsResponse) {
                        try {
                            channel.sendResponse(RestTable.buildResponse(buildTable(concreteIndices, clusterStateResponse, indicesStatsResponse), request, channel));
                        } catch (Throwable e) {
                            onFailure(e);
                        }
                    }

                    @Override
                    public void onFailure(Throwable e) {
                        try {
                            channel.sendResponse(new XContentThrowableRestResponse(request, e));
                        } catch (IOException e1) {
                            logger.error("Failed to send failure response", e1);
                        }
                    }
                });
            }

            @Override
            public void onFailure(Throwable e) {
                try {
                    channel.sendResponse(new XContentThrowableRestResponse(request, e));
                } catch (IOException e1) {
                    logger.error("Failed to send failure response", e1);
                }
            }
        });
    }
,
(startLine=65 endLine=107 srcPath=/root/NewExperiment/elasticsearchFilter/00995/src/main/java/org/elasticsearch/rest/action/cat/RestIndicesAction.java)
            public void onResponse(final ClusterStateResponse clusterStateResponse) {
                final String[] concreteIndices = clusterStateResponse.getState().metaData().concreteIndicesIgnoreMissing(indices);
                ClusterHealthRequest clusterHealthRequest = Requests.clusterHealthRequest(indices);
                clusterHealthRequest.local(request.paramAsBoolean("local", clusterHealthRequest.local()));
                clusterHealthRequest.indices(indices);
                client.admin().cluster().health(clusterHealthRequest, new ActionListener<ClusterHealthResponse>() {
                    @Override
                    public void onResponse(final ClusterHealthResponse clusterHealthResponse) {
                        IndicesStatsRequest indicesStatsRequest = new IndicesStatsRequest();
                        indicesStatsRequest.clear().store(true).docs(true);
                        client.admin().indices().stats(indicesStatsRequest, new ActionListener<IndicesStatsResponse>() {
                            @Override
                            public void onResponse(IndicesStatsResponse indicesStatsResponse) {
                                try {
                                    Table tab = buildTable(concreteIndices, clusterHealthResponse, indicesStatsResponse);
                                    channel.sendResponse(RestTable.buildResponse(tab, request, channel));
                                } catch (Throwable e) {
                                    onFailure(e);
                                }
                            }

                            @Override
                            public void onFailure(Throwable e) {
                                try {
                                    channel.sendResponse(new XContentThrowableRestResponse(request, e));
                                } catch (IOException e1) {
                                    logger.error("Failed to send failure response", e1);
                                }
                            }
                        });

                    }

                    @Override
                    public void onFailure(Throwable e) {
                        try {
                            channel.sendResponse(new XContentThrowableRestResponse(request, e));
                        } catch (IOException e1) {
                            logger.error("Failed to send failure response", e1);
                        }
                    }
                });
            }
,
>
, <(startLine=60 endLine=72 srcPath=/root/NewExperiment/elasticsearchFilter/02414/core/src/test/java/org/elasticsearch/index/translog/CountedBitSetTests.java)
        for (int i = 1; i < numBits; i++) {
            final int value = values.get(i);
            assertThat(countedBitSet.get(value), equalTo(false));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));

            countedBitSet.set(value);

            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(i));
            assertThat(countedBitSet.ramBytesUsed(), equalTo(ramBytesUsedWithBitSet));
        }
,
(startLine=75 endLine=87 srcPath=/root/NewExperiment/elasticsearchFilter/02414/core/src/test/java/org/elasticsearch/index/translog/CountedBitSetTests.java)
        {
            final int value = values.get(0);
            assertThat(countedBitSet.get(value), equalTo(false));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(false));

            countedBitSet.set(value);

            assertThat(countedBitSet.get(value), equalTo(true));
            assertThat(countedBitSet.isInternalBitsetReleased(), equalTo(true));
            assertThat(countedBitSet.length(), equalTo(numBits));
            assertThat(countedBitSet.cardinality(), equalTo(numBits));
            assertThat(countedBitSet.ramBytesUsed(), allOf(equalTo(CountedBitSet.BASE_RAM_BYTES_USED), lessThan(ramBytesUsedWithBitSet)));
        }
,
>
, <(startLine=553 endLine=559 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/main/java/org/elasticsearch/snapshots/RestoreService.java)
                    if (changedCount > 0) {
                        logger.trace("changed cluster state triggered by {} snapshot restore state updates", changedCount);

                        final RestoreMetaData updatedRestore = new RestoreMetaData(entries.toArray(new RestoreMetaData.Entry[entries.size()]));
                        final MetaData.Builder mdBuilder = MetaData.builder(currentState.metaData()).putCustom(RestoreMetaData.TYPE, updatedRestore);
                        return ClusterState.builder(currentState).metaData(mdBuilder).build();
                    }
,
(startLine=1056 endLine=1062 srcPath=/root/NewExperiment/elasticsearchFilter/01707/core/src/main/java/org/elasticsearch/snapshots/SnapshotsService.java)
                    if (changedCount > 0) {
                        logger.trace("changed cluster state triggered by {} snapshot state updates", changedCount);

                        final SnapshotMetaData updatedSnapshots = new SnapshotMetaData(entries.toArray(new SnapshotMetaData.Entry[entries.size()]));
                        final MetaData.Builder mdBuilder = MetaData.builder(currentState.metaData()).putCustom(SnapshotMetaData.TYPE, updatedSnapshots);
                        return ClusterState.builder(currentState).metaData(mdBuilder).build();
                    }
,
>
, <(startLine=44 endLine=53 srcPath=/root/NewExperiment/elasticsearchFilter/02436/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java)
    public void testDefaultUsage() throws Exception {
        Settings settings = Settings.builder()
                .put("index.analysis.filter.myCollator.type", "icu_collation")
                .put("index.analysis.filter.myCollator.strength", "primary")
                .build();
        TestAnalysis analysis = createTestAnalysis(new Index("test", "_na_"), settings, new AnalysisICUPlugin());

        TokenFilterFactory filterFactory = analysis.tokenFilter.get("myCollator");
        assertCollatesToSame(filterFactory, "FOO", "foo");
    }
,
(startLine=227 endLine=236 srcPath=/root/NewExperiment/elasticsearchFilter/02436/plugins/analysis-icu/src/test/java/org/elasticsearch/index/analysis/SimpleIcuCollationTokenFilterTests.java)
    public void testBasicCustomRules() throws Exception {
        Settings settings = Settings.builder()
                .put("index.analysis.filter.myCollator.type", "icu_collation")
                .put("index.analysis.filter.myCollator.rules", "&a < g")
                .build();
        TestAnalysis analysis = createTestAnalysis(new Index("test", "_na_"), settings, new AnalysisICUPlugin());

        TokenFilterFactory filterFactory = analysis.tokenFilter.get("myCollator");
        assertCollation(filterFactory, "green", "bird", -1);
    }
,
>
, <(startLine=292 endLine=299 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/main/java/org/elasticsearch/action/admin/indices/alias/IndicesAliasesRequest.java)
            } else {
                for (String alias : aliasAction.aliases) {
                    if (!Strings.hasText(alias)) {
                        validationException = addValidationError("Alias action [" + aliasAction.actionType().name().toLowerCase(Locale.ENGLISH)
                            + "]: [alias/aliases] may not be empty string", validationException);
                    }
                }
            }
,
(startLine=303 endLine=310 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/main/java/org/elasticsearch/action/admin/indices/alias/IndicesAliasesRequest.java)
            } else {
                for (String index : aliasAction.indices) {
                    if (!Strings.hasText(index)) {
                        validationException = addValidationError("Alias action [" + aliasAction.actionType().name().toLowerCase(Locale.ENGLISH)
                                + "]: [index/indices] may not be empty string", validationException);
                    }
                }
            }
,
>
, <(startLine=447 endLine=456 srcPath=/root/NewExperiment/elasticsearchFilter/01767/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/StatsTests.java)
    private void assertShardExecutionState(SearchResponse response, int expectedFailures) throws Exception {
        ShardSearchFailure[] failures = response.getShardFailures();
        if (failures.length != expectedFailures) {
            for (ShardSearchFailure failure : failures) {
                logger.error("Shard Failure: {}", failure.reason(), failure.toString());
            }
            fail("Unexpected shard failures!");
        }
        assertThat("Not all shards are initialized", response.getSuccessfulShards(), equalTo(response.getTotalShards()));
    }
,
(startLine=554 endLine=563 srcPath=/root/NewExperiment/elasticsearchFilter/01767/plugins/lang-groovy/src/test/java/org/elasticsearch/messy/tests/ExtendedStatsTests.java)
    private void assertShardExecutionState(SearchResponse response, int expectedFailures) throws Exception {
        ShardSearchFailure[] failures = response.getShardFailures();
        if (failures.length != expectedFailures) {
            for (ShardSearchFailure failure : failures) {
                logger.error("Shard Failure: {}", failure.reason(), failure.toString());
            }
            fail("Unexpected shard failures!");
        }
        assertThat("Not all shards are initialized", response.getSuccessfulShards(), equalTo(response.getTotalShards()));
    }
,
>
, <(startLine=72 endLine=88 srcPath=/root/NewExperiment/elasticsearchFilter/00234/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MultiFieldMapperQueryParser.java)
        if (useDisMax) {
            DisjunctionMaxQuery disMaxQuery = new DisjunctionMaxQuery(tieBreaker);
            boolean added = false;
            for (String field : fields) {
                Query q = super.getFieldQuery(field, queryText);
                if (q != null) {
                    added = true;
                    applyBoost(field, q);
                    applySlop(q, slop);
                    disMaxQuery.add(q);
                }
            }
            if (!added) {
                return null;
            }
            return disMaxQuery;
        } else {
,
(startLine=108 endLine=123 srcPath=/root/NewExperiment/elasticsearchFilter/00234/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MultiFieldMapperQueryParser.java)
        if (useDisMax) {
            DisjunctionMaxQuery disMaxQuery = new DisjunctionMaxQuery(tieBreaker);
            boolean added = false;
            for (String field : fields) {
                Query q = super.getRangeQuery(field, part1, part2, inclusive);
                if (q != null) {
                    added = true;
                    applyBoost(field, q);
                    disMaxQuery.add(q);
                }
            }
            if (!added) {
                return null;
            }
            return disMaxQuery;
        } else {
,
(startLine=142 endLine=157 srcPath=/root/NewExperiment/elasticsearchFilter/00234/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MultiFieldMapperQueryParser.java)
        if (useDisMax) {
            DisjunctionMaxQuery disMaxQuery = new DisjunctionMaxQuery(tieBreaker);
            boolean added = false;
            for (String field : fields) {
                Query q = super.getPrefixQuery(field, termStr);
                if (q != null) {
                    added = true;
                    applyBoost(field, q);
                    disMaxQuery.add(q);
                }
            }
            if (!added) {
                return null;
            }
            return disMaxQuery;
        } else {
,
(startLine=176 endLine=191 srcPath=/root/NewExperiment/elasticsearchFilter/00234/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MultiFieldMapperQueryParser.java)
        if (useDisMax) {
            DisjunctionMaxQuery disMaxQuery = new DisjunctionMaxQuery(tieBreaker);
            boolean added = false;
            for (String field : fields) {
                Query q = super.getWildcardQuery(field, termStr);
                if (q != null) {
                    added = true;
                    applyBoost(field, q);
                    disMaxQuery.add(q);
                }
            }
            if (!added) {
                return null;
            }
            return disMaxQuery;
        } else {
,
(startLine=210 endLine=225 srcPath=/root/NewExperiment/elasticsearchFilter/00234/modules/elasticsearch/src/main/java/org/elasticsearch/index/query/support/MultiFieldMapperQueryParser.java)
        if (useDisMax) {
            DisjunctionMaxQuery disMaxQuery = new DisjunctionMaxQuery(tieBreaker);
            boolean added = false;
            for (String field : fields) {
                Query q = super.getFuzzyQuery(field, termStr, minSimilarity);
                if (q != null) {
                    added = true;
                    applyBoost(field, q);
                    disMaxQuery.add(q);
                }
            }
            if (!added) {
                return null;
            }
            return disMaxQuery;
        } else {
,
>
, <(startLine=92 endLine=159 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/cluster/routing/allocation/DeadNodesAllocationTests.java)
    public void testDeadNodeWhileRelocatingOnToNode() {
        AllocationService allocation = createAllocationService(Settings.builder()
                .put("cluster.routing.allocation.node_concurrent_recoveries", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), "always")
                .build());

        logger.info("--> building initial routing table");
        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder("test").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();
        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index("test"))
                .build();
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info("--> adding 2 nodes on same rack and do rerouting");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode("node1"))
                .add(newNode("node2"))
        ).build();

        clusterState = allocation.reroute(clusterState, "reroute");

        // starting primaries
        clusterState = allocation.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
        // starting replicas
        clusterState = allocation.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));

        logger.info("--> verifying all is allocated");
        assertThat(clusterState.getRoutingNodes().node("node1").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node1").iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node2").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node2").iterator().next().state(), equalTo(STARTED));

        logger.info("--> adding additional node");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode("node3"))
        ).build();
        clusterState = allocation.reroute(clusterState, "reroute");

        assertThat(clusterState.getRoutingNodes().node("node1").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node1").iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node2").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node2").iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node3").size(), equalTo(0));

        String origPrimaryNodeId = clusterState.routingTable().index("test").shard(0).primaryShard().currentNodeId();
        String origReplicaNodeId = clusterState.routingTable().index("test").shard(0).replicaShards().get(0).currentNodeId();

        logger.info("--> moving primary shard to node3");
        AllocationService.CommandsResult commandsResult = allocation.reroute(clusterState, new AllocationCommands(
                new MoveAllocationCommand("test", 0, clusterState.routingTable().index("test").shard(0).primaryShard().currentNodeId(), "node3")),
            false, false);
        assertThat(commandsResult.getClusterState(), not(equalTo(clusterState)));
        clusterState = commandsResult.getClusterState();
        assertThat(clusterState.getRoutingNodes().node(origPrimaryNodeId).iterator().next().state(), equalTo(RELOCATING));
        assertThat(clusterState.getRoutingNodes().node("node3").iterator().next().state(), equalTo(INITIALIZING));

        logger.info("--> fail primary shard recovering instance on node3 being initialized by killing node3");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode(origPrimaryNodeId))
                .add(newNode(origReplicaNodeId))
        ).build();
        clusterState = allocation.deassociateDeadNodes(clusterState, true, "reroute");

        assertThat(clusterState.getRoutingNodes().node(origPrimaryNodeId).iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node(origReplicaNodeId).iterator().next().state(), equalTo(STARTED));
    }
,
(startLine=161 endLine=228 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/test/java/org/elasticsearch/cluster/routing/allocation/DeadNodesAllocationTests.java)
    public void testDeadNodeWhileRelocatingOnFromNode() {
        AllocationService allocation = createAllocationService(Settings.builder()
                .put("cluster.routing.allocation.node_concurrent_recoveries", 10)
                .put(ClusterRebalanceAllocationDecider.CLUSTER_ROUTING_ALLOCATION_ALLOW_REBALANCE_SETTING.getKey(), "always")
                .build());

        logger.info("--> building initial routing table");
        MetaData metaData = MetaData.builder()
                .put(IndexMetaData.builder("test").settings(settings(Version.CURRENT)).numberOfShards(1).numberOfReplicas(1))
                .build();
        RoutingTable routingTable = RoutingTable.builder()
                .addAsNew(metaData.index("test"))
                .build();
        ClusterState clusterState = ClusterState.builder(org.elasticsearch.cluster.ClusterName.CLUSTER_NAME_SETTING.getDefault(Settings.EMPTY)).metaData(metaData).routingTable(routingTable).build();

        logger.info("--> adding 2 nodes on same rack and do rerouting");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode("node1"))
                .add(newNode("node2"))
        ).build();

        clusterState = allocation.reroute(clusterState, "reroute");

        // starting primaries
        clusterState = allocation.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));
        // starting replicas
        clusterState = allocation.applyStartedShards(clusterState, clusterState.getRoutingNodes().shardsWithState(INITIALIZING));

        logger.info("--> verifying all is allocated");
        assertThat(clusterState.getRoutingNodes().node("node1").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node1").iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node2").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node2").iterator().next().state(), equalTo(STARTED));

        logger.info("--> adding additional node");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder(clusterState.nodes())
                .add(newNode("node3"))
        ).build();
        clusterState = allocation.reroute(clusterState, "reroute");

        assertThat(clusterState.getRoutingNodes().node("node1").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node1").iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node2").size(), equalTo(1));
        assertThat(clusterState.getRoutingNodes().node("node2").iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node3").size(), equalTo(0));

        String origPrimaryNodeId = clusterState.routingTable().index("test").shard(0).primaryShard().currentNodeId();
        String origReplicaNodeId = clusterState.routingTable().index("test").shard(0).replicaShards().get(0).currentNodeId();

        logger.info("--> moving primary shard to node3");
        AllocationService.CommandsResult commandsResult = allocation.reroute(clusterState, new AllocationCommands(
                new MoveAllocationCommand("test",0 , clusterState.routingTable().index("test").shard(0).primaryShard().currentNodeId(), "node3")),
            false, false);
        assertThat(commandsResult.getClusterState(), not(equalTo(clusterState)));
        clusterState = commandsResult.getClusterState();
        assertThat(clusterState.getRoutingNodes().node(origPrimaryNodeId).iterator().next().state(), equalTo(RELOCATING));
        assertThat(clusterState.getRoutingNodes().node("node3").iterator().next().state(), equalTo(INITIALIZING));

        logger.info("--> fail primary shard recovering instance on 'origPrimaryNodeId' being relocated");
        clusterState = ClusterState.builder(clusterState).nodes(DiscoveryNodes.builder()
                .add(newNode("node3"))
                .add(newNode(origReplicaNodeId))
        ).build();
        clusterState = allocation.deassociateDeadNodes(clusterState, true, "reroute");

        assertThat(clusterState.getRoutingNodes().node(origReplicaNodeId).iterator().next().state(), equalTo(STARTED));
        assertThat(clusterState.getRoutingNodes().node("node3").iterator().next().state(), equalTo(INITIALIZING));
    }
,
>
, <(startLine=395 endLine=454 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/test/java/org/elasticsearch/index/mapper/numeric/LegacyNumericTests.java)
    public void testPrecisionStepDefaultsMapped() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties")
                .startObject("int")
                    .field("type", "integer")
                .endObject()
                .startObject("float")
                    .field("type", "float")
                .endObject()
                .startObject("long")
                    .field("type", "long")
                .endObject()
                .startObject("double")
                    .field("type", "double")
                .endObject()
                .startObject("short")
                    .field("type", "short")
                .endObject()
                .startObject("byte")
                    .field("type", "byte")
                .endObject()
                .startObject("date")
                    .field("type", "date")
                .endObject()
                .startObject("ip")
                    .field("type", "ip")
                .endObject()

                .endObject()
                .endObject().endObject().string();

        DocumentMapper mapper = createIndex("test", BW_SETTINGS).mapperService().documentMapperParser().parse("type", new CompressedXContent(mapping));

        ParsedDocument doc = mapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .field("int",    "100")
                .field("float",  "100.0")
                .field("long",   "5000")
                .field("double", "34.545")
                .field("short",  "1645")
                .field("byte",   "50")
                .field("date",   "2010-01-01")
                .field("ip",     "255.255.255.255")
                .endObject()
                .bytes());

        assertEquals(1, doc.docs().size());
        Document luceneDoc = doc.docs().get(0);

        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_64_BIT, luceneDoc.getField("long"));
        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_64_BIT, luceneDoc.getField("double"));
        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_64_BIT, luceneDoc.getField("date"));
        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_64_BIT, luceneDoc.getField("ip"));

        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_32_BIT, luceneDoc.getField("int"));
        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_32_BIT, luceneDoc.getField("float"));

        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_16_BIT, luceneDoc.getField("short"));
        assertPrecisionStepEquals(LegacyNumberFieldMapper.Defaults.PRECISION_STEP_8_BIT,  luceneDoc.getField("byte"));
    }
,
(startLine=457 endLine=523 srcPath=/root/NewExperiment/elasticsearchFilter/01771/core/src/test/java/org/elasticsearch/index/mapper/numeric/LegacyNumericTests.java)
    public void testPrecisionStepExplicit() throws Exception {
        String mapping = XContentFactory.jsonBuilder().startObject().startObject("type")
                .startObject("properties")
                .startObject("int")
                    .field("type", "integer")
                    .field("precision_step", "1")
                .endObject()
                .startObject("float")
                    .field("type", "float")
                    .field("precision_step", "2")
                .endObject()
                .startObject("long")
                    .field("type", "long")
                    .field("precision_step", "1")
                .endObject()
                .startObject("double")
                    .field("type", "double")
                    .field("precision_step", "2")
                .endObject()
                .startObject("short")
                    .field("type", "short")
                    .field("precision_step", "1")
                .endObject()
                .startObject("byte")
                    .field("type", "byte")
                    .field("precision_step", "2")
                .endObject()
                .startObject("date")
                    .field("type", "date")
                    .field("precision_step", "1")
                .endObject()
                .startObject("ip")
                    .field("type", "ip")
                    .field("precision_step", "2")
                .endObject()

                .endObject()
                .endObject().endObject().string();

        DocumentMapper mapper = createIndex("test", BW_SETTINGS).mapperService().documentMapperParser().parse("type", new CompressedXContent(mapping));

        ParsedDocument doc = mapper.parse("test", "type", "1", XContentFactory.jsonBuilder()
                .startObject()
                .field("int",    "100")
                .field("float",  "100.0")
                .field("long",   "5000")
                .field("double", "34.545")
                .field("short",  "1645")
                .field("byte",   "50")
                .field("date",   "2010-01-01")
                .field("ip",     "255.255.255.255")
                .endObject()
                .bytes());

        assertEquals(1, doc.docs().size());
        Document luceneDoc = doc.docs().get(0);

        assertPrecisionStepEquals(1, luceneDoc.getField("int"));
        assertPrecisionStepEquals(2, luceneDoc.getField("float"));
        assertPrecisionStepEquals(1, luceneDoc.getField("long"));
        assertPrecisionStepEquals(2, luceneDoc.getField("double"));
        assertPrecisionStepEquals(1, luceneDoc.getField("short"));
        assertPrecisionStepEquals(2, luceneDoc.getField("byte"));
        assertPrecisionStepEquals(1, luceneDoc.getField("date"));
        assertPrecisionStepEquals(2, luceneDoc.getField("ip"));

    }
,
>
, <(startLine=196 endLine=204 srcPath=/root/NewExperiment/elasticsearchFilter/01728/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashMap.java)
    private static <T> T[] removeArrayElement(T[] array, int index) {
        final Object result = Array.newInstance(array.getClass().getComponentType(), array.length - 1);
        System.arraycopy(array, 0, result, 0, index);
        if (index < array.length - 1) {
            System.arraycopy(array, index + 1, result, index, array.length - index - 1);
        }

        return (T[]) result;
    }
,
(startLine=212 endLine=220 srcPath=/root/NewExperiment/elasticsearchFilter/01728/core/src/main/java/org/elasticsearch/common/collect/CopyOnWriteHashMap.java)
    public static <T> T[] insertElement(final T[] array, final T element, final int index) {
        final T[] result = Arrays.copyOf(array, array.length + 1);
        System.arraycopy(array, 0, result, 0, index);
        result[index] = element;
        if (index < array.length) {
            System.arraycopy(array, index, result, index + 1, array.length - index);
        }
        return result;
    }
,
>
, <(startLine=76 endLine=85 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/support/AggregationPath.java)
                if (index >= 0) {
                    if (index == 0 || index > element.length() - 3) {
                        throw new AggregationExecutionException("Invalid path element [" + element + "] in path [" + path + "]");
                    }
                    if (element.charAt(element.length() - 1) != ']') {
                        throw new AggregationExecutionException("Invalid path element [" + element + "] in path [" + path + "]");
                    }
                    tokens.add(new PathElement(element, element.substring(0, index), element.substring(index + 1, element.length() - 1)));
                    continue;
                }
,
(startLine=99 endLine=108 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/search/aggregations/support/AggregationPath.java)
                if (index >= 0) {
                    if (index == 0 || index > element.length() - 3) {
                        throw new AggregationExecutionException("Invalid path element [" + element + "] in path [" + path + "]");
                    }
                    if (element.charAt(element.length() - 1) != ']') {
                        throw new AggregationExecutionException("Invalid path element [" + element + "] in path [" + path + "]");
                    }
                    tokens.add(new PathElement(element, element.substring(0, index), element.substring(index + 1, element.length() - 1)));
                    continue;
                }
,
>
, <(startLine=347 endLine=356 srcPath=/root/NewExperiment/elasticsearchFilter/02348/core/src/test/java/org/elasticsearch/index/SearchSlowLogTests.java)
    private void assertTimeValueException(final IllegalArgumentException e, final String key) {
        final String expected = "illegal value can't update [" + key + "] from [-1] to [NOT A TIME VALUE]";
        assertThat(e, hasToString(containsString(expected)));
        assertNotNull(e.getCause());
        assertThat(e.getCause(), instanceOf(IllegalArgumentException.class));
        final IllegalArgumentException cause = (IllegalArgumentException) e.getCause();
        final String causeExpected =
                "failed to parse setting [" + key + "] with value [NOT A TIME VALUE] as a time value: unit is missing or unrecognized";
        assertThat(cause, hasToString(containsString(causeExpected)));
    }
,
(startLine=218 endLine=227 srcPath=/root/NewExperiment/elasticsearchFilter/02348/core/src/test/java/org/elasticsearch/index/IndexingSlowLogTests.java)
    private void assertTimeValueException(final IllegalArgumentException e, final String key) {
        final String expected = "illegal value can't update [" + key + "] from [-1] to [NOT A TIME VALUE]";
        assertThat(e, hasToString(containsString(expected)));
        assertNotNull(e.getCause());
        assertThat(e.getCause(), instanceOf(IllegalArgumentException.class));
        final IllegalArgumentException cause = (IllegalArgumentException) e.getCause();
        final String causeExpected =
                "failed to parse setting [" + key + "] with value [NOT A TIME VALUE] as a time value: unit is missing or unrecognized";
        assertThat(cause, hasToString(containsString(causeExpected)));
    }
,
>
, <(startLine=89 endLine=99 srcPath=/root/NewExperiment/elasticsearchFilter/01771/modules/ingest-common/src/test/java/org/elasticsearch/ingest/RenameProcessorTests.java)
    public void testRenameNonExistingField() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random(), new HashMap<>());
        String fieldName = RandomDocumentPicks.randomFieldName(random());
        Processor processor = new RenameProcessor(randomAsciiOfLength(10), fieldName, RandomDocumentPicks.randomFieldName(random()));
        try {
            processor.execute(ingestDocument);
            fail("processor execute should have failed");
        } catch(IllegalArgumentException e) {
            assertThat(e.getMessage(), equalTo("field [" + fieldName + "] doesn't exist"));
        }
    }
,
(startLine=101 endLine=112 srcPath=/root/NewExperiment/elasticsearchFilter/01771/modules/ingest-common/src/test/java/org/elasticsearch/ingest/RenameProcessorTests.java)
    public void testRenameNewFieldAlreadyExists() throws Exception {
        IngestDocument ingestDocument = RandomDocumentPicks.randomIngestDocument(random());
        String fieldName = RandomDocumentPicks.randomExistingFieldName(random(), ingestDocument);
        Processor processor = new RenameProcessor(randomAsciiOfLength(10), RandomDocumentPicks.randomExistingFieldName(
                random(), ingestDocument), fieldName);
        try {
            processor.execute(ingestDocument);
            fail("processor execute should have failed");
        } catch(IllegalArgumentException e) {
            assertThat(e.getMessage(), equalTo("field [" + fieldName + "] already exists"));
        }
    }
,
>
, <(startLine=159 endLine=172 srcPath=/root/NewExperiment/elasticsearchFilter/01728/core/src/main/java/org/elasticsearch/gateway/MetaStateService.java)
    static MetaDataStateFormat<MetaData> globalStateFormat(XContentType format, final ToXContent.Params formatParams) {
        return new MetaDataStateFormat<MetaData>(format, GLOBAL_STATE_FILE_PREFIX) {

            @Override
            public void toXContent(XContentBuilder builder, MetaData state) throws IOException {
                MetaData.Builder.toXContent(state, builder, formatParams);
            }

            @Override
            public MetaData fromXContent(XContentParser parser) throws IOException {
                return MetaData.Builder.fromXContent(parser);
            }
        };
    }
,
(startLine=177 endLine=189 srcPath=/root/NewExperiment/elasticsearchFilter/01728/core/src/main/java/org/elasticsearch/gateway/MetaStateService.java)
    static MetaDataStateFormat<IndexMetaData> indexStateFormat(XContentType format, final ToXContent.Params formatParams) {
        return new MetaDataStateFormat<IndexMetaData>(format, INDEX_STATE_FILE_PREFIX) {

            @Override
            public void toXContent(XContentBuilder builder, IndexMetaData state) throws IOException {
                IndexMetaData.Builder.toXContent(state, builder, formatParams);            }

            @Override
            public IndexMetaData fromXContent(XContentParser parser) throws IOException {
                return IndexMetaData.Builder.fromXContent(parser);
            }
        };
    }
,
>
, <(startLine=105 endLine=152 srcPath=/root/NewExperiment/elasticsearchFilter/02096/core/src/test/java/org/elasticsearch/search/aggregations/bucket/SignificantTermsTests.java)
        if (randomBoolean()) {
            IncludeExclude incExc = null;
            switch (randomInt(5)) {
            case 0:
                incExc = new IncludeExclude(new RegExp("foobar"), null);
                break;
            case 1:
                incExc = new IncludeExclude(null, new RegExp("foobaz"));
                break;
            case 2:
                incExc = new IncludeExclude(new RegExp("foobar"), new RegExp("foobaz"));
                break;
            case 3:
                SortedSet<BytesRef> includeValues = new TreeSet<>();
                int numIncs = randomIntBetween(1, 20);
                for (int i = 0; i < numIncs; i++) {
                    includeValues.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                SortedSet<BytesRef> excludeValues = null;
                incExc = new IncludeExclude(includeValues, excludeValues);
                break;
            case 4:
                SortedSet<BytesRef> includeValues2 = null;
                SortedSet<BytesRef> excludeValues2 = new TreeSet<>();
                int numExcs2 = randomIntBetween(1, 20);
                for (int i = 0; i < numExcs2; i++) {
                    excludeValues2.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                incExc = new IncludeExclude(includeValues2, excludeValues2);
                break;
            case 5:
                SortedSet<BytesRef> includeValues3 = new TreeSet<>();
                int numIncs3 = randomIntBetween(1, 20);
                for (int i = 0; i < numIncs3; i++) {
                    includeValues3.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                SortedSet<BytesRef> excludeValues3 = new TreeSet<>();
                int numExcs3 = randomIntBetween(1, 20);
                for (int i = 0; i < numExcs3; i++) {
                    excludeValues3.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                incExc = new IncludeExclude(includeValues3, excludeValues3);
                break;
            default:
                fail();
            }
            factory.includeExclude(incExc);
        }
,
(startLine=104 endLine=156 srcPath=/root/NewExperiment/elasticsearchFilter/02096/core/src/test/java/org/elasticsearch/search/aggregations/bucket/TermsTests.java)
        if (randomBoolean()) {
            IncludeExclude incExc = null;
            switch (randomInt(6)) {
            case 0:
                incExc = new IncludeExclude(new RegExp("foobar"), null);
                break;
            case 1:
                incExc = new IncludeExclude(null, new RegExp("foobaz"));
                break;
            case 2:
                incExc = new IncludeExclude(new RegExp("foobar"), new RegExp("foobaz"));
                break;
            case 3:
                SortedSet<BytesRef> includeValues = new TreeSet<>();
                int numIncs = randomIntBetween(1, 20);
                for (int i = 0; i < numIncs; i++) {
                    includeValues.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                SortedSet<BytesRef> excludeValues = null;
                incExc = new IncludeExclude(includeValues, excludeValues);
                break;
            case 4:
                SortedSet<BytesRef> includeValues2 = null;
                SortedSet<BytesRef> excludeValues2 = new TreeSet<>();
                int numExcs2 = randomIntBetween(1, 20);
                for (int i = 0; i < numExcs2; i++) {
                    excludeValues2.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                incExc = new IncludeExclude(includeValues2, excludeValues2);
                break;
            case 5:
                SortedSet<BytesRef> includeValues3 = new TreeSet<>();
                int numIncs3 = randomIntBetween(1, 20);
                for (int i = 0; i < numIncs3; i++) {
                    includeValues3.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                SortedSet<BytesRef> excludeValues3 = new TreeSet<>();
                int numExcs3 = randomIntBetween(1, 20);
                for (int i = 0; i < numExcs3; i++) {
                    excludeValues3.add(new BytesRef(randomAlphaOfLengthBetween(1, 30)));
                }
                incExc = new IncludeExclude(includeValues3, excludeValues3);
                break;
            case 6:
                final int numPartitions = randomIntBetween(1, 100);
                final int partition = randomIntBetween(0, numPartitions - 1);
                incExc = new IncludeExclude(partition, numPartitions);
                break;
            default:
                fail();
            }
            factory.includeExclude(incExc);
        }
,
>
, <(startLine=354 endLine=366 srcPath=/root/NewExperiment/elasticsearchFilter/00760/src/main/java/org/elasticsearch/threadpool/ThreadPool.java)
                    if (!previousInfo.keepAlive().equals(updatedKeepAlive) || previousInfo.min() != updatedMin || previousInfo.max() != updatedSize) {
                        logger.debug("updating thread_pool [{}], type [{}], keep_alive [{}]", name, type, updatedKeepAlive);
                        if (!previousInfo.getKeepAlive().equals(updatedKeepAlive)) {
                            ((EsThreadPoolExecutor) previousExecutorHolder.executor).setKeepAliveTime(updatedKeepAlive.millis(), TimeUnit.MILLISECONDS);
                        }
                        if (previousInfo.getMin() != updatedMin) {
                            ((EsThreadPoolExecutor) previousExecutorHolder.executor).setCorePoolSize(updatedMin);
                        }
                        if (previousInfo.getMax() != updatedSize) {
                            ((EsThreadPoolExecutor) previousExecutorHolder.executor).setMaximumPoolSize(updatedSize);
                        }
                        return new ExecutorHolder(previousExecutorHolder.executor, new Info(name, type, updatedMin, updatedSize, updatedKeepAlive, null));
                    }
,
(startLine=404 endLine=416 srcPath=/root/NewExperiment/elasticsearchFilter/00760/src/main/java/org/elasticsearch/threadpool/ThreadPool.java)
                                previousInfo.getMin() != updatedMin || previousInfo.getMax() != updatedSize) {
                            logger.debug("updating thread_pool [{}], type [{}], keep_alive [{}]", name, type, updatedKeepAlive);
                            if (!previousInfo.getKeepAlive().equals(updatedKeepAlive)) {
                                ((EsThreadPoolExecutor) previousExecutorHolder.executor).setKeepAliveTime(updatedKeepAlive.millis(), TimeUnit.MILLISECONDS);
                            }
                            if (previousInfo.getMin() != updatedMin) {
                                ((EsThreadPoolExecutor) previousExecutorHolder.executor).setCorePoolSize(updatedMin);
                            }
                            if (previousInfo.getMax() != updatedSize) {
                                ((EsThreadPoolExecutor) previousExecutorHolder.executor).setMaximumPoolSize(updatedSize);
                            }
                            return new ExecutorHolder(previousExecutorHolder.executor, new Info(name, type, updatedMin, updatedSize, updatedKeepAlive, updatedCapacity, updatedWaitTime));
                        }
,
>
, <(startLine=49 endLine=106 srcPath=/root/NewExperiment/elasticsearchFilter/00894/src/test/java/org/elasticsearch/test/unit/cluster/routing/allocation/FailedNodeRoutingTests.java)
    public void simpleFailedNodeTest() {
        AllocationService strategy = new AllocationService(settingsBuilder().put("cluster.routing.allocation.allow_rebalance", ClusterRebalanceAllocationDecider.ClusterRebalanceType.ALWAYS.toString()).build());

        MetaData metaData = newMetaDataBuilder()
                .put(newIndexMetaDataBuilder("test1").numberOfShards(1).numberOfReplicas(1))
                .put(newIndexMetaDataBuilder("test2").numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = routingTable()
                .addAsNew(metaData.index("test1"))
                .addAsNew(metaData.index("test2"))
                .build();

        ClusterState clusterState = newClusterStateBuilder().metaData(metaData).routingTable(routingTable).build();

        logger.info("start 4 nodes");
        clusterState = newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().put(RoutingAllocationTests.newNode("node1")).put(RoutingAllocationTests.newNode("node2")).put(RoutingAllocationTests.newNode("node3")).put(RoutingAllocationTests.newNode("node4"))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();

        logger.info("start all the primary shards, replicas will start initializing");
        RoutingNodes routingNodes = clusterState.routingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.routingNodes();

        logger.info("start the replica shards");
        routingNodes = clusterState.routingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.routingNodes();

        assertThat(routingNodes.node("node1").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node("node2").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node("node3").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node("node4").numberOfShardsWithState(STARTED), equalTo(1));


        logger.info("remove 2 nodes where primaries are allocated, reroute");

        clusterState = newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().putAll(clusterState.nodes())
                .remove(routingTable.index("test1").shard(0).primaryShard().currentNodeId())
                .remove(routingTable.index("test2").shard(0).primaryShard().currentNodeId())
        )
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.routingNodes();

        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(1));
            assertThat(routingNode.numberOfShardsWithState(INITIALIZING), equalTo(1));
        }
    }
,
(startLine=109 endLine=166 srcPath=/root/NewExperiment/elasticsearchFilter/00894/src/test/java/org/elasticsearch/test/unit/cluster/routing/allocation/FailedNodeRoutingTests.java)
    public void simpleFailedNodeTestNoReassign() {
        AllocationService strategy = new AllocationService(settingsBuilder().put("cluster.routing.allocation.allow_rebalance", ClusterRebalanceAllocationDecider.ClusterRebalanceType.ALWAYS.toString()).build());

        MetaData metaData = newMetaDataBuilder()
                .put(newIndexMetaDataBuilder("test1").numberOfShards(1).numberOfReplicas(1))
                .put(newIndexMetaDataBuilder("test2").numberOfShards(1).numberOfReplicas(1))
                .build();

        RoutingTable routingTable = routingTable()
                .addAsNew(metaData.index("test1"))
                .addAsNew(metaData.index("test2"))
                .build();

        ClusterState clusterState = newClusterStateBuilder().metaData(metaData).routingTable(routingTable).build();

        logger.info("start 4 nodes");
        clusterState = newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().put(RoutingAllocationTests.newNode("node1")).put(RoutingAllocationTests.newNode("node2")).put(RoutingAllocationTests.newNode("node3")).put(RoutingAllocationTests.newNode("node4"))).build();
        RoutingTable prevRoutingTable = routingTable;
        routingTable = strategy.reroute(clusterState).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();

        logger.info("start all the primary shards, replicas will start initializing");
        RoutingNodes routingNodes = clusterState.routingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.routingNodes();

        logger.info("start the replica shards");
        routingNodes = clusterState.routingNodes();
        prevRoutingTable = routingTable;
        routingTable = strategy.applyStartedShards(clusterState, routingNodes.shardsWithState(INITIALIZING)).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.routingNodes();

        assertThat(routingNodes.node("node1").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node("node2").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node("node3").numberOfShardsWithState(STARTED), equalTo(1));
        assertThat(routingNodes.node("node4").numberOfShardsWithState(STARTED), equalTo(1));


        logger.info("remove 2 nodes where primaries are allocated, reroute");

        clusterState = newClusterStateBuilder().state(clusterState).nodes(newNodesBuilder().putAll(clusterState.nodes())
                .remove(routingTable.index("test1").shard(0).primaryShard().currentNodeId())
                .remove(routingTable.index("test2").shard(0).primaryShard().currentNodeId())
        )
                .build();
        prevRoutingTable = routingTable;
        routingTable = strategy.rerouteWithNoReassign(clusterState).routingTable();
        clusterState = newClusterStateBuilder().state(clusterState).routingTable(routingTable).build();
        routingNodes = clusterState.routingNodes();

        for (RoutingNode routingNode : routingNodes) {
            assertThat(routingNode.numberOfShardsWithState(STARTED), equalTo(1));
        }
        assertThat(routingNodes.unassigned().size(), equalTo(2));
    }
,
>
, <(startLine=53 endLine=67 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/main/java/org/elasticsearch/search/aggregations/bucket/children/ChildrenParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.VALUE_STRING) {
                if ("type".equals(currentFieldName)) {
                    childType = parser.text();
                } else {
                    throw new SearchParseException(context, "Unknown key for a " + token + " in [" + aggregationName + "]: ["
                            + currentFieldName + "].", parser.getTokenLocation());
                }
            } else {
                throw new SearchParseException(context, "Unexpected token " + token + " in [" + aggregationName + "].",
                        parser.getTokenLocation());
            }
        }
,
(startLine=45 endLine=59 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/main/java/org/elasticsearch/search/aggregations/bucket/nested/NestedParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.VALUE_STRING) {
                if ("path".equals(currentFieldName)) {
                    path = parser.text();
                } else {
                    throw new SearchParseException(context, "Unknown key for a " + token + " in [" + aggregationName + "]: ["
                            + currentFieldName + "].", parser.getTokenLocation());
                }
            } else {
                throw new SearchParseException(context, "Unexpected token " + token + " in [" + aggregationName + "].",
                        parser.getTokenLocation());
            }
        }
,
(startLine=45 endLine=59 srcPath=/root/NewExperiment/elasticsearchFilter/01736/core/src/main/java/org/elasticsearch/search/aggregations/bucket/nested/ReverseNestedParser.java)
        while ((token = parser.nextToken()) != XContentParser.Token.END_OBJECT) {
            if (token == XContentParser.Token.FIELD_NAME) {
                currentFieldName = parser.currentName();
            } else if (token == XContentParser.Token.VALUE_STRING) {
                if ("path".equals(currentFieldName)) {
                    path = parser.text();
                } else {
                    throw new SearchParseException(context, "Unknown key for a " + token + " in [" + aggregationName + "]: ["
                            + currentFieldName + "].", parser.getTokenLocation());
                }
            } else {
                throw new SearchParseException(context, "Unexpected token " + token + " in [" + aggregationName + "].",
                        parser.getTokenLocation());
            }
        }
,
>
, <(startLine=146 endLine=157 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java)
            } else if (freeBytes > diskThresholdSettings.getFreeBytesThresholdHigh().getBytes()) {
                // Allow the shard to be allocated because it is primary that
                // has never been allocated if it's under the high watermark
                if (logger.isDebugEnabled()) {
                    logger.debug("less than the required {} free bytes threshold ({} bytes free) on node {}, " +
                                    "but allowing allocation because primary has never been allocated",
                            diskThresholdSettings.getFreeBytesThresholdLow(), freeBytes, node.nodeId());
                }
                return allocation.decision(Decision.YES, NAME,
                        "the node is above the low watermark, but less than the high watermark, and this primary shard has " +
                        "never been allocated before");
            } else {
,
(startLine=188 endLine=200 srcPath=/root/NewExperiment/elasticsearchFilter/02446/elasticsearch/core/src/main/java/org/elasticsearch/cluster/routing/allocation/decider/DiskThresholdDecider.java)
            } else if (freeDiskPercentage > diskThresholdSettings.getFreeDiskThresholdHigh()) {
                // Allow the shard to be allocated because it is primary that
                // has never been allocated if it's under the high watermark
                if (logger.isDebugEnabled()) {
                    logger.debug("more than the allowed {} used disk threshold ({} used) on node [{}], " +
                                    "but allowing allocation because primary has never been allocated",
                            Strings.format1Decimals(usedDiskThresholdLow, "%"),
                            Strings.format1Decimals(usedDiskPercentage, "%"), node.nodeId());
                }
                return allocation.decision(Decision.YES, NAME,
                    "the node is above the low watermark, but less than the high watermark, and this primary shard has " +
                    "never been allocated before");
            } else {
,
>
, <(startLine=368 endLine=378 srcPath=/root/NewExperiment/elasticsearchFilter/00852/src/main/java/org/elasticsearch/common/Preconditions.java)
    public static void checkElementIndex(int index, int size, String desc) {
        checkArgument(size >= 0, "negative size: %s", size);
        if (index < 0) {
            throw new IndexOutOfBoundsException(
                    format("%s (%s) must not be negative", desc, index));
        }
        if (index >= size) {
            throw new IndexOutOfBoundsException(
                    format("%s (%s) must be less than size (%s)", desc, index, size));
        }
    }
,
(startLine=411 endLine=421 srcPath=/root/NewExperiment/elasticsearchFilter/00852/src/main/java/org/elasticsearch/common/Preconditions.java)
    public static void checkPositionIndex(int index, int size, String desc) {
        checkArgument(size >= 0, "negative size: %s", size);
        if (index < 0) {
            throw new IndexOutOfBoundsException(format(
                    "%s (%s) must not be negative", desc, index));
        }
        if (index > size) {
            throw new IndexOutOfBoundsException(format(
                    "%s (%s) must not be greater than size (%s)", desc, index, size));
        }
    }
,
>
, <(startLine=56 endLine=103 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testProfileQuery() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        List<String> stringFields = Arrays.asList("field1");
        List<String> numericFields = Arrays.asList("field2");

        indexRandom(true, docs);

        refresh();
        int iters = between(20, 100);
        for (int i = 0; i < iters; i++) {
            QueryBuilder q = randomQueryBuilder(stringFields, numericFields, numDocs, 3);
            logger.info("Query: {}", q);

            SearchResponse resp = client().prepareSearch()
                    .setQuery(q)
                    .setProfile(true)
                    .setSearchType(SearchType.QUERY_THEN_FETCH)
                    .execute().actionGet();

            assertNotNull("Profile response element should not be null", resp.getProfileResults());
            assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));
            for (Map.Entry<String, ProfileShardResult> shard : resp.getProfileResults().entrySet()) {
                for (QueryProfileShardResult searchProfiles : shard.getValue().getQueryProfileResults()) {
                    for (ProfileResult result : searchProfiles.getQueryResults()) {
                        assertNotNull(result.getQueryName());
                        assertNotNull(result.getLuceneDescription());
                        assertThat(result.getTime(), greaterThan(0L));
                    }

                    CollectorResult result = searchProfiles.getCollectorResult();
                    assertThat(result.getName(), not(isEmptyOrNullString()));
                    assertThat(result.getTime(), greaterThan(0L));
                }
            }

        }
    }
,
(startLine=185 endLine=225 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testSimpleMatch() throws Exception {
        createIndex("test");
        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        indexRandom(true, docs);
        ensureGreen();

        QueryBuilder q = QueryBuilders.matchQuery("field1", "one");

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        Map<String, ProfileShardResult> p = resp.getProfileResults();
        assertNotNull(p);
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertEquals(result.getQueryName(), "TermQuery");
                    assertEquals(result.getLuceneDescription(), "field1:one");
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
(startLine=297 endLine=340 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testEmptyBool() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        indexRandom(true, docs);

        refresh();

        QueryBuilder q = QueryBuilders.boolQuery();
        logger.info("Query: {}", q);

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        assertNotNull("Profile response element should not be null", resp.getProfileResults());
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertNotNull(result.getQueryName());
                    assertNotNull(result.getLuceneDescription());
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
(startLine=347 endLine=392 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testCollapsingBool() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        indexRandom(true, docs);

        refresh();

        QueryBuilder q = QueryBuilders.boolQuery()
                .must(QueryBuilders.boolQuery().must(QueryBuilders.boolQuery().must(QueryBuilders.matchQuery("field1", "one"))));

        logger.info("Query: {}", q);

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        assertNotNull("Profile response element should not be null", resp.getProfileResults());
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertNotNull(result.getQueryName());
                    assertNotNull(result.getLuceneDescription());
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
(startLine=394 endLine=439 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testBoosting() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        indexRandom(true, docs);

        refresh();

        QueryBuilder q = QueryBuilders.boostingQuery(QueryBuilders.matchQuery("field1", "one"), QueryBuilders.matchQuery("field1", "two"))
                .boost(randomFloat())
                .negativeBoost(randomFloat());
        logger.info("Query: {}", q);

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        assertNotNull("Profile response element should not be null", resp.getProfileResults());
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertNotNull(result.getQueryName());
                    assertNotNull(result.getLuceneDescription());
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
(startLine=441 endLine=486 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testDisMaxRange() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        indexRandom(true, docs);

        refresh();

        QueryBuilder q = QueryBuilders.disMaxQuery()
                .boost(0.33703882f)
                .add(QueryBuilders.rangeQuery("field2").from(null).to(73).includeLower(true).includeUpper(true));
        logger.info("Query: {}", q);

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        assertNotNull("Profile response element should not be null", resp.getProfileResults());
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertNotNull(result.getQueryName());
                    assertNotNull(result.getLuceneDescription());
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
(startLine=488 endLine=532 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testRange() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i),
                    "field2", i
            );
        }

        indexRandom(true, docs);

        refresh();

        QueryBuilder q = QueryBuilders.rangeQuery("field2").from(0).to(5);

        logger.info("Query: {}", q.toString());

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        assertNotNull("Profile response element should not be null", resp.getProfileResults());
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertNotNull(result.getQueryName());
                    assertNotNull(result.getLuceneDescription());
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
(startLine=534 endLine=587 srcPath=/root/NewExperiment/elasticsearchFilter/01936/core/src/test/java/org/elasticsearch/search/profile/query/QueryProfilerIT.java)
    public void testPhrase() throws Exception {
        createIndex("test");
        ensureGreen();

        int numDocs = randomIntBetween(100, 150);
        IndexRequestBuilder[] docs = new IndexRequestBuilder[numDocs];
        for (int i = 0; i < numDocs; i++) {
            docs[i] = client().prepareIndex("test", "type1", String.valueOf(i)).setSource(
                    "field1", English.intToEnglish(i) + " " + English.intToEnglish(i+1),
                    "field2", i
            );
        }

        indexRandom(true, docs);

        refresh();

        QueryBuilder q = QueryBuilders.matchPhraseQuery("field1", "one two");

        logger.info("Query: {}", q);

        SearchResponse resp = client().prepareSearch()
                .setQuery(q)
                .setIndices("test")
                .setTypes("type1")
                .setProfile(true)
                .setSearchType(SearchType.QUERY_THEN_FETCH)
                .execute().actionGet();

        if (resp.getShardFailures().length > 0) {
            for (ShardSearchFailure f : resp.getShardFailures()) {
                logger.error("Shard search failure: {}", f);
            }
            fail();
        }

        assertNotNull("Profile response element should not be null", resp.getProfileResults());
        assertThat("Profile response should not be an empty array", resp.getProfileResults().size(), not(0));

        for (Map.Entry<String, ProfileShardResult> shardResult : resp.getProfileResults().entrySet()) {
            for (QueryProfileShardResult searchProfiles : shardResult.getValue().getQueryProfileResults()) {
                for (ProfileResult result : searchProfiles.getQueryResults()) {
                    assertNotNull(result.getQueryName());
                    assertNotNull(result.getLuceneDescription());
                    assertThat(result.getTime(), greaterThan(0L));
                    assertNotNull(result.getTimeBreakdown());
                }

                CollectorResult result = searchProfiles.getCollectorResult();
                assertThat(result.getName(), not(isEmptyOrNullString()));
                assertThat(result.getTime(), greaterThan(0L));
            }
        }
    }
,
>
, <(startLine=305 endLine=315 srcPath=/root/NewExperiment/elasticsearchFilter/01750/core/src/main/java/org/elasticsearch/cluster/routing/IndexRoutingTable.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        IndexRoutingTable that = (IndexRoutingTable) o;

        if (!index.equals(that.index)) return false;
        if (!shards.equals(that.shards)) return false;

        return true;
    }
,
(startLine=421 endLine=431 srcPath=/root/NewExperiment/elasticsearchFilter/01750/core/src/main/java/org/elasticsearch/cluster/routing/IndexShardRoutingTable.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        IndexShardRoutingTable that = (IndexShardRoutingTable) o;

        if (!shardId.equals(that.shardId)) return false;
        if (!shards.equals(that.shards)) return false;

        return true;
    }
,
(startLine=101 endLine=111 srcPath=/root/NewExperiment/elasticsearchFilter/01750/core/src/main/java/org/elasticsearch/cluster/metadata/RepositoryMetaData.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        RepositoryMetaData that = (RepositoryMetaData) o;

        if (!name.equals(that.name)) return false;
        if (!type.equals(that.type)) return false;
        return settings.equals(that.settings);

    }
,
(startLine=104 endLine=114 srcPath=/root/NewExperiment/elasticsearchFilter/01750/core/src/main/java/org/elasticsearch/cluster/routing/RestoreSource.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        RestoreSource that = (RestoreSource) o;

        if (!index.equals(that.index)) return false;
        if (!snapshotId.equals(that.snapshotId)) return false;

        return true;
    }
,
(startLine=74 endLine=84 srcPath=/root/NewExperiment/elasticsearchFilter/01750/core/src/main/java/org/elasticsearch/index/fielddata/FieldDataType.java)
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        FieldDataType that = (FieldDataType) o;

        if (!settings.equals(that.settings)) return false;
        if (!type.equals(that.type)) return false;

        return true;
    }
,
>
, <(startLine=135 endLine=170 srcPath=/root/NewExperiment/elasticsearchFilter/00128/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/ShardTermsRequest.java)
    @Override public void writeTo(StreamOutput out) throws IOException {
        super.writeTo(out);
        out.writeVInt(fields.length);
        for (String field : fields) {
            out.writeUTF(field);
        }
        if (from == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(from);
        }
        if (to == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(to);
        }
        out.writeBoolean(fromInclusive);
        out.writeBoolean(toInclusive);
        if (prefix == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(prefix);
        }
        if (regexp == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(regexp);
        }
        out.writeVInt(size);
        out.writeByte(sortType.value());
        out.writeBoolean(exact);
    }
,
(startLine=399 endLine=437 srcPath=/root/NewExperiment/elasticsearchFilter/00128/modules/elasticsearch/src/main/java/org/elasticsearch/action/terms/TermsRequest.java)
    @Override public void writeTo(StreamOutput out) throws IOException {
        super.writeTo(out);
        out.writeVInt(fields.length);
        for (String field : fields) {
            out.writeUTF(field);
        }
        if (from == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(from);
        }
        if (to == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(to);
        }
        out.writeBoolean(fromInclusive);
        out.writeBoolean(toInclusive);
        if (prefix == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(prefix);
        }
        if (regexp == null) {
            out.writeBoolean(false);
        } else {
            out.writeBoolean(true);
            out.writeUTF(regexp);
        }
        out.writeVInt(size);
        out.writeBoolean(convert);
        out.writeByte(sortType.value());
        out.writeVInt(minFreq);
        out.writeVInt(maxFreq);
        out.writeBoolean(exact);
    }
,
>
, <(startLine=33 endLine=46 srcPath=/root/NewExperiment/elasticsearchFilter/01482/src/test/java/org/elasticsearch/common/util/SlicedDoubleListTests.java)
    public void testCapacity() {
        SlicedDoubleList list = new SlicedDoubleList(5);
        assertThat(list.length, equalTo(5));
        assertThat(list.offset, equalTo(0));
        assertThat(list.values.length, equalTo(5));
        assertThat(list.size(), equalTo(5));

        
        list = new SlicedDoubleList(new double[10], 5, 5);
        assertThat(list.length, equalTo(5));
        assertThat(list.offset, equalTo(5));
        assertThat(list.size(), equalTo(5));
        assertThat(list.values.length, equalTo(10));
    }
,
(startLine=33 endLine=45 srcPath=/root/NewExperiment/elasticsearchFilter/01482/src/test/java/org/elasticsearch/common/util/SlicedLongListTests.java)
    public void testCapacity() {
        SlicedLongList list = new SlicedLongList(5);
        assertThat(list.length, equalTo(5));
        assertThat(list.offset, equalTo(0));
        assertThat(list.values.length, equalTo(5));
        assertThat(list.size(), equalTo(5));
        
        list = new SlicedLongList(new long[10], 5, 5);
        assertThat(list.length, equalTo(5));
        assertThat(list.offset, equalTo(5));
        assertThat(list.size(), equalTo(5));
        assertThat(list.values.length, equalTo(10));
    }
,
(startLine=60 endLine=73 srcPath=/root/NewExperiment/elasticsearchFilter/01482/src/test/java/org/elasticsearch/common/util/SlicedObjectListTests.java)
    public void testCapacity() {
        TestList list = new TestList(5);
        assertThat(list.length, equalTo(5));
        assertThat(list.offset, equalTo(0));
        assertThat(list.values.length, equalTo(5));
        assertThat(list.size(), equalTo(5));

        
        list = new TestList(new Double[10], 5, 5);
        assertThat(list.length, equalTo(5));
        assertThat(list.offset, equalTo(5));
        assertThat(list.size(), equalTo(5));
        assertThat(list.values.length, equalTo(10));
    }
,
>
, <(startLine=59 endLine=73 srcPath=/root/NewExperiment/elasticsearchFilter/02407/core/src/test/java/org/elasticsearch/index/fielddata/ordinals/MultiOrdinalsTests.java)
            public int compare(OrdAndId o1, OrdAndId o2) {
                if (o1.ord < o2.ord) {
                    return -1;
                }
                if (o1.ord == o2.ord) {
                    if (o1.id < o2.id) {
                        return -1;
                    }
                    if (o1.id > o2.id) {
                        return 1;
                    }
                    return 0;
                }
                return 1;
            }
,
(startLine=88 endLine=102 srcPath=/root/NewExperiment/elasticsearchFilter/02407/core/src/test/java/org/elasticsearch/index/fielddata/ordinals/MultiOrdinalsTests.java)
            public int compare(OrdAndId o1, OrdAndId o2) {
                if (o1.id < o2.id) {
                    return -1;
                }
                if (o1.id == o2.id) {
                    if (o1.ord < o2.ord) {
                        return -1;
                    }
                    if (o1.ord > o2.ord) {
                        return 1;
                    }
                    return 0;
                }
                return 1;
            }
,
>
, <(startLine=998 endLine=1009 srcPath=/root/NewExperiment/elasticsearchFilter/01705/src/test/java/org/elasticsearch/aliases/IndexAliasesTests.java)
        for (String block : Arrays.asList(SETTING_BLOCKS_READ, SETTING_BLOCKS_WRITE)) {
            try {
                enableIndexBlock("test", block);

                assertAcked(admin().indices().prepareAliases().addAlias("test", "alias1").addAlias("test", "alias2"));
                assertAcked(admin().indices().prepareAliases().removeAlias("test", "alias1"));
                assertThat(admin().indices().prepareGetAliases("alias2").execute().actionGet().getAliases().get("test").size(), equalTo(1));
                assertThat(admin().indices().prepareAliasesExist("alias2").get().exists(), equalTo(true));
            } finally {
                disableIndexBlock("test", block);
            }
        }
,
(startLine=1011 endLine=1019 srcPath=/root/NewExperiment/elasticsearchFilter/01705/src/test/java/org/elasticsearch/aliases/IndexAliasesTests.java)
        try {
            enableIndexBlock("test", SETTING_READ_ONLY);

            assertBlocked(admin().indices().prepareAliases().addAlias("test", "alias3"), INDEX_READ_ONLY_BLOCK);
            assertBlocked(admin().indices().prepareAliases().removeAlias("test", "alias2"), INDEX_READ_ONLY_BLOCK);
            assertThat(admin().indices().prepareGetAliases("alias2").execute().actionGet().getAliases().get("test").size(), equalTo(1));
            assertThat(admin().indices().prepareAliasesExist("alias2").get().exists(), equalTo(true));

        } finally {
,
>
, <(startLine=122 endLine=140 srcPath=/root/NewExperiment/elasticsearchFilter/02079/core/src/main/java/org/elasticsearch/common/breaker/MemoryCircuitBreaker.java)
        do {
            currentUsed = this.used.get();
            newUsed = currentUsed + bytes;
            long newUsedWithOverhead = (long)(newUsed * overheadConstant);
            if (logger.isTraceEnabled()) {
                logger.trace("Adding [{}][{}] to used bytes [new used: [{}], limit: {} [{}], estimate: {} [{}]]",
                        new ByteSizeValue(bytes), label, new ByteSizeValue(newUsed),
                        memoryBytesLimit, new ByteSizeValue(memoryBytesLimit),
                        newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead));
            }
            if (memoryBytesLimit > 0 && newUsedWithOverhead > memoryBytesLimit) {
                logger.warn("New used memory {} [{}] from field [{}] would be larger than configured breaker: {} [{}], breaking",
                        newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label,
                        memoryBytesLimit, new ByteSizeValue(memoryBytesLimit));
                circuitBreak(label, newUsedWithOverhead);
            }
            // Attempt to set the new used value, but make sure it hasn't changed
            // underneath us, if it has, keep trying until we are able to set it
        } while (!this.used.compareAndSet(currentUsed, newUsed));
,
(startLine=149 endLine=176 srcPath=/root/NewExperiment/elasticsearchFilter/02079/core/src/main/java/org/elasticsearch/common/breaker/ChildMemoryCircuitBreaker.java)
    private long limit(long bytes, String label) {
        long newUsed;// Otherwise, check the addition and commit the addition, looping if
        // there are conflicts. May result in additional logging, but it's
        // trace logging and shouldn't be counted on for additions.
        long currentUsed;
        do {
            currentUsed = this.used.get();
            newUsed = currentUsed + bytes;
            long newUsedWithOverhead = (long) (newUsed * overheadConstant);
            if (logger.isTraceEnabled()) {
                logger.trace("[{}] Adding [{}][{}] to used bytes [new used: [{}], limit: {} [{}], estimate: {} [{}]]",
                        this.name,
                        new ByteSizeValue(bytes), label, new ByteSizeValue(newUsed),
                        memoryBytesLimit, new ByteSizeValue(memoryBytesLimit),
                        newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead));
            }
            if (memoryBytesLimit > 0 && newUsedWithOverhead > memoryBytesLimit) {
                logger.warn("[{}] New used memory {} [{}] for data of [{}] would be larger than configured breaker: {} [{}], breaking",
                        this.name,
                        newUsedWithOverhead, new ByteSizeValue(newUsedWithOverhead), label,
                        memoryBytesLimit, new ByteSizeValue(memoryBytesLimit));
                circuitBreak(label, newUsedWithOverhead);
            }
            // Attempt to set the new used value, but make sure it hasn't changed
            // underneath us, if it has, keep trying until we are able to set it
        } while (!this.used.compareAndSet(currentUsed, newUsed));
        return newUsed;
    }
,
>
, <(startLine=165 endLine=175 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
            } else {
                List<BooleanClause> clauses = new ArrayList<>();
                for (String mField : fields) {
                    Query q = getFieldQuerySingle(mField, queryText, quoted);
                    if (q != null) {
                        clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                    }
                }
                if (clauses.isEmpty()) return null; // happens for stopwords
                return getBooleanQueryCoordDisabled(clauses);
            }
,
(startLine=266 endLine=277 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
            } else {
                List<BooleanClause> clauses = new ArrayList<>();
                for (String mField : fields) {
                    Query q = super.getFieldQuery(mField, queryText, slop);
                    if (q != null) {
                        q = applySlop(q, slop);
                        clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                    }
                }
                if (clauses.isEmpty()) return null; // happens for stopwords
                return getBooleanQueryCoordDisabled(clauses);
            }
,
(startLine=318 endLine=328 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
        } else {
            List<BooleanClause> clauses = new ArrayList<>();
            for (String mField : fields) {
                Query q = getRangeQuerySingle(mField, part1, part2, startInclusive, endInclusive, context);
                if (q != null) {
                    clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                }
            }
            if (clauses.isEmpty()) return null; // happens for stopwords
            return getBooleanQueryCoordDisabled(clauses);
        }
,
(startLine=377 endLine=386 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
            } else {
                List<BooleanClause> clauses = new ArrayList<>();
                for (String mField : fields) {
                    Query q = getFuzzyQuerySingle(mField, termStr, minSimilarity);
                    if (q != null) {
                        clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                    }
                }
                return getBooleanQueryCoordDisabled(clauses);
            }
,
(startLine=440 endLine=450 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
            } else {
                List<BooleanClause> clauses = new ArrayList<>();
                for (String mField : fields) {
                    Query q = getPrefixQuerySingle(mField, termStr);
                    if (q != null) {
                        clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                    }
                }
                if (clauses.isEmpty()) return null; // happens for stopwords
                return getBooleanQueryCoordDisabled(clauses);
            }
,
(startLine=604 endLine=614 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
            } else {
                List<BooleanClause> clauses = new ArrayList<>();
                for (String mField : fields) {
                    Query q = getWildcardQuerySingle(mField, termStr);
                    if (q != null) {
                        clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                    }
                }
                if (clauses.isEmpty()) return null; // happens for stopwords
                return getBooleanQueryCoordDisabled(clauses);
            }
,
(startLine=664 endLine=674 srcPath=/root/NewExperiment/elasticsearchFilter/01892/core/src/main/java/org/apache/lucene/queryparser/classic/MapperQueryParser.java)
            } else {
                List<BooleanClause> clauses = new ArrayList<>();
                for (String mField : fields) {
                    Query q = getRegexpQuerySingle(mField, termStr);
                    if (q != null) {
                        clauses.add(new BooleanClause(applyBoost(mField, q), BooleanClause.Occur.SHOULD));
                    }
                }
                if (clauses.isEmpty()) return null; // happens for stopwords
                return getBooleanQueryCoordDisabled(clauses);
            }
,
>
, <(startLine=664 endLine=671 srcPath=/root/NewExperiment/elasticsearchFilter/01923/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java)
        for (int i = 0; i < clusterState.routingTable().index("test").shards().size(); i++) {
            assertThat(clusterState.routingTable().index("test").shard(i).shards().size(), equalTo(1));
            if (clusterState.routingTable().index("test").shard(i).primaryShard().state() == STARTED) {
                numStarted++;
            } else if (clusterState.routingTable().index("test").shard(i).primaryShard().state() == RELOCATING) {
                numRelocating++;
            }
        }
,
(startLine=743 endLine=751 srcPath=/root/NewExperiment/elasticsearchFilter/01923/core/src/test/java/org/elasticsearch/cluster/routing/allocation/ClusterRebalanceRoutingTests.java)
        for (int i = 0; i < clusterState.routingTable().index("test").shards().size(); i++) {

            assertThat(clusterState.routingTable().index("test").shard(i).shards().size(), equalTo(1));
            if (clusterState.routingTable().index("test").shard(i).primaryShard().state() == STARTED) {
                numStarted++;
            } else if (clusterState.routingTable().index("test").shard(i).primaryShard().state() == RELOCATING) {
                numRelocating++;
            }
        }
,
>
, <(startLine=269 endLine=306 srcPath=/root/NewExperiment/elasticsearchFilter/01747/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java)
    public void testQueryAndFetch() throws Exception {
        prepareData(3);

        SearchSourceBuilder source = searchSource()
                .query(termQuery("multi", "test"))
                .from(0).size(20).explain(true);

        Set<String> expectedIds = new HashSet<>();
        for (int i = 0; i < 100; i++) {
            expectedIds.add(Integer.toString(i));
        }

        SearchResponse searchResponse = client().search(searchRequest("test").source(source).searchType(QUERY_AND_FETCH).scroll(new Scroll(timeValueMinutes(10)))).actionGet();
        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(100l));
        assertThat(searchResponse.getHits().hits().length, equalTo(60)); // 20 per shard
        for (int i = 0; i < 60; i++) {
            SearchHit hit = searchResponse.getHits().hits()[i];
//            System.out.println(hit.shard() + ": " +  hit.explanation());
            assertThat(hit.explanation(), notNullValue());
            // we can't really check here, since its query and fetch, and not controlling distribution
//            assertThat("id[" + hit.id() + "]", hit.id(), equalTo(Integer.toString(100 - i - 1)));
            assertThat("make sure we don't have duplicates", expectedIds.remove(hit.id()), notNullValue());
        }

        do {
            searchResponse = client().prepareSearchScroll(searchResponse.getScrollId()).setScroll("10m").get();
            assertThat(searchResponse.getHits().totalHits(), equalTo(100l));
            assertThat(searchResponse.getHits().hits().length, lessThanOrEqualTo(40));
            for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
                SearchHit hit = searchResponse.getHits().hits()[i];
                // we don't do perfect sorting when it comes to scroll with Query+Fetch
                assertThat("make sure we don't have duplicates", expectedIds.remove(hit.id()), notNullValue());
            }
        } while (searchResponse.getHits().getHits().length > 0);
        clearScroll(searchResponse.getScrollId());
        assertThat("make sure we got all [" + expectedIds + "]", expectedIds.size(), equalTo(0));
    }
,
(startLine=309 endLine=348 srcPath=/root/NewExperiment/elasticsearchFilter/01747/core/src/test/java/org/elasticsearch/search/basic/TransportTwoNodesSearchIT.java)
    public void testDfsQueryAndFetch() throws Exception {
        prepareData(3);

        SearchSourceBuilder source = searchSource()
                .query(termQuery("multi", "test"))
                .from(0).size(20).explain(true);

        Set<String> expectedIds = new HashSet<>();
        for (int i = 0; i < 100; i++) {
            expectedIds.add(Integer.toString(i));
        }


        //SearchResponse searchResponse = client().search(searchRequest("test").source(source).searchType(DFS_QUERY_AND_FETCH).scroll(new Scroll(timeValueMinutes(10)))).actionGet();
        SearchResponse searchResponse = client().prepareSearch("test").setSearchType(DFS_QUERY_AND_FETCH).setScroll("10m").setSource(source).get();
        assertNoFailures(searchResponse);
        assertThat(searchResponse.getHits().totalHits(), equalTo(100l));
        assertThat(searchResponse.getHits().hits().length, equalTo(60)); // 20 per shard
        for (int i = 0; i < 60; i++) {
            SearchHit hit = searchResponse.getHits().hits()[i];
//            System.out.println(hit.shard() + ": " +  hit.explanation());
            assertThat(hit.explanation(), notNullValue());
//            assertThat("id[" + hit.id() + "]", hit.id(), equalTo(Integer.toString(100 - i - 1)));
            assertThat("make sure we don't have duplicates", expectedIds.remove(hit.id()), notNullValue());
        }

        do {
            searchResponse = client().prepareSearchScroll(searchResponse.getScrollId()).setScroll("10m").get();
    
            assertThat(searchResponse.getHits().totalHits(), equalTo(100l));
            assertThat(searchResponse.getHits().hits().length, lessThanOrEqualTo(40));
            for (int i = 0; i < searchResponse.getHits().hits().length; i++) {
                SearchHit hit = searchResponse.getHits().hits()[i];
                // we don't do perfect sorting when it comes to scroll with Query+Fetch
                assertThat("make sure we don't have duplicates", expectedIds.remove(hit.id()), notNullValue());
            }
        } while (searchResponse.getHits().hits().length > 0);
        clearScroll(searchResponse.getScrollId());
        assertThat("make sure we got all [" + expectedIds + "]", expectedIds.size(), equalTo(0));
    }
,
>
, <(startLine=210 endLine=267 srcPath=/root/NewExperiment/elasticsearchFilter/01011/src/test/java/org/elasticsearch/index/fielddata/DuelFieldDataTests.java)
    public void testDuelDoubles() throws Exception {
        Random random = getRandom();
        int atLeast = atLeast(random, 1000);
        for (int i = 0; i < atLeast; i++) {
            Document d = new Document();
            d.add(new StringField("_id", "" + i, Field.Store.NO));
            if (random.nextInt(15) != 0) {
                int[] numbers = getNumbers(random, Short.MAX_VALUE);
                for (int j : numbers) {
                    d.add(new FloatField("float", j, Field.Store.NO ));
                    d.add(new DoubleField("double", j, Field.Store.NO));
                    if (LuceneTestCase.defaultCodecSupportsSortedSet()) {
                        d.add(doubleDV("double", j));
                        d.add(floatDV("float", j));
                    }
                }
            }
            writer.addDocument(d);
            if (random.nextInt(10) == 0) {
                refreshReader();
            }
        }
        AtomicReaderContext context = refreshReader();
        Map<FieldDataType, Type> typeMap = new HashMap<FieldDataType, Type>();
        typeMap.put(new FieldDataType("double", ImmutableSettings.builder().put("format", "array")), Type.Double);
        typeMap.put(new FieldDataType("float", ImmutableSettings.builder().put("format", "array")), Type.Float);
        if (LuceneTestCase.defaultCodecSupportsSortedSet()) {
            typeMap.put(new FieldDataType("double", ImmutableSettings.builder().put("format", "doc_values")), Type.Double);
            typeMap.put(new FieldDataType("float", ImmutableSettings.builder().put("format", "doc_values")), Type.Float);
        }
        ArrayList<Entry<FieldDataType, Type>> list = new ArrayList<Entry<FieldDataType, Type>>(typeMap.entrySet());
        while (!list.isEmpty()) {
            Entry<FieldDataType, Type> left;
            Entry<FieldDataType, Type> right;
            if (list.size() > 1) {
                left = list.remove(random.nextInt(list.size()));
                right = list.remove(random.nextInt(list.size()));
            } else {
                right = left = list.remove(0);
            }
            ifdService.clear();
            IndexNumericFieldData leftFieldData = ifdService.getForField(new FieldMapper.Names(left.getValue().name().toLowerCase(Locale.ROOT)),
                    left.getKey(), true);
            ifdService.clear();
            IndexNumericFieldData rightFieldData = ifdService.getForField(new FieldMapper.Names(right.getValue().name().toLowerCase(Locale.ROOT)),
                    right.getKey(), true);
            duelFieldDataDouble(random, context, leftFieldData, rightFieldData);
            duelFieldDataDouble(random, context, rightFieldData, leftFieldData);

            DirectoryReader perSegment = DirectoryReader.open(writer, true);
            CompositeReaderContext composite = perSegment.getContext();
            List<AtomicReaderContext> leaves = composite.leaves();
            for (AtomicReaderContext atomicReaderContext : leaves) {
                duelFieldDataDouble(random, atomicReaderContext, leftFieldData, rightFieldData);
            }
        }

    }
,
(startLine=271 endLine=335 srcPath=/root/NewExperiment/elasticsearchFilter/01011/src/test/java/org/elasticsearch/index/fielddata/DuelFieldDataTests.java)
    public void testDuelStrings() throws Exception {
        Random random = getRandom();
        int atLeast = atLeast(random, 1000);
        for (int i = 0; i < atLeast; i++) {
            Document d = new Document();
            d.add(new StringField("_id", "" + i, Field.Store.NO));
            if (random.nextInt(15) != 0) {
                int[] numbers = getNumbers(random, Integer.MAX_VALUE);
                for (int j : numbers) {
                    final String s = English.longToEnglish(j);
                    d.add(new StringField("bytes", s, Field.Store.NO));
                    if (LuceneTestCase.defaultCodecSupportsSortedSet()) {
                        d.add(new SortedSetDocValuesField("bytes", new BytesRef(s)));
                    }
                }
                if (random.nextInt(10) == 0) {
                    d.add(new StringField("bytes", "", Field.Store.NO));
                    if (LuceneTestCase.defaultCodecSupportsSortedSet()) {
                        d.add(new SortedSetDocValuesField("bytes", new BytesRef()));
                    }
                }
            }
            writer.addDocument(d);
            if (random.nextInt(10) == 0) {
                refreshReader();
            }
        }
        AtomicReaderContext context = refreshReader();
        Map<FieldDataType, Type> typeMap = new HashMap<FieldDataType, DuelFieldDataTests.Type>();
        typeMap.put(new FieldDataType("string", ImmutableSettings.builder().put("format", "fst")), Type.Bytes);
        typeMap.put(new FieldDataType("string", ImmutableSettings.builder().put("format", "paged_bytes")), Type.Bytes);
        if (LuceneTestCase.defaultCodecSupportsSortedSet()) {
            typeMap.put(new FieldDataType("string", ImmutableSettings.builder().put("format", "doc_values")), Type.Bytes);
        }
        // TODO add filters
        ArrayList<Entry<FieldDataType, Type>> list = new ArrayList<Entry<FieldDataType, Type>>(typeMap.entrySet());
        Preprocessor pre = new Preprocessor();
        while (!list.isEmpty()) {
            Entry<FieldDataType, Type> left;
            Entry<FieldDataType, Type> right;
            if (list.size() > 1) {
                left = list.remove(random.nextInt(list.size()));
                right = list.remove(random.nextInt(list.size()));
            } else {
                right = left = list.remove(0);
            }
            ifdService.clear();
            IndexFieldData leftFieldData = ifdService.getForField(new FieldMapper.Names(left.getValue().name().toLowerCase(Locale.ROOT)),
                    left.getKey(), true);
            ifdService.clear();
            IndexFieldData rightFieldData = ifdService.getForField(new FieldMapper.Names(right.getValue().name().toLowerCase(Locale.ROOT)),
                    right.getKey(), true);
            duelFieldDataBytes(random, context, leftFieldData, rightFieldData, pre);
            duelFieldDataBytes(random, context, rightFieldData, leftFieldData, pre);

            DirectoryReader perSegment = DirectoryReader.open(writer, true);
            CompositeReaderContext composite = perSegment.getContext();
            List<AtomicReaderContext> leaves = composite.leaves();
            for (AtomicReaderContext atomicReaderContext : leaves) {
                duelFieldDataBytes(random, atomicReaderContext, leftFieldData, rightFieldData, pre);
            }
            perSegment.close();
        }

    }
,
>
, <(startLine=59 endLine=101 srcPath=/root/NewExperiment/elasticsearchFilter/00399/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/scan/SearchScanTests.java)
    @Test public void testSimpleScroll1() throws Exception {
        try {
            client.admin().indices().prepareDelete("test").execute().actionGet();
        } catch (Exception e) {
            // ignore
        }
        client.admin().indices().prepareCreate("test").setSettings(ImmutableSettings.settingsBuilder().put("index.number_of_shards", 3)).execute().actionGet();
        client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();

        Set<String> ids = Sets.newHashSet();
        Set<String> expectedIds = Sets.newHashSet();
        for (int i = 0; i < 100; i++) {
            String id = Integer.toString(i);
            expectedIds.add(id);
            client.prepareIndex("test", "type1", id).setSource("field", i).execute().actionGet();
        }

        client.admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client.prepareSearch()
                .setSearchType(SearchType.SCAN)
                .setQuery(matchAllQuery())
                .setSize(7)
                .setScroll(TimeValue.timeValueMinutes(2))
                .execute().actionGet();

        assertThat(searchResponse.hits().totalHits(), equalTo(100l));

        // start scrolling, until we get not results
        while (true) {
            searchResponse = client.prepareSearchScroll(searchResponse.scrollId()).setScroll(TimeValue.timeValueMinutes(2)).execute().actionGet();
            assertThat(searchResponse.failedShards(), equalTo(0));
            for (SearchHit hit : searchResponse.hits()) {
                assertThat(hit.id() + "should not exists in the result set", ids.contains(hit.id()), equalTo(false));
                ids.add(hit.id());
            }
            if (searchResponse.hits().totalHits() == 0) {
                break;
            }
        }

        assertThat(expectedIds, equalTo(ids));
    }
,
(startLine=103 endLine=145 srcPath=/root/NewExperiment/elasticsearchFilter/00399/modules/test/integration/src/test/java/org/elasticsearch/test/integration/search/scan/SearchScanTests.java)
    @Test public void testSimpleScroll2() throws Exception {
        try {
            client.admin().indices().prepareDelete("test").execute().actionGet();
        } catch (Exception e) {
            // ignore
        }
        client.admin().indices().prepareCreate("test").setSettings(ImmutableSettings.settingsBuilder().put("index.number_of_shards", 1)).execute().actionGet();
        client.admin().cluster().prepareHealth().setWaitForGreenStatus().execute().actionGet();

        Set<String> ids = Sets.newHashSet();
        Set<String> expectedIds = Sets.newHashSet();
        for (int i = 0; i < 100; i++) {
            String id = Integer.toString(i);
            expectedIds.add(id);
            client.prepareIndex("test", "type1", id).setSource("field", i).execute().actionGet();
        }

        client.admin().indices().prepareRefresh().execute().actionGet();

        SearchResponse searchResponse = client.prepareSearch()
                .setSearchType(SearchType.SCAN)
                .setQuery(matchAllQuery())
                .setSize(10)
                .setScroll(TimeValue.timeValueMinutes(2))
                .execute().actionGet();

        assertThat(searchResponse.hits().totalHits(), equalTo(100l));

        // start scrolling, until we get not results
        while (true) {
            searchResponse = client.prepareSearchScroll(searchResponse.scrollId()).setScroll(TimeValue.timeValueMinutes(2)).execute().actionGet();
            assertThat(searchResponse.failedShards(), equalTo(0));
            for (SearchHit hit : searchResponse.hits()) {
                assertThat(hit.id() + "should not exists in the result set", ids.contains(hit.id()), equalTo(false));
                ids.add(hit.id());
            }
            if (searchResponse.hits().totalHits() == 0) {
                break;
            }
        }

        assertThat(expectedIds, equalTo(ids));
    }
,
>
, <(startLine=48 endLine=61 srcPath=/root/NewExperiment/elasticsearchFilter/00430/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/status/GatewayRecoveryStatus.java)
        public static Stage fromValue(byte value) {
            if (value == 0) {
                return INIT;
            } else if (value == 1) {
                return INDEX;
            } else if (value == 2) {
                return TRANSLOG;
            } else if (value == 3) {
                return FINALIZE;
            } else if (value == 4) {
                return DONE;
            }
            throw new ElasticSearchIllegalArgumentException("No stage found for [" + value + ']');
        }
,
(startLine=48 endLine=61 srcPath=/root/NewExperiment/elasticsearchFilter/00430/modules/elasticsearch/src/main/java/org/elasticsearch/action/admin/indices/status/PeerRecoveryStatus.java)
        public static Stage fromValue(byte value) {
            if (value == 0) {
                return INIT;
            } else if (value == 1) {
                return INDEX;
            } else if (value == 2) {
                return TRANSLOG;
            } else if (value == 3) {
                return FINALIZE;
            } else if (value == 4) {
                return DONE;
            }
            throw new ElasticSearchIllegalArgumentException("No stage found for [" + value + ']');
        }
,
>
, <(startLine=449 endLine=465 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/metrics/CardinalityTests.java)
    public void asSubAgg() throws Exception {
        SearchResponse response = client().prepareSearch("idx").setTypes("type")
                .addAggregation(terms("terms").field("str_value")
                        .collectMode(randomFrom(SubAggCollectionMode.values()))
                        .subAggregation(cardinality("cardinality").precisionThreshold(precisionThreshold).field("str_values")))
                .execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        for (Terms.Bucket bucket : terms.getBuckets()) {
            Cardinality count = bucket.getAggregations().get("cardinality");
            assertThat(count, notNullValue());
            assertThat(count.getName(), equalTo("cardinality"));
            assertCount(count, 2);
        }
    }
,
(startLine=468 endLine=484 srcPath=/root/NewExperiment/elasticsearchFilter/01715/core/src/test/java/org/elasticsearch/search/aggregations/metrics/CardinalityTests.java)
    public void asSubAggHashed() throws Exception {
        SearchResponse response = client().prepareSearch("idx").setTypes("type")
                .addAggregation(terms("terms").field("str_value")
                        .collectMode(randomFrom(SubAggCollectionMode.values()))
                        .subAggregation(cardinality("cardinality").precisionThreshold(precisionThreshold).field("str_values.hash")))
                .execute().actionGet();

        assertSearchResponse(response);

        Terms terms = response.getAggregations().get("terms");
        for (Terms.Bucket bucket : terms.getBuckets()) {
            Cardinality count = bucket.getAggregations().get("cardinality");
            assertThat(count, notNullValue());
            assertThat(count.getName(), equalTo("cardinality"));
            assertCount(count, 2);
        }
    }
,
>
]